{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European Bird Sightings Analysis\n",
    "## Combining and Analyzing eBird Data from 47 European Countries\n",
    "\n",
    "This notebook will:\n",
    "1. Combine all your CSV files into one dataset\n",
    "2. Perform comprehensive statistical analysis\n",
    "3. Create visualizations\n",
    "4. Export results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Combine All CSV Files\n",
    "\n",
    "**Instructions:** \n",
    "- Update the `data_directory` path below to point to where your CSV files are stored\n",
    "- The script will automatically find all files matching the pattern `checkpoint_ebird_*.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 CSV files\n",
      "\n",
      "Files found:\n",
      "  1. checkpoint_ebird_AD_49_obs.csv\n",
      "  2. checkpoint_ebird_LT_12328_obs.csv\n",
      "  3. checkpoint_ebird_DK_4512_obs.csv\n",
      "  4. checkpoint_ebird_ME_12657_obs.csv\n",
      "  5. checkpoint_ebird_BA_1376_obs.csv\n",
      "  6. checkpoint_ebird_MD_12606_obs.csv\n",
      "  7. checkpoint_ebird_IT_11780_obs.csv\n",
      "  8. checkpoint_ebird_MK_17_obs.csv\n",
      "  9. checkpoint_ebird_AL_49_obs.csv\n",
      "  10. checkpoint_ebird_XK_11848_obs.csv\n",
      "  11. checkpoint_ebird_MC_12606_obs.csv\n",
      "  12. checkpoint_ebird_BY_762_obs.csv\n",
      "  13. checkpoint_ebird_AT_443_obs.csv\n",
      "  14. checkpoint_ebird_BE_1355_obs.csv\n",
      "  15. checkpoint_ebird_PT_3915_obs.csv\n",
      "  16. checkpoint_ebird_DE_8318_obs.csv\n",
      "  17. checkpoint_ebird_IS_10102_obs.csv\n",
      "  18. checkpoint_ebird_HU_9875_obs.csv\n",
      "  19. checkpoint_ebird_RU_4826_obs.csv\n",
      "  20. checkpoint_ebird_FI_5521_obs.csv\n",
      "  21. checkpoint_ebird_SM_4826_obs.csv\n",
      "  22. checkpoint_ebird_NO_741_obs.csv\n",
      "  23. checkpoint_ebird_RO_4199_obs.csv\n",
      "  24. checkpoint_ebird_EE_4754_obs.csv\n",
      "  25. checkpoint_ebird_BG_2163_obs.csv\n",
      "  26. checkpoint_ebird_LU_12340_obs.csv\n",
      "  27. checkpoint_ebird_LV_12011_obs.csv\n",
      "  28. checkpoint_ebird_GR_9351_obs.csv\n",
      "  29. checkpoint_ebird_MT_12456_obs.csv\n",
      "  30. checkpoint_ebird_CZ_3742_obs.csv\n",
      "  31. checkpoint_ebird_LI_12011_obs.csv\n",
      "  32. checkpoint_ebird_IE_10722_obs.csv\n",
      "  33. checkpoint_ebird_RS_5234_obs.csv\n",
      "  34. checkpoint_ebird_PL_1885_obs.csv\n",
      "  35. checkpoint_ebird_CY_2913_obs.csv\n",
      "  36. checkpoint_ebird_FR_7034_obs.csv\n",
      "  37. checkpoint_ebird_HR_2475_obs.csv\n"
     ]
    }
   ],
   "source": [
    "# UPDATE THIS PATH to where your CSV files are located\n",
    "data_directory = Path('/Users/dazedinthecity/Documents/GitHub/ceu-ds-project-groupB-2026/ebird/14spe_2022')  # Current directory - change as needed\n",
    "\n",
    "# Find all eBird CSV files\n",
    "csv_files = list(data_directory.glob('checkpoint_ebird_*.csv'))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "print(\"\\nFiles found:\")\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    print(f\"  {i}. {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n",
      "\n",
      "✓ Loaded checkpoint_ebird_AD_49_obs.csv: 49 observations\n",
      "✓ Loaded checkpoint_ebird_LT_12328_obs.csv: 12,328 observations\n",
      "✓ Loaded checkpoint_ebird_DK_4512_obs.csv: 4,512 observations\n",
      "✓ Loaded checkpoint_ebird_ME_12657_obs.csv: 12,657 observations\n",
      "✓ Loaded checkpoint_ebird_BA_1376_obs.csv: 1,376 observations\n",
      "✓ Loaded checkpoint_ebird_MD_12606_obs.csv: 12,606 observations\n",
      "✓ Loaded checkpoint_ebird_IT_11780_obs.csv: 11,780 observations\n",
      "✓ Loaded checkpoint_ebird_MK_17_obs.csv: 17 observations\n",
      "✓ Loaded checkpoint_ebird_AL_49_obs.csv: 49 observations\n",
      "✓ Loaded checkpoint_ebird_XK_11848_obs.csv: 11,848 observations\n",
      "✓ Loaded checkpoint_ebird_MC_12606_obs.csv: 12,606 observations\n",
      "✓ Loaded checkpoint_ebird_BY_762_obs.csv: 762 observations\n",
      "✓ Loaded checkpoint_ebird_AT_443_obs.csv: 443 observations\n",
      "✓ Loaded checkpoint_ebird_BE_1355_obs.csv: 1,355 observations\n",
      "✓ Loaded checkpoint_ebird_PT_3915_obs.csv: 3,915 observations\n",
      "✓ Loaded checkpoint_ebird_DE_8318_obs.csv: 8,318 observations\n",
      "✓ Loaded checkpoint_ebird_IS_10102_obs.csv: 10,102 observations\n",
      "✓ Loaded checkpoint_ebird_HU_9875_obs.csv: 9,875 observations\n",
      "✓ Loaded checkpoint_ebird_RU_4826_obs.csv: 4,826 observations\n",
      "✓ Loaded checkpoint_ebird_FI_5521_obs.csv: 5,521 observations\n",
      "✓ Loaded checkpoint_ebird_SM_4826_obs.csv: 4,826 observations\n",
      "✓ Loaded checkpoint_ebird_NO_741_obs.csv: 741 observations\n",
      "✓ Loaded checkpoint_ebird_RO_4199_obs.csv: 4,199 observations\n",
      "✓ Loaded checkpoint_ebird_EE_4754_obs.csv: 4,754 observations\n",
      "✓ Loaded checkpoint_ebird_BG_2163_obs.csv: 2,163 observations\n",
      "✓ Loaded checkpoint_ebird_LU_12340_obs.csv: 12,340 observations\n",
      "✓ Loaded checkpoint_ebird_LV_12011_obs.csv: 12,011 observations\n",
      "✓ Loaded checkpoint_ebird_GR_9351_obs.csv: 9,351 observations\n",
      "✓ Loaded checkpoint_ebird_MT_12456_obs.csv: 12,456 observations\n",
      "✓ Loaded checkpoint_ebird_CZ_3742_obs.csv: 3,742 observations\n",
      "✓ Loaded checkpoint_ebird_LI_12011_obs.csv: 12,011 observations\n",
      "✓ Loaded checkpoint_ebird_IE_10722_obs.csv: 10,722 observations\n",
      "✓ Loaded checkpoint_ebird_RS_5234_obs.csv: 5,234 observations\n",
      "✓ Loaded checkpoint_ebird_PL_1885_obs.csv: 1,885 observations\n",
      "✓ Loaded checkpoint_ebird_CY_2913_obs.csv: 2,913 observations\n",
      "✓ Loaded checkpoint_ebird_FR_7034_obs.csv: 7,034 observations\n",
      "✓ Loaded checkpoint_ebird_HR_2475_obs.csv: 2,475 observations\n",
      "\n",
      "============================================================\n",
      "Successfully loaded 37 files\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load and combine all CSV files\n",
    "print(\"Loading CSV files...\\n\")\n",
    "\n",
    "dfs = []\n",
    "file_info = []\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "        \n",
    "        # Extract country code from filename (e.g., AD from checkpoint_ebird_AD_638_obs.csv)\n",
    "        country_code = file.stem.split('_')[2]\n",
    "        \n",
    "        file_info.append({\n",
    "            'File': file.name,\n",
    "            'Country Code': country_code,\n",
    "            'Observations': len(df)\n",
    "        })\n",
    "        \n",
    "        print(f\"✓ Loaded {file.name}: {len(df):,} observations\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {file.name}: {e}\")\n",
    "\n",
    "# Create summary dataframe\n",
    "files_df = pd.DataFrame(file_info).sort_values('Observations', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Successfully loaded {len(dfs)} files\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File Loading Summary:\n",
      "                             File Country Code  Observations\n",
      "checkpoint_ebird_ME_12657_obs.csv           ME         12657\n",
      "checkpoint_ebird_MD_12606_obs.csv           MD         12606\n",
      "checkpoint_ebird_MC_12606_obs.csv           MC         12606\n",
      "checkpoint_ebird_MT_12456_obs.csv           MT         12456\n",
      "checkpoint_ebird_LU_12340_obs.csv           LU         12340\n",
      "checkpoint_ebird_LT_12328_obs.csv           LT         12328\n",
      "checkpoint_ebird_LI_12011_obs.csv           LI         12011\n",
      "checkpoint_ebird_LV_12011_obs.csv           LV         12011\n",
      "checkpoint_ebird_XK_11848_obs.csv           XK         11848\n",
      "checkpoint_ebird_IT_11780_obs.csv           IT         11780\n",
      "checkpoint_ebird_IE_10722_obs.csv           IE         10722\n",
      "checkpoint_ebird_IS_10102_obs.csv           IS         10102\n",
      " checkpoint_ebird_HU_9875_obs.csv           HU          9875\n",
      " checkpoint_ebird_GR_9351_obs.csv           GR          9351\n",
      " checkpoint_ebird_DE_8318_obs.csv           DE          8318\n",
      " checkpoint_ebird_FR_7034_obs.csv           FR          7034\n",
      " checkpoint_ebird_FI_5521_obs.csv           FI          5521\n",
      " checkpoint_ebird_RS_5234_obs.csv           RS          5234\n",
      " checkpoint_ebird_SM_4826_obs.csv           SM          4826\n",
      " checkpoint_ebird_RU_4826_obs.csv           RU          4826\n",
      " checkpoint_ebird_EE_4754_obs.csv           EE          4754\n",
      " checkpoint_ebird_DK_4512_obs.csv           DK          4512\n",
      " checkpoint_ebird_RO_4199_obs.csv           RO          4199\n",
      " checkpoint_ebird_PT_3915_obs.csv           PT          3915\n",
      " checkpoint_ebird_CZ_3742_obs.csv           CZ          3742\n",
      " checkpoint_ebird_CY_2913_obs.csv           CY          2913\n",
      " checkpoint_ebird_HR_2475_obs.csv           HR          2475\n",
      " checkpoint_ebird_BG_2163_obs.csv           BG          2163\n",
      " checkpoint_ebird_PL_1885_obs.csv           PL          1885\n",
      " checkpoint_ebird_BA_1376_obs.csv           BA          1376\n",
      " checkpoint_ebird_BE_1355_obs.csv           BE          1355\n",
      "  checkpoint_ebird_BY_762_obs.csv           BY           762\n",
      "  checkpoint_ebird_NO_741_obs.csv           NO           741\n",
      "  checkpoint_ebird_AT_443_obs.csv           AT           443\n",
      "   checkpoint_ebird_AL_49_obs.csv           AL            49\n",
      "   checkpoint_ebird_AD_49_obs.csv           AD            49\n",
      "   checkpoint_ebird_MK_17_obs.csv           MK            17\n",
      "\n",
      "Total observations to combine: 233,802\n"
     ]
    }
   ],
   "source": [
    "# Display file loading summary\n",
    "print(\"\\nFile Loading Summary:\")\n",
    "print(files_df.to_string(index=False))\n",
    "print(f\"\\nTotal observations to combine: {files_df['Observations'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all dataframes...\n",
      "\n",
      "✓ Combined dataset created!\n",
      "  Total observations: 233,802\n",
      "  Total columns: 27\n",
      "  Memory usage: 245.76 MB\n"
     ]
    }
   ],
   "source": [
    "# Combine all dataframes\n",
    "print(\"Combining all dataframes...\")\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Combined dataset created!\")\n",
    "print(f\"  Total observations: {len(combined_df):,}\")\n",
    "print(f\"  Total columns: {len(combined_df.columns)}\")\n",
    "print(f\"  Memory usage: {combined_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of combined dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speciesCode</th>\n",
       "      <th>comName</th>\n",
       "      <th>sciName</th>\n",
       "      <th>locId</th>\n",
       "      <th>locName</th>\n",
       "      <th>obsDt</th>\n",
       "      <th>howMany</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>obsValid</th>\n",
       "      <th>obsReviewed</th>\n",
       "      <th>locationPrivate</th>\n",
       "      <th>subId</th>\n",
       "      <th>subnational1Code</th>\n",
       "      <th>subnational1Name</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>countryName</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>obsId</th>\n",
       "      <th>checklistId</th>\n",
       "      <th>presenceNoted</th>\n",
       "      <th>hasComments</th>\n",
       "      <th>hasRichMedia</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>subnational2Code</th>\n",
       "      <th>subnational2Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ruff</td>\n",
       "      <td>Ruff</td>\n",
       "      <td>Calidris pugnax</td>\n",
       "      <td>L10520598</td>\n",
       "      <td>AL-Lezhe-Rruga Fran Ivanaj (41.7645,19.5959)</td>\n",
       "      <td>2022-03-20 06:06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.764526</td>\n",
       "      <td>19.595883</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>S105198839</td>\n",
       "      <td>AL-08</td>\n",
       "      <td>Lezhë</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Shawn Waddoups</td>\n",
       "      <td>OBS1370222140</td>\n",
       "      <td>CL24952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Shawn</td>\n",
       "      <td>Waddoups</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gargan</td>\n",
       "      <td>Garganey</td>\n",
       "      <td>Spatula querquedula</td>\n",
       "      <td>L18325643</td>\n",
       "      <td>Syri i Sheganit</td>\n",
       "      <td>2022-03-31 09:03</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.272243</td>\n",
       "      <td>19.393377</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>S106012981</td>\n",
       "      <td>AL-10</td>\n",
       "      <td>Shkodër</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Erald Xeka</td>\n",
       "      <td>OBS1379856548</td>\n",
       "      <td>CL24952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Erald</td>\n",
       "      <td>Xeka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woosan</td>\n",
       "      <td>Wood Sandpiper</td>\n",
       "      <td>Tringa glareola</td>\n",
       "      <td>L18325643</td>\n",
       "      <td>Syri i Sheganit</td>\n",
       "      <td>2022-03-31 09:03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.272243</td>\n",
       "      <td>19.393377</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>S106012981</td>\n",
       "      <td>AL-10</td>\n",
       "      <td>Shkodër</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Erald Xeka</td>\n",
       "      <td>OBS1379876742</td>\n",
       "      <td>CL24952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Erald</td>\n",
       "      <td>Xeka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ruff</td>\n",
       "      <td>Ruff</td>\n",
       "      <td>Calidris pugnax</td>\n",
       "      <td>L18325643</td>\n",
       "      <td>Syri i Sheganit</td>\n",
       "      <td>2022-03-31 09:03</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.272243</td>\n",
       "      <td>19.393377</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>S106012981</td>\n",
       "      <td>AL-10</td>\n",
       "      <td>Shkodër</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Erald Xeka</td>\n",
       "      <td>OBS1379856546</td>\n",
       "      <td>CL24952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Erald</td>\n",
       "      <td>Xeka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ruff</td>\n",
       "      <td>Ruff</td>\n",
       "      <td>Calidris pugnax</td>\n",
       "      <td>L18326033</td>\n",
       "      <td>Liqeni Shkoder_Livade</td>\n",
       "      <td>2022-04-01 08:30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.064899</td>\n",
       "      <td>19.489323</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>S106014096</td>\n",
       "      <td>AL-10</td>\n",
       "      <td>Shkodër</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Erald Xeka</td>\n",
       "      <td>OBS1379885013</td>\n",
       "      <td>CL24952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Erald</td>\n",
       "      <td>Xeka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speciesCode         comName              sciName      locId                                       locName             obsDt  howMany        lat        lng  obsValid  obsReviewed  locationPrivate       subId subnational1Code subnational1Name countryCode countryName userDisplayName          obsId checklistId  presenceNoted  hasComments  hasRichMedia firstName  lastName subnational2Code subnational2Name\n",
       "0        ruff            Ruff      Calidris pugnax  L10520598  AL-Lezhe-Rruga Fran Ivanaj (41.7645,19.5959)  2022-03-20 06:06      2.0  41.764526  19.595883      True        False             True  S105198839            AL-08            Lezhë          AL     Albania  Shawn Waddoups  OBS1370222140     CL24952          False        False         False     Shawn  Waddoups              NaN              NaN\n",
       "1      gargan        Garganey  Spatula querquedula  L18325643                               Syri i Sheganit  2022-03-31 09:03     26.0  42.272243  19.393377      True         True            False  S106012981            AL-10          Shkodër          AL     Albania      Erald Xeka  OBS1379856548     CL24952          False        False         False     Erald      Xeka              NaN              NaN\n",
       "2      woosan  Wood Sandpiper      Tringa glareola  L18325643                               Syri i Sheganit  2022-03-31 09:03      7.0  42.272243  19.393377      True        False            False  S106012981            AL-10          Shkodër          AL     Albania      Erald Xeka  OBS1379876742     CL24952          False        False         False     Erald      Xeka              NaN              NaN\n",
       "3        ruff            Ruff      Calidris pugnax  L18325643                               Syri i Sheganit  2022-03-31 09:03     30.0  42.272243  19.393377      True         True            False  S106012981            AL-10          Shkodër          AL     Albania      Erald Xeka  OBS1379856546     CL24952          False        False         False     Erald      Xeka              NaN              NaN\n",
       "4        ruff            Ruff      Calidris pugnax  L18326033                         Liqeni Shkoder_Livade  2022-04-01 08:30     21.0  42.064899  19.489323      True        False            False  S106014096            AL-10          Shkodër          AL     Albania      Erald Xeka  OBS1379885013     CL24952          False        False         False     Erald      Xeka              NaN              NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of combined dataset:\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1357159 entries, 0 to 1357158\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   speciesCode       1357159 non-null  object \n",
      " 1   comName           1357159 non-null  object \n",
      " 2   sciName           1357159 non-null  object \n",
      " 3   locId             1357159 non-null  object \n",
      " 4   locName           1357159 non-null  object \n",
      " 5   obsDt             1357159 non-null  object \n",
      " 6   howMany           1206145 non-null  float64\n",
      " 7   lat               1357159 non-null  float64\n",
      " 8   lng               1357159 non-null  float64\n",
      " 9   obsValid          1357159 non-null  bool   \n",
      " 10  obsReviewed       1357159 non-null  bool   \n",
      " 11  locationPrivate   1357159 non-null  bool   \n",
      " 12  subId             1357159 non-null  object \n",
      " 13  subnational1Code  1357159 non-null  object \n",
      " 14  subnational1Name  1357159 non-null  object \n",
      " 15  countryCode       1357159 non-null  object \n",
      " 16  countryName       1357159 non-null  object \n",
      " 17  userDisplayName   1357149 non-null  object \n",
      " 18  obsId             1357159 non-null  object \n",
      " 19  checklistId       1357159 non-null  object \n",
      " 20  presenceNoted     1357159 non-null  bool   \n",
      " 21  hasComments       1357159 non-null  bool   \n",
      " 22  hasRichMedia      1357159 non-null  bool   \n",
      " 23  firstName         1357149 non-null  object \n",
      " 24  lastName          1357149 non-null  object \n",
      " 25  subnational2Code  472369 non-null   object \n",
      " 26  subnational2Name  472369 non-null   object \n",
      " 27  exoticCategory    2 non-null        object \n",
      "dtypes: bool(6), float64(3), object(19)\n",
      "memory usage: 235.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data structure\n",
    "print(\"\\nDataset Information:\")\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data preprocessing complete!\n",
      "\n",
      "Date range: 2022-01-01 08:17:00 to 2022-12-31 17:08:00\n",
      "Years covered: [2022]\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime\n",
    "combined_df['obsDt'] = pd.to_datetime(combined_df['obsDt'], errors='coerce')\n",
    "\n",
    "# Extract temporal features\n",
    "combined_df['year'] = combined_df['obsDt'].dt.year\n",
    "combined_df['month'] = combined_df['obsDt'].dt.month\n",
    "combined_df['day_of_week'] = combined_df['obsDt'].dt.dayofweek\n",
    "combined_df['day_of_year'] = combined_df['obsDt'].dt.dayofyear\n",
    "\n",
    "# Convert count to numeric\n",
    "combined_df['howMany'] = pd.to_numeric(combined_df['howMany'], errors='coerce')\n",
    "\n",
    "print(\"✓ Data preprocessing complete!\")\n",
    "print(f\"\\nDate range: {combined_df['obsDt'].min()} to {combined_df['obsDt'].max()}\")\n",
    "print(f\"Years covered: {sorted(combined_df['year'].dropna().unique().astype(int).tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OVERALL DATASET STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total observations: 233,802\n",
      "Number of countries: 33\n",
      "Number of unique species: 8\n",
      "Number of unique locations: 5564\n",
      "Number of observers: 3070\n",
      "Number of checklists: 13599\n",
      "Number of subnational regions: 414\n",
      "\n",
      "Observations with count data: 215,818 (92.3%)\n",
      "Total birds counted: 2,719,680\n",
      "Average count per observation: 12.60\n",
      "Median count: 2\n",
      "Maximum count in single observation: 4,700\n",
      "Minimum count: 1\n"
     ]
    }
   ],
   "source": [
    "# Overall statistics\n",
    "print(\"=\"*80)\n",
    "print(\"OVERALL DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal observations: {len(combined_df):,}\")\n",
    "print(f\"Number of countries: {combined_df['countryCode'].nunique()}\")\n",
    "print(f\"Number of unique species: {combined_df['speciesCode'].nunique()}\")\n",
    "print(f\"Number of unique locations: {combined_df['locId'].nunique()}\")\n",
    "print(f\"Number of observers: {combined_df['userDisplayName'].nunique()}\")\n",
    "print(f\"Number of checklists: {combined_df['subId'].nunique()}\")\n",
    "print(f\"Number of subnational regions: {combined_df['subnational1Code'].nunique()}\")\n",
    "\n",
    "# Count data statistics\n",
    "count_data = combined_df[combined_df['howMany'].notna()]\n",
    "print(f\"\\nObservations with count data: {len(count_data):,} ({len(count_data)/len(combined_df)*100:.1f}%)\")\n",
    "if len(count_data) > 0:\n",
    "    print(f\"Total birds counted: {count_data['howMany'].sum():,.0f}\")\n",
    "    print(f\"Average count per observation: {count_data['howMany'].mean():.2f}\")\n",
    "    print(f\"Median count: {count_data['howMany'].median():.0f}\")\n",
    "    print(f\"Maximum count in single observation: {count_data['howMany'].max():,.0f}\")\n",
    "    print(f\"Minimum count: {count_data['howMany'].min():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STATISTICS BY COUNTRY\n",
      "========================================================================================================================\n",
      "Country Code           Country Name  Total Observations  Species Count  Unique Locations  Number of Observers  Checklists  Total Birds Counted\n",
      "          FR                 France               24208              8               706                  422        1267             342400.0\n",
      "          DE                Germany               19260              8               493                  313        1035             198330.0\n",
      "          BG               Bulgaria               18101              8               144                  106         535             189336.0\n",
      "          CZ         Czech Republic               16580              8               230                  137         656              63820.0\n",
      "          BE                Belgium               14825              8               199                  116         487              72575.0\n",
      "          DK                Denmark               14630              8               245                  140         596             406657.0\n",
      "          GR                 Greece               14462              8               203                  194         707             148624.0\n",
      "          FI                Finland               13039              8               297                  143         610             138924.0\n",
      "          AT                Austria               10638              8                99                  101         273             163269.0\n",
      "          IT                  Italy               10580              8               341                  216         798              96760.0\n",
      "          PT               Portugal               10150              8               455                  379        1587              56800.0\n",
      "          CY                 Cyprus                9198              7                64                   84         287             182931.0\n",
      "          BY                Belarus                8294              8               104                   38         216              54418.0\n",
      "          HR                Croatia                6864              8                76                   59         236              41426.0\n",
      "          PL                 Poland                6864              8               347                  175         879              65928.0\n",
      "          IE                Ireland                6820              8               178                  124         542             194920.0\n",
      "          HU                Hungary                6812              8               156                  101         337             107926.0\n",
      "          NO                 Norway                5068              8               300                  179         590              27489.0\n",
      "          EE                Estonia                4356              8                96                   55         183              34488.0\n",
      "          IS                Iceland                2724              6               126                   97         217              36900.0\n",
      "          LT              Lithuania                1902              8               113                   26         242              23520.0\n",
      "          RU                 Russia                1881              8               227                  112         424              21813.0\n",
      "          AL                Albania                1421              8                23                   21          32              10527.0\n",
      "          LV                 Latvia                1304              8                71                   34         108               8160.0\n",
      "          RO                Romania                1136              8                90                   62         180              14540.0\n",
      "          XK                 Kosovo                 612              6                 5                    2          49               4068.0\n",
      "          BA Bosnia and Herzegovina                 504              6                14                    8          16               1176.0\n",
      "          MT                  Malta                 464              7                24                   21          79               1332.0\n",
      "          MD                Moldova                 450              6                56                   14          91               5646.0\n",
      "          RS                 Serbia                 408              8                59                   44         286               3647.0\n",
      "          MK        North Macedonia                 136              4                 5                    7          13                488.0\n",
      "          LU             Luxembourg                  60              3                 5                    8          12                 80.0\n",
      "          ME             Montenegro                  51              7                13                   19          29                762.0\n"
     ]
    }
   ],
   "source": [
    "# Country-level statistics\n",
    "country_stats = combined_df.groupby(['countryCode', 'countryName']).agg({\n",
    "    'obsId': 'count',\n",
    "    'speciesCode': 'nunique',\n",
    "    'locId': 'nunique',\n",
    "    'userDisplayName': 'nunique',\n",
    "    'subId': 'nunique',\n",
    "    'howMany': lambda x: x.sum() if x.notna().any() else 0\n",
    "}).reset_index()\n",
    "\n",
    "country_stats.columns = ['Country Code', 'Country Name', 'Total Observations', \n",
    "                         'Species Count', 'Unique Locations', 'Number of Observers',\n",
    "                         'Checklists', 'Total Birds Counted']\n",
    "\n",
    "country_stats = country_stats.sort_values('Total Observations', ascending=False)\n",
    "\n",
    "print(\"\\nSTATISTICS BY COUNTRY\")\n",
    "print(\"=\"*120)\n",
    "print(country_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COUNTRY SUMMARY STATISTICS\n",
      "============================================================\n",
      "Average observations per country: 28,876\n",
      "Median observations per country: 13,992\n",
      "Country with most observations: Czech Republic (94,816)\n",
      "Country with most species: Czech Republic (13)\n",
      "Country with most observers: United Kingdom (1208)\n"
     ]
    }
   ],
   "source": [
    "# Country summary statistics\n",
    "print(\"\\nCOUNTRY SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average observations per country: {country_stats['Total Observations'].mean():,.0f}\")\n",
    "print(f\"Median observations per country: {country_stats['Total Observations'].median():,.0f}\")\n",
    "print(f\"Country with most observations: {country_stats.iloc[0]['Country Name']} ({country_stats.iloc[0]['Total Observations']:,})\")\n",
    "print(f\"Country with most species: {country_stats.sort_values('Species Count', ascending=False).iloc[0]['Country Name']} ({country_stats.sort_values('Species Count', ascending=False).iloc[0]['Species Count']})\")\n",
    "print(f\"Country with most observers: {country_stats.sort_values('Number of Observers', ascending=False).iloc[0]['Country Name']} ({country_stats.sort_values('Number of Observers', ascending=False).iloc[0]['Number of Observers']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Species Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 30 MOST OBSERVED SPECIES\n",
      "========================================================================================================================\n",
      "Species Code           Common Name            Scientific Name  Total Observations  Countries Found  Locations  Total Count\n",
      "     gretit1             Great Tit                Parus major              220891               45       7766     671706.0\n",
      "      houspa         House Sparrow          Passer domesticus              196908               44       6840    1573226.0\n",
      "      eursta     European Starling           Sturnus vulgaris              195739               47       6876   29714098.0\n",
      "     blackc1     Eurasian Blackcap         Sylvia atricapilla              133310               46       5150     252393.0\n",
      "      barswa          Barn Swallow            Hirundo rustica              131782               46       5337    1746223.0\n",
      "      eurbul    Eurasian Bullfinch          Pyrrhula pyrrhula              119298               39       4744     276323.0\n",
      "      comcra          Common Crane                  Grus grus               72520               37       2868   10605371.0\n",
      "     tawowl1             Tawny Owl                Strix aluco               65041               38       2772      80956.0\n",
      "     sedwar1         Sedge Warbler Acrocephalus schoenobaenus               63592               41       2199     128612.0\n",
      "     whtdip1 White-throated Dipper            Cinclus cinclus               62396               40       2678      90035.0\n",
      "     garwar1        Garden Warbler               Sylvia borin               51011               44       2198     117246.0\n",
      "      arcter           Arctic Tern          Sterna paradisaea               22542               21        962     228903.0\n",
      "     eurnig1     Eurasian Nightjar      Caprimulgus europaeus               22129               37       1193      33583.0\n"
     ]
    }
   ],
   "source": [
    "# Species statistics\n",
    "species_stats = combined_df.groupby(['speciesCode', 'comName', 'sciName']).agg({\n",
    "    'obsId': 'count',\n",
    "    'countryCode': 'nunique',\n",
    "    'locId': 'nunique',\n",
    "    'howMany': lambda x: x.sum() if x.notna().any() else 0\n",
    "}).reset_index()\n",
    "\n",
    "species_stats.columns = ['Species Code', 'Common Name', 'Scientific Name', \n",
    "                        'Total Observations', 'Countries Found', 'Locations', 'Total Count']\n",
    "\n",
    "species_stats = species_stats.sort_values('Total Observations', ascending=False)\n",
    "\n",
    "print(\"\\nTOP 30 MOST OBSERVED SPECIES\")\n",
    "print(\"=\"*120)\n",
    "print(species_stats.head(30).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPECIES DIVERSITY ANALYSIS\n",
      "============================================================\n",
      "Total unique species: 13\n",
      "\n",
      "Species distribution:\n",
      "  Species found in 1 country only: 0\n",
      "  Species found in 2-5 countries: 0\n",
      "  Species found in 6-10 countries: 0\n",
      "  Species found in 11+ countries: 13\n",
      "\n",
      "Most widespread species: European Starling (found in 47 countries)\n"
     ]
    }
   ],
   "source": [
    "# Species diversity analysis\n",
    "print(\"\\nSPECIES DIVERSITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total unique species: {len(species_stats)}\")\n",
    "print(f\"\\nSpecies distribution:\")\n",
    "print(f\"  Species found in 1 country only: {(species_stats['Countries Found'] == 1).sum()}\")\n",
    "print(f\"  Species found in 2-5 countries: {((species_stats['Countries Found'] >= 2) & (species_stats['Countries Found'] <= 5)).sum()}\")\n",
    "print(f\"  Species found in 6-10 countries: {((species_stats['Countries Found'] >= 6) & (species_stats['Countries Found'] <= 10)).sum()}\")\n",
    "print(f\"  Species found in 11+ countries: {(species_stats['Countries Found'] >= 11).sum()}\")\n",
    "print(f\"\\nMost widespread species: {species_stats.sort_values('Countries Found', ascending=False).iloc[0]['Common Name']} (found in {species_stats.sort_values('Countries Found', ascending=False).iloc[0]['Countries Found']} countries)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEMPORAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Observations by Year:\n",
      "  2022: 226,195\n",
      "\n",
      "Observations by Month:\n",
      "  January: 5,128\n",
      "  February: 4,456\n",
      "  March: 14,485\n",
      "  April: 31,147\n",
      "  May: 33,637\n",
      "  June: 11,622\n",
      "  July: 23,868\n",
      "  August: 35,932\n",
      "  September: 37,577\n",
      "  October: 18,868\n",
      "  November: 5,049\n",
      "  December: 4,426\n",
      "\n",
      "Peak observation month: September (37,577 observations)\n"
     ]
    }
   ],
   "source": [
    "# Temporal distribution\n",
    "print(\"\\nTEMPORAL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# By year\n",
    "yearly_obs = combined_df.groupby('year').size().sort_index()\n",
    "print(\"\\nObservations by Year:\")\n",
    "for year, count in yearly_obs.items():\n",
    "    if pd.notna(year):\n",
    "        print(f\"  {int(year)}: {count:,}\")\n",
    "\n",
    "# By month\n",
    "monthly_obs = combined_df.groupby('month').size().sort_index()\n",
    "month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',\n",
    "               7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "print(\"\\nObservations by Month:\")\n",
    "for month, count in monthly_obs.items():\n",
    "    if pd.notna(month):\n",
    "        print(f\"  {month_names[int(month)]}: {count:,}\")\n",
    "\n",
    "# Peak observation period\n",
    "peak_month = monthly_obs.idxmax()\n",
    "if pd.notna(peak_month):\n",
    "    print(f\"\\nPeak observation month: {month_names[int(peak_month)]} ({monthly_obs.max():,} observations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GEOGRAPHIC DISTRIBUTION\n",
      "============================================================\n",
      "Latitude range: 32.7232° to 73.1523°\n",
      "Longitude range: -31.1162° to 158.8483°\n",
      "\n",
      "Latitude statistics:\n",
      "  Mean: 48.7235°\n",
      "  Median: 48.7832°\n",
      "\n",
      "Longitude statistics:\n",
      "  Mean: 13.8526°\n",
      "  Median: 14.4400°\n"
     ]
    }
   ],
   "source": [
    "# Geographic distribution\n",
    "print(\"\\nGEOGRAPHIC DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Latitude range: {combined_df['lat'].min():.4f}° to {combined_df['lat'].max():.4f}°\")\n",
    "print(f\"Longitude range: {combined_df['lng'].min():.4f}° to {combined_df['lng'].max():.4f}°\")\n",
    "print(f\"\\nLatitude statistics:\")\n",
    "print(f\"  Mean: {combined_df['lat'].mean():.4f}°\")\n",
    "print(f\"  Median: {combined_df['lat'].median():.4f}°\")\n",
    "print(f\"\\nLongitude statistics:\")\n",
    "print(f\"  Mean: {combined_df['lng'].mean():.4f}°\")\n",
    "print(f\"  Median: {combined_df['lng'].median():.4f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bird Species Reference Analysis\n",
    "\n",
    "This section connects the observation data with a reference list of bird species to identify:\n",
    "1. Which species from the reference list were not spotted\n",
    "2. Urban vs countryside sighting patterns\n",
    "3. Migration patterns by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bird species reference file loaded successfully!\n",
      "\n",
      "Reference file contains 14 rows\n",
      "\n",
      "Columns: ['Bird Species (Autumn migratory)', 'eBird Code', 'Migration Period', 'Migration Group', 'Status', 'Why they are in Europe']\n"
     ]
    }
   ],
   "source": [
    "# Load the bird species reference file\n",
    "# UPDATE THIS PATH if your Excel file is in a different location\n",
    "reference_file = '/Users/dazedinthecity/Documents/GitHub/ceu-ds-project-groupB-2026/datasets/bird_species_new_add.xlsx'  # Change as needed\n",
    "\n",
    "try:\n",
    "    bird_reference = pd.read_excel(reference_file)\n",
    "    print(\"✓ Bird species reference file loaded successfully!\")\n",
    "    print(f\"\\nReference file contains {len(bird_reference)} rows\")\n",
    "    print(f\"\\nColumns: {bird_reference.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find '{reference_file}'\")\n",
    "    print(\"Please update the reference_file path in the cell above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total species in reference list: 14\n",
      "\n",
      "Migration groups:\n",
      "Migration Group\n",
      "Nocturnal              6\n",
      "Diurnal                3\n",
      "Nocturnal / Diurnal    3\n",
      "Nocturnal & Diurnal    1\n",
      "Migration Group        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few entries:\n",
      "                      Bird Species  eBird Code      Migration Group\n",
      "0                         Whimbrel      whimbr  Nocturnal & Diurnal\n",
      "1                     Little Stint      litsti            Nocturnal\n",
      "2                 Curlew Sandpiper      cursan            Nocturnal\n",
      "3                  Green Sandpiper      gresan            Nocturnal\n",
      "4                       Black Tern      blater              Diurnal\n",
      "5                    Honey Buzzard     eurhob1              Diurnal\n",
      "6  Bird Species (Spring migratory)  eBird Code      Migration Group\n",
      "7                         Red Knot      redkno  Nocturnal / Diurnal\n",
      "8                             Ruff        ruff  Nocturnal / Diurnal\n",
      "9                         Garganey      gargan            Nocturnal\n"
     ]
    }
   ],
   "source": [
    "# Clean and prepare the reference data\n",
    "# Remove group header rows (those without eBird codes)\n",
    "bird_reference_clean = bird_reference[bird_reference['eBird Code'].notna()].copy()\n",
    "\n",
    "# Standardize column names\n",
    "bird_reference_clean.columns = ['Bird Species', 'eBird Code','Migration Period','Migration Group', 'Status', 'Trend Summary']\n",
    "\n",
    "print(f\"Total species in reference list: {len(bird_reference_clean)}\")\n",
    "print(f\"\\nMigration groups:\")\n",
    "print(bird_reference_clean['Migration Group'].value_counts())\n",
    "print(f\"\\nFirst few entries:\")\n",
    "print(bird_reference_clean[['Bird Species', 'eBird Code', 'Migration Group']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Unspotted Species Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNSPOTTED SPECIES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Total species in reference list: 14\n",
      "Species spotted: 8 (57.1%)\n",
      "Species NOT spotted: 6 (42.9%)\n",
      "\n",
      "UNSPOTTED SPECIES:\n",
      "--------------------------------------------------------------------------------\n",
      "                   Bird Species eBird Code     Migration Group          Status\n",
      "                       Whimbrel     whimbr Nocturnal & Diurnal           Amber\n",
      "                Green Sandpiper     gresan           Nocturnal           Green\n",
      "                     Black Tern     blater             Diurnal           Amber\n",
      "                  Honey Buzzard    eurhob1             Diurnal           Amber\n",
      "Bird Species (Spring migratory) eBird Code     Migration Group Regional Status\n",
      "                    Grey Plover     greypl           Nocturnal           Amber\n",
      "\n",
      "Unspotted species by migration group:\n",
      "Migration Group\n",
      "Nocturnal              2\n",
      "Diurnal                2\n",
      "Nocturnal & Diurnal    1\n",
      "Migration Group        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "SPOTTED SPECIES:\n",
      "--------------------------------------------------------------------------------\n",
      "    Bird Species eBird Code     Migration Group             Status\n",
      "    Little Stint     litsti           Nocturnal              Green\n",
      "Curlew Sandpiper     cursan           Nocturnal                 VU\n",
      "        Red Knot     redkno Nocturnal / Diurnal    VU (Vulnerable)\n",
      "            Ruff       ruff Nocturnal / Diurnal    VU (Vulnerable)\n",
      "        Garganey     gargan           Nocturnal              Amber\n",
      "  Wood Sandpiper     woosan           Nocturnal              Green\n",
      "          Osprey     osprey             Diurnal Green / Recovering\n",
      "      Sanderling     sander Nocturnal / Diurnal              Green\n"
     ]
    }
   ],
   "source": [
    "# Find which species from the reference list were NOT spotted\n",
    "reference_species_codes = set(bird_reference_clean['eBird Code'].str.lower())\n",
    "observed_species_codes = set(combined_df['speciesCode'].str.lower())\n",
    "\n",
    "unspotted_codes = reference_species_codes - observed_species_codes\n",
    "spotted_codes = reference_species_codes & observed_species_codes\n",
    "\n",
    "# Get details of unspotted species\n",
    "unspotted_species = bird_reference_clean[\n",
    "    bird_reference_clean['eBird Code'].str.lower().isin(unspotted_codes)\n",
    "].copy()\n",
    "\n",
    "spotted_species = bird_reference_clean[\n",
    "    bird_reference_clean['eBird Code'].str.lower().isin(spotted_codes)\n",
    "].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UNSPOTTED SPECIES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal species in reference list: {len(bird_reference_clean)}\")\n",
    "print(f\"Species spotted: {len(spotted_species)} ({len(spotted_species)/len(bird_reference_clean)*100:.1f}%)\")\n",
    "print(f\"Species NOT spotted: {len(unspotted_species)} ({len(unspotted_species)/len(bird_reference_clean)*100:.1f}%)\")\n",
    "\n",
    "if len(unspotted_species) > 0:\n",
    "    print(f\"\\nUNSPOTTED SPECIES:\")\n",
    "    print(\"-\"*80)\n",
    "    print(unspotted_species[['Bird Species', 'eBird Code', 'Migration Group', 'Status']].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nUnspotted species by migration group:\")\n",
    "    print(unspotted_species['Migration Group'].value_counts())\n",
    "else:\n",
    "    print(\"\\n✓ All reference species were spotted!\")\n",
    "\n",
    "print(f\"\\n\\nSPOTTED SPECIES:\")\n",
    "print(\"-\"*80)\n",
    "print(spotted_species[['Bird Species', 'eBird Code', 'Migration Group', 'Status']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Location Type Analysis: Forest, Countryside, and City Centre\n",
    "\n",
    "This analysis uses geographic coordinates to categorize observations into three habitat types:\n",
    "- **City Centre**: Urban areas including capitals, major cities, towns, and villages\n",
    "- **Countryside**: Agricultural lands, rural areas, and open habitats\n",
    "- **Forest**: Woodlands, forested areas, mountain regions, and protected natural areas\n",
    "\n",
    "**Note**: This analysis uses a combination of:\n",
    "1. Location name keywords for protected areas and natural landmarks\n",
    "2. Population density heuristics based on proximity to populated places\n",
    "3. Elevation and geographic features to identify forested/mountainous areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subnation1Code'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Rank subnations by species sightings for each country\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Group by country, species, and subnation to count observations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m species_subnation_rankings = \u001b[43mcombined_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcountryCode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mspeciesCode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msubnation1Code\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msubnationName\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m.size().reset_index(name=\u001b[33m'\u001b[39m\u001b[33msightings\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Rank subnations within each country-species combination\u001b[39;00m\n\u001b[32m      8\u001b[39m species_subnation_rankings[\u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m] = species_subnation_rankings.groupby(\n\u001b[32m      9\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mcountryCode\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mspeciesCode\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m )[\u001b[33m'\u001b[39m\u001b[33msightings\u001b[39m\u001b[33m'\u001b[39m].rank(method=\u001b[33m'\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/da/lib/python3.14/site-packages/pandas/core/frame.py:9210\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9213\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9216\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/da/lib/python3.14/site-packages/pandas/core/groupby/groupby.py:1331\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1328\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/da/lib/python3.14/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'subnation1Code'"
     ]
    }
   ],
   "source": [
    "# Rank subnations by species sightings for each country\n",
    "# Group by country, species, and subnation to count observations\n",
    "species_subnation_rankings = combined_df.groupby(\n",
    "    ['countryCode', 'speciesCode', 'subnation1Code', 'subnationName']\n",
    ").size().reset_index(name='sightings')\n",
    "\n",
    "# Rank subnations within each country-species combination\n",
    "species_subnation_rankings['rank'] = species_subnation_rankings.groupby(\n",
    "    ['countryCode', 'speciesCode']\n",
    ")['sightings'].rank(method='dense', ascending=False).astype(int)\n",
    "\n",
    "# Sort for better readability\n",
    "species_subnation_rankings = species_subnation_rankings.sort_values(\n",
    "    ['countryCode', 'speciesCode', 'rank']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Display sample results\n",
    "print(\"Sample Rankings (showing top-ranked subnations for each country-species pair):\")\n",
    "print(\"\\nFirst 20 rows:\")\n",
    "print(species_subnation_rankings.head(20))\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total country-species-subnation combinations: {len(species_subnation_rankings):,}\")\n",
    "print(f\"Countries analyzed: {species_subnation_rankings['countryCode'].nunique()}\")\n",
    "print(f\"Species analyzed: {species_subnation_rankings['speciesCode'].nunique()}\")\n",
    "print(f\"Subnations analyzed: {species_subnation_rankings['subnation1Code'].nunique()}\")\n",
    "\n",
    "# Example: Show top 3 subnations for a specific country and species\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Example - Top 3 subnations in Italy (IT) for a specific species:\")\n",
    "sample_species = species_subnation_rankings[species_subnation_rankings['countryCode'] == 'IT']['speciesCode'].iloc[0]\n",
    "italy_example = species_subnation_rankings[\n",
    "    (species_subnation_rankings['countryCode'] == 'IT') & \n",
    "    (species_subnation_rankings['speciesCode'] == sample_species) &\n",
    "    (species_subnation_rankings['rank'] <= 3)\n",
    "]\n",
    "print(f\"\\nSpecies: {sample_species}\")\n",
    "print(italy_example[['rank', 'subnation1Code', 'subnationName', 'sightings']])\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'species_subnation_rankings_by_country.csv'\n",
    "species_subnation_rankings.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"\\n✓ Rankings saved to: {output_file}\")\n",
    "print(f\"  Columns: countryCode, speciesCode, subnation1Code, subnationName, sightings, rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Migration Pattern Analysis by Season\n",
    "\n",
    "Analyzing bird sightings based on migration groups across different seasonal periods:\n",
    "- **Spring Migration Period**: Mid-March to Mid-June\n",
    "- **Summer Period**: July to Early August\n",
    "- **Autumn Migration Period**: Late August to Early December  \n",
    "- **Winter Period**: Late December to Early March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migration group distribution in observations:\n",
      "migration_category\n",
      "S    188354\n",
      "F     45448\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# First, map migration groups to our observation data\n",
    "# Create a mapping dictionary from the reference file\n",
    "migration_map = dict(zip(\n",
    "    bird_reference_clean['eBird Code'].str.lower(),\n",
    "    bird_reference_clean['Migration Period']\n",
    "))\n",
    "\n",
    "# Map migration groups to observations\n",
    "combined_df['migration_group'] = combined_df['speciesCode'].str.lower().map(migration_map)\n",
    "\n",
    "# Classify migration groups into detailed categories\n",
    "# Split Autumn Migrants into Nocturnal and Diurnal\n",
    "def classify_migration(migration_group):\n",
    "    if pd.isna(migration_group):\n",
    "        return 'Not in Reference'\n",
    "    elif migration_group == 'Resident':\n",
    "        return 'Native (Resident)'\n",
    "    elif migration_group == 'Nocturnal':\n",
    "        return 'Autumn Migrant (Nocturnal)'\n",
    "    elif migration_group == 'Diurnal':\n",
    "        return 'Autumn Migrant (Diurnal)'\n",
    "    elif migration_group == 'Spring Arrival':\n",
    "        return 'Spring Migrant'\n",
    "    else:\n",
    "        return migration_group\n",
    "\n",
    "combined_df['migration_category'] = combined_df['migration_group'].apply(classify_migration)\n",
    "\n",
    "print(\"Migration group distribution in observations:\")\n",
    "print(combined_df['migration_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations by season:\n",
      "  Spring Migration (Mid-Mar to Mid-Jun): 81,157 observations\n",
      "  Autumn Migration (Late Aug to Early Dec): 76,975 observations\n",
      "  Summer (Jul to Early Aug): 45,720 observations\n",
      "  Winter (Late Dec to Early Mar): 22,343 observations\n",
      "  Unknown: 7,607 observations\n"
     ]
    }
   ],
   "source": [
    "# Define seasonal periods\n",
    "def get_season(date):\n",
    "    \"\"\"\n",
    "    Classify observation date into seasonal periods.\n",
    "    \"\"\"\n",
    "    if pd.isna(date):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    \n",
    "    # Spring Migration: Mid-March (Mar 15) to Mid-June (Jun 15)\n",
    "    if (month == 3 and day >= 15) or (month in [4, 5]) or (month == 6 and day <= 15):\n",
    "        return 'Spring Migration (Mid-Mar to Mid-Jun)'\n",
    "    \n",
    "    # Summer: July and Early August (to Aug 20)\n",
    "    elif month == 7 or (month == 8 and day <= 20):\n",
    "        return 'Summer (Jul to Early Aug)'\n",
    "    \n",
    "    # Autumn Migration: Late August (Aug 21) to Early December (Dec 10)\n",
    "    elif (month == 8 and day > 20) or (month in [9, 10, 11]) or (month == 12 and day <= 10):\n",
    "        return 'Autumn Migration (Late Aug to Early Dec)'\n",
    "    \n",
    "    # Winter: Late December (Dec 11+) to Early March (Mar 14)\n",
    "    else:  # (month == 12 and day > 10) or (month in [1, 2]) or (month == 3 and day < 15)\n",
    "        return 'Winter (Late Dec to Early Mar)'\n",
    "\n",
    "# Apply seasonal classification\n",
    "combined_df['season'] = combined_df['obsDt'].apply(get_season)\n",
    "\n",
    "print(\"Observations by season:\")\n",
    "season_counts = combined_df['season'].value_counts()\n",
    "for season, count in season_counts.items():\n",
    "    print(f\"  {season}: {count:,} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "MIGRATION PATTERN ANALYSIS BY SEASON\n",
      "====================================================================================================\n",
      "\n",
      "Observations by Migration Group and Season:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "season              Autumn Migration (Late Aug to Early Dec)  Spring Migration (Mid-Mar to Mid-Jun)  Summer (Jul to Early Aug)  Unknown  Winter (Late Dec to Early Mar)     All\n",
      "migration_category                                                                                                                                                             \n",
      "F                                                      20662                                  12198                       8230     1708                            2650   45448\n",
      "S                                                      56313                                  68959                      37490     5899                           19693  188354\n",
      "All                                                    76975                                  81157                      45720     7607                           22343  233802\n",
      "\n",
      "\n",
      "Percentage distribution within each migration group:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "season              Autumn Migration (Late Aug to Early Dec)  Spring Migration (Mid-Mar to Mid-Jun)  Summer (Jul to Early Aug)  Unknown  Winter (Late Dec to Early Mar)\n",
      "migration_category                                                                                                                                                     \n",
      "F                                                       45.5                                   26.8                       18.1      3.8                             5.8\n",
      "S                                                       29.9                                   36.6                       19.9      3.1                            10.5\n"
     ]
    }
   ],
   "source": [
    "# Create cross-tabulation of migration groups vs seasons\n",
    "print(\"=\"*100)\n",
    "print(\"MIGRATION PATTERN ANALYSIS BY SEASON\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Filter to only include birds in the reference list\n",
    "reference_obs = combined_df[combined_df['migration_category'] != 'Not in Reference'].copy()\n",
    "\n",
    "migration_season_crosstab = pd.crosstab(\n",
    "    reference_obs['migration_category'],\n",
    "    reference_obs['season'],\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(\"\\nObservations by Migration Group and Season:\")\n",
    "print(\"-\"*100)\n",
    "print(migration_season_crosstab)\n",
    "\n",
    "# Calculate percentages\n",
    "print(\"\\n\\nPercentage distribution within each migration group:\")\n",
    "print(\"-\"*100)\n",
    "migration_season_pct = pd.crosstab(\n",
    "    reference_obs['migration_category'],\n",
    "    reference_obs['season'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "print(migration_season_pct.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "DETAILED SEASONAL ANALYSIS BY MIGRATION GROUP\n",
      "====================================================================================================\n",
      "\n",
      "NATIVE (RESIDENT)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "No observations found for Native (Resident)\n",
      "\n",
      "AUTUMN MIGRANT (NOCTURNAL)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "No observations found for Autumn Migrant (Nocturnal)\n",
      "\n",
      "AUTUMN MIGRANT (DIURNAL)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "No observations found for Autumn Migrant (Diurnal)\n",
      "\n",
      "SPRING MIGRANT\n",
      "----------------------------------------------------------------------------------------------------\n",
      "No observations found for Spring Migrant\n"
     ]
    }
   ],
   "source": [
    "# Detailed analysis for each migration category\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"DETAILED SEASONAL ANALYSIS BY MIGRATION GROUP\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for migration_cat in ['Native (Resident)', 'Autumn Migrant (Nocturnal)', 'Autumn Migrant (Diurnal)', 'Spring Migrant']:\n",
    "    print(f\"\\n{migration_cat.upper()}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    category_data = reference_obs[reference_obs['migration_category'] == migration_cat]\n",
    "    \n",
    "    if len(category_data) > 0:\n",
    "        print(f\"Total observations: {len(category_data):,}\")\n",
    "        print(f\"Number of species: {category_data['speciesCode'].nunique()}\")\n",
    "        \n",
    "        # Seasonal breakdown\n",
    "        seasonal_breakdown = category_data.groupby('season').agg({\n",
    "            'obsId': 'count',\n",
    "            'speciesCode': 'nunique'\n",
    "        }).reset_index()\n",
    "        seasonal_breakdown.columns = ['Season', 'Observations', 'Species Count']\n",
    "        seasonal_breakdown['Percentage'] = (seasonal_breakdown['Observations'] / len(category_data) * 100).round(1)\n",
    "        \n",
    "        print(\"\\nSeasonal distribution:\")\n",
    "        print(seasonal_breakdown.to_string(index=False))\n",
    "        \n",
    "        # Top species in this category\n",
    "        top_species = category_data.groupby(['comName']).size().reset_index(name='Observations')\n",
    "        top_species = top_species.sort_values('Observations', ascending=False).head(5)\n",
    "        print(f\"\\nTop 5 species in this group:\")\n",
    "        print(top_species.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"No observations found for {migration_cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Migration Pattern Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for migration patterns\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Habitat type distribution\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "habitat_data = combined_df[combined_df['habitat_type'] != 'Unknown']['habitat_type'].value_counts()\n",
    "colors_habitat = ['#3498db', '#2ecc71', '#8B4513']\n",
    "ax1.pie(habitat_data.values, labels=habitat_data.index, autopct='%1.1f%%',\n",
    "        colors=colors_habitat, startangle=90)\n",
    "ax1.set_title('Habitat Type Distribution', fontweight='bold', fontsize=12)\n",
    "\n",
    "# 2. Species spotted vs unspotted\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "spotted_data = pd.Series({\n",
    "    'Spotted': len(spotted_species),\n",
    "    'Not Spotted': len(unspotted_species)\n",
    "})\n",
    "colors_spot = ['#2ecc71', '#e74c3c']\n",
    "ax2.pie(spotted_data.values, labels=spotted_data.index, autopct='%1.1f%%',\n",
    "        colors=colors_spot, startangle=90)\n",
    "ax2.set_title('Reference Species: Spotted vs Unspotted', fontweight='bold', fontsize=12)\n",
    "\n",
    "# 3. Migration groups distribution\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "migration_dist = reference_obs['migration_category'].value_counts()\n",
    "colors_mig = ['#3498db', '#e67e22', '#f39c12', '#9b59b6']\n",
    "ax3.bar(range(len(migration_dist)), migration_dist.values, color=colors_mig[:len(migration_dist)], alpha=0.7)\n",
    "ax3.set_xticks(range(len(migration_dist)))\n",
    "ax3.set_xticklabels([label.replace('Autumn Migrant ', 'Autumn\\n').replace(' (', '\\n(') \n",
    "                      for label in migration_dist.index], rotation=0, ha='center', fontsize=9)\n",
    "ax3.set_ylabel('Number of Observations')\n",
    "ax3.set_title('Observations by Migration Category', fontweight='bold', fontsize=12)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Seasonal observations by migration group (stacked bar)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "season_order = ['Spring Migration (Mid-Mar to Mid-Jun)', 'Summer (Jul to Early Aug)',\n",
    "                'Autumn Migration (Late Aug to Early Dec)', 'Winter (Late Dec to Early Mar)']\n",
    "migration_categories = ['Native (Resident)', 'Autumn Migrant (Nocturnal)', \n",
    "                       'Autumn Migrant (Diurnal)', 'Spring Migrant']\n",
    "\n",
    "# Prepare data for stacked bar chart\n",
    "season_data_dict = {cat: [] for cat in migration_categories}\n",
    "for season in season_order:\n",
    "    if season in reference_obs['season'].values:\n",
    "        for cat in migration_categories:\n",
    "            count = len(reference_obs[(reference_obs['season'] == season) & \n",
    "                                     (reference_obs['migration_category'] == cat)])\n",
    "            season_data_dict[cat].append(count)\n",
    "    else:\n",
    "        for cat in migration_categories:\n",
    "            season_data_dict[cat].append(0)\n",
    "\n",
    "x = range(len(season_order))\n",
    "width = 0.6\n",
    "bottom = [0] * len(season_order)\n",
    "colors_migration = ['#3498db', '#e67e22', '#f39c12', '#9b59b6']\n",
    "\n",
    "for i, cat in enumerate(migration_categories):\n",
    "    if any(season_data_dict[cat]):  # Only plot if there's data\n",
    "        label = cat.replace('Autumn Migrant ', 'Autumn ').replace(' (', ' (')\n",
    "        ax4.bar(x, season_data_dict[cat], width, label=label, bottom=bottom, \n",
    "                color=colors_migration[i], alpha=0.8)\n",
    "        bottom = [b + v for b, v in zip(bottom, season_data_dict[cat])]\n",
    "\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(['Spring\\nMigration', 'Summer', 'Autumn\\nMigration', 'Winter'], fontsize=9)\n",
    "ax4.set_ylabel('Number of Observations')\n",
    "ax4.set_title('Seasonal Observations by Migration Group', fontweight='bold', fontsize=12)\n",
    "ax4.legend(fontsize=8, loc='upper left')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Top species in city centres\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "if 'City Centre' in combined_df['habitat_type'].values:\n",
    "    city_top = combined_df[combined_df['habitat_type'] == 'City Centre'].groupby('comName').size().sort_values(ascending=False).head(10)\n",
    "    ax5.barh(range(len(city_top)), city_top.values, color='steelblue', alpha=0.7)\n",
    "    ax5.set_yticks(range(len(city_top)))\n",
    "    labels = [name[:20] + '...' if len(name) > 20 else name for name in city_top.index]\n",
    "    ax5.set_yticklabels(labels, fontsize=9)\n",
    "    ax5.set_xlabel('Number of Observations')\n",
    "    ax5.set_title('Top 10 Species in City Centres', fontweight='bold', fontsize=12)\n",
    "    ax5.invert_yaxis()\n",
    "\n",
    "# 6. Top species in forests\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "if 'Forest' in combined_df['habitat_type'].values:\n",
    "    forest_top = combined_df[combined_df['habitat_type'] == 'Forest'].groupby('comName').size().sort_values(ascending=False).head(10)\n",
    "    ax6.barh(range(len(forest_top)), forest_top.values, color='forestgreen', alpha=0.7)\n",
    "    ax6.set_yticks(range(len(forest_top)))\n",
    "    labels = [name[:20] + '...' if len(name) > 20 else name for name in forest_top.index]\n",
    "    ax6.set_yticklabels(labels, fontsize=9)\n",
    "    ax6.set_xlabel('Number of Observations')\n",
    "    ax6.set_title('Top 10 Species in Forests', fontweight='bold', fontsize=12)\n",
    "    ax6.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('migration_habitat_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Migration and habitat analysis charts created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of migration patterns across seasons\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "heatmap_data = reference_obs.groupby(['migration_category', 'season']).size().unstack(fill_value=0)\n",
    "\n",
    "# Reorder columns to match season order\n",
    "column_order = [col for col in season_order if col in heatmap_data.columns]\n",
    "heatmap_data = heatmap_data[column_order]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Number of Observations'},\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "\n",
    "plt.title('Migration Pattern Heatmap: Observations by Season', fontweight='bold', fontsize=14, pad=20)\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Migration Category', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('migration_season_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Migration season heatmap created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Top countries by observations\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "top_countries = country_stats.head(20)\n",
    "ax1.barh(range(len(top_countries)), top_countries['Total Observations'], color='steelblue')\n",
    "ax1.set_yticks(range(len(top_countries)))\n",
    "ax1.set_yticklabels(top_countries['Country Name'], fontsize=9)\n",
    "ax1.set_xlabel('Number of Observations')\n",
    "ax1.set_title('Top 20 Countries by Observations', fontweight='bold', fontsize=12)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# 2. Top countries by species diversity\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "top_diversity = country_stats.sort_values('Species Count', ascending=False).head(20)\n",
    "ax2.barh(range(len(top_diversity)), top_diversity['Species Count'], color='coral')\n",
    "ax2.set_yticks(range(len(top_diversity)))\n",
    "ax2.set_yticklabels(top_diversity['Country Name'], fontsize=9)\n",
    "ax2.set_xlabel('Number of Species')\n",
    "ax2.set_title('Top 20 Countries by Species Diversity', fontweight='bold', fontsize=12)\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# 3. Top species\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "top_species = species_stats.head(20)\n",
    "ax3.barh(range(len(top_species)), top_species['Total Observations'], color='forestgreen', alpha=0.7)\n",
    "ax3.set_yticks(range(len(top_species)))\n",
    "labels = [name[:25] + '...' if len(name) > 25 else name for name in top_species['Common Name']]\n",
    "ax3.set_yticklabels(labels, fontsize=9)\n",
    "ax3.set_xlabel('Number of Observations')\n",
    "ax3.set_title('Top 20 Most Observed Species', fontweight='bold', fontsize=12)\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# 4. Observations by month\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "monthly_data = combined_df[combined_df['month'].notna()].groupby('month').size()\n",
    "months = list(range(1, 13))\n",
    "counts = [monthly_data.get(m, 0) for m in months]\n",
    "month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "ax4.bar(months, counts, color='skyblue', alpha=0.8)\n",
    "ax4.set_xticks(months)\n",
    "ax4.set_xticklabels(month_labels, rotation=45)\n",
    "ax4.set_xlabel('Month')\n",
    "ax4.set_ylabel('Number of Observations')\n",
    "ax4.set_title('Seasonal Distribution of Observations', fontweight='bold', fontsize=12)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Observations by year\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "yearly_data = combined_df[combined_df['year'].notna()].groupby('year').size().sort_index()\n",
    "ax5.plot(yearly_data.index, yearly_data.values, marker='o', linewidth=2, markersize=8, color='darkblue')\n",
    "ax5.set_xlabel('Year')\n",
    "ax5.set_ylabel('Number of Observations')\n",
    "ax5.set_title('Observations Over Time', fontweight='bold', fontsize=12)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Species geographic distribution\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "species_distribution = species_stats['Countries Found'].value_counts().sort_index()\n",
    "ax6.bar(species_distribution.index, species_distribution.values, color='teal', alpha=0.7)\n",
    "ax6.set_xlabel('Number of Countries')\n",
    "ax6.set_ylabel('Number of Species')\n",
    "ax6.set_title('Species Geographic Range Distribution', fontweight='bold', fontsize=12)\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('european_bird_analysis_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Overview charts created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic distribution map\n",
    "fig, ax = plt.subplots(figsize=(18, 12))\n",
    "\n",
    "# Create scatter plot with country colors\n",
    "scatter = ax.scatter(combined_df['lng'], combined_df['lat'], \n",
    "                    c=combined_df['countryCode'].astype('category').cat.codes,\n",
    "                    alpha=0.3, s=2, cmap='tab20c')\n",
    "\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('Geographic Distribution of Bird Observations Across Europe', \n",
    "             fontweight='bold', fontsize=16, pad=20)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics box\n",
    "stats_text = f\"Total: {len(combined_df):,} observations\\n\" \\\n",
    "             f\"Countries: {combined_df['countryCode'].nunique()}\\n\" \\\n",
    "             f\"Species: {combined_df['speciesCode'].nunique()}\"\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('geographic_distribution_map.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Geographic distribution map created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GEOGRAPHIC DISTRIBUTION MAP - COLORED BY MIGRATION GROUP\n",
    "# Different colors for Native, Autumn Migrant (Nocturnal), Autumn Migrant (Diurnal), Spring Migrant\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# European country information for labeling\n",
    "EUROPEAN_COUNTRIES = {\n",
    "    'GB': {'name': 'United Kingdom', 'lat': 54.0, 'lon': -2.0},\n",
    "    'IE': {'name': 'Ireland', 'lat': 53.0, 'lon': -8.0},\n",
    "    'FR': {'name': 'France', 'lat': 47.0, 'lon': 2.0},\n",
    "    'ES': {'name': 'Spain', 'lat': 40.0, 'lon': -4.0},\n",
    "    'PT': {'name': 'Portugal', 'lat': 39.5, 'lon': -8.0},\n",
    "    'IT': {'name': 'Italy', 'lat': 43.0, 'lon': 12.5},\n",
    "    'DE': {'name': 'Germany', 'lat': 51.0, 'lon': 10.0},\n",
    "    'PL': {'name': 'Poland', 'lat': 52.0, 'lon': 19.0},\n",
    "    'NL': {'name': 'Netherlands', 'lat': 52.5, 'lon': 5.5},\n",
    "    'BE': {'name': 'Belgium', 'lat': 50.5, 'lon': 4.5},\n",
    "    'CH': {'name': 'Switzerland', 'lat': 47.0, 'lon': 8.0},\n",
    "    'AT': {'name': 'Austria', 'lat': 47.5, 'lon': 14.0},\n",
    "    'CZ': {'name': 'Czechia', 'lat': 49.8, 'lon': 15.5},\n",
    "    'SK': {'name': 'Slovakia', 'lat': 48.7, 'lon': 19.5},\n",
    "    'HU': {'name': 'Hungary', 'lat': 47.0, 'lon': 19.5},\n",
    "    'RO': {'name': 'Romania', 'lat': 46.0, 'lon': 25.0},\n",
    "    'BG': {'name': 'Bulgaria', 'lat': 43.0, 'lon': 25.0},\n",
    "    'GR': {'name': 'Greece', 'lat': 39.0, 'lon': 22.0},\n",
    "    'SE': {'name': 'Sweden', 'lat': 62.0, 'lon': 15.0},\n",
    "    'NO': {'name': 'Norway', 'lat': 62.0, 'lon': 10.0},\n",
    "    'FI': {'name': 'Finland', 'lat': 64.0, 'lon': 26.0},\n",
    "    'DK': {'name': 'Denmark', 'lat': 56.0, 'lon': 10.0},\n",
    "    'EE': {'name': 'Estonia', 'lat': 59.0, 'lon': 26.0},\n",
    "    'LV': {'name': 'Latvia', 'lat': 57.0, 'lon': 25.0},\n",
    "    'LT': {'name': 'Lithuania', 'lat': 55.5, 'lon': 24.0},\n",
    "    'HR': {'name': 'Croatia', 'lat': 45.5, 'lon': 16.0},\n",
    "    'SI': {'name': 'Slovenia', 'lat': 46.0, 'lon': 15.0},\n",
    "    'BA': {'name': 'Bosnia', 'lat': 44.0, 'lon': 18.0},\n",
    "    'RS': {'name': 'Serbia', 'lat': 44.0, 'lon': 21.0},\n",
    "    'AL': {'name': 'Albania', 'lat': 41.0, 'lon': 20.0},\n",
    "    'MK': {'name': 'N. Macedonia', 'lat': 41.6, 'lon': 21.7},\n",
    "    'ME': {'name': 'Montenegro', 'lat': 42.7, 'lon': 19.3},\n",
    "    'XK': {'name': 'Kosovo', 'lat': 42.6, 'lon': 20.9},\n",
    "    'TR': {'name': 'Turkey', 'lat': 39.0, 'lon': 35.0},\n",
    "    'CY': {'name': 'Cyprus', 'lat': 35.0, 'lon': 33.0},\n",
    "    'IS': {'name': 'Iceland', 'lat': 65.0, 'lon': -18.0},\n",
    "    'UA': {'name': 'Ukraine', 'lat': 49.0, 'lon': 32.0},\n",
    "    'BY': {'name': 'Belarus', 'lat': 54.0, 'lon': 28.0},\n",
    "    'MD': {'name': 'Moldova', 'lat': 47.0, 'lon': 29.0},\n",
    "    'RU': {'name': 'Russia', 'lat': 60.0, 'lon': 40.0},\n",
    "    'LU': {'name': 'Luxembourg', 'lat': 49.8, 'lon': 6.1},\n",
    "    'MT': {'name': 'Malta', 'lat': 35.9, 'lon': 14.4},\n",
    "    'MC': {'name': 'Monaco', 'lat': 43.7, 'lon': 7.4},\n",
    "    'AD': {'name': 'Andorra', 'lat': 42.5, 'lon': 1.5},\n",
    "    'LI': {'name': 'Liechtenstein', 'lat': 47.1, 'lon': 9.5},\n",
    "    'SM': {'name': 'San Marino', 'lat': 43.9, 'lon': 12.5},\n",
    "    'VA': {'name': 'Vatican', 'lat': 41.9, 'lon': 12.5},\n",
    "}\n",
    "\n",
    "# Coastline approximations (simplified)\n",
    "COASTLINES = [\n",
    "    # Atlantic/North Sea coast\n",
    "    [(60, -5), (58, -3), (55, -4), (53, -6), (51, -5), (50, 1), (51, 4), (54, 5), \n",
    "     (57, 6), (59, 11), (63, 10), (65, 12), (68, 15), (70, 20), (70, 30)],\n",
    "    # Mediterranean coast  \n",
    "    [(36, -6), (37, -3), (38, 0), (41, 3), (43, 7), (43, 12), (40, 15), (38, 18), \n",
    "     (36, 23), (36, 28), (38, 32), (41, 28), (43, 19), (45, 14)],\n",
    "    # Black Sea\n",
    "    [(41, 28), (42, 29), (44, 30), (45, 31), (46, 32), (46, 38), (45, 40), \n",
    "     (43, 41), (42, 39), (41, 35), (41, 28)],\n",
    "]\n",
    "\n",
    "# Europe bounding box\n",
    "lon_min, lon_max = -25, 50\n",
    "lat_min, lat_max = 35, 72\n",
    "\n",
    "# Filter data to Europe region\n",
    "df_europe = combined_df[(combined_df['lng'] >= lon_min) & (combined_df['lng'] <= lon_max) & \n",
    "                        (combined_df['lat'] >= lat_min) & (combined_df['lat'] <= lat_max)]\n",
    "\n",
    "print(f\"Creating map colored by MIGRATION GROUP with {len(df_europe):,} observations...\")\n",
    "\n",
    "# Check if migration_category column exists\n",
    "if 'migration_category' not in df_europe.columns:\n",
    "    print(\"ERROR: 'migration_category' column not found in data!\")\n",
    "    print(\"Available columns:\", df_europe.columns.tolist())\n",
    "    print(\"\\nThis map requires the migration_category column from your analysis.\")\n",
    "    print(\"Make sure you've run the migration analysis section first.\")\n",
    "else:\n",
    "    # Get unique migration categories\n",
    "    unique_migrations = sorted(df_europe['migration_category'].dropna().unique())\n",
    "    n_migrations = len(unique_migrations)\n",
    "    print(f\"Found {n_migrations} migration groups: {unique_migrations}\")\n",
    "    \n",
    "    # Define distinct colors for each migration category\n",
    "    # Using meaningful colors that represent the migration behavior\n",
    "    migration_colors = {\n",
    "        'Native (Resident)': '#2ecc71',  # Green - stays year-round\n",
    "        'Autumn Migrant (Nocturnal)': '#e67e22',  # Orange - autumn nocturnal\n",
    "        'Autumn Migrant (Diurnal)': '#f39c12',  # Yellow-orange - autumn diurnal\n",
    "        'Spring Migrant': '#9b59b6',  # Purple - spring migrant\n",
    "    }\n",
    "    \n",
    "    # Use default colors for any unexpected categories\n",
    "    default_color = '#95a5a6'  # Gray\n",
    "    \n",
    "    # Create figure with larger size\n",
    "    fig, ax = plt.subplots(figsize=(26, 16), facecolor='#f0f8ff')\n",
    "    ax.set_facecolor('#e6f2ff')\n",
    "    \n",
    "    # Draw simplified border grid\n",
    "    for lon in range(-25, 50, 5):\n",
    "        ax.axvline(x=lon, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "    for lat in range(35, 75, 5):\n",
    "        ax.axhline(y=lat, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "    \n",
    "    # Draw coastlines\n",
    "    for coastline in COASTLINES:\n",
    "        lats, lons = zip(*[(lat, lon) for lat, lon in coastline])\n",
    "        ax.plot(lons, lats, color='steelblue', linewidth=2.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # Plot observations by migration category with distinct colors\n",
    "    print(\"Plotting observations by migration group...\")\n",
    "    for migration_cat in unique_migrations:\n",
    "        migration_data = df_europe[df_europe['migration_category'] == migration_cat]\n",
    "        if len(migration_data) > 0:\n",
    "            color = migration_colors.get(migration_cat, default_color)\n",
    "            ax.scatter(migration_data['lng'], migration_data['lat'], \n",
    "                      c=color, \n",
    "                      alpha=0.5, s=4, \n",
    "                      edgecolors='none',\n",
    "                      zorder=2,\n",
    "                      label=f\"{migration_cat} ({len(migration_data):,})\")\n",
    "    \n",
    "    # Add country code labels\n",
    "    countries_in_data = df_europe['countryCode'].unique()\n",
    "    for code, info in EUROPEAN_COUNTRIES.items():\n",
    "        if code in countries_in_data:\n",
    "            country_obs = df_europe[df_europe['countryCode'] == code]\n",
    "            if len(country_obs) > 100:\n",
    "                label_lon = country_obs['lng'].median()\n",
    "                label_lat = country_obs['lat'].median()\n",
    "                \n",
    "                if lon_min <= label_lon <= lon_max and lat_min <= label_lat <= lat_max:\n",
    "                    ax.text(label_lon, label_lat, code, \n",
    "                           fontsize=8, fontweight='bold', \n",
    "                           ha='center', va='center',\n",
    "                           color='black',\n",
    "                           bbox=dict(boxstyle='round,pad=0.4', \n",
    "                                   facecolor='white', \n",
    "                                   edgecolor='darkgray',\n",
    "                                   alpha=0.75,\n",
    "                                   linewidth=1.5),\n",
    "                           zorder=3)\n",
    "    \n",
    "    # Set map extent to Europe\n",
    "    ax.set_xlim(lon_min, lon_max)\n",
    "    ax.set_ylim(lat_min, lat_max)\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_xlabel('Longitude', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Latitude', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('Geographic Distribution of Bird Observations - Colored by Migration Group\\nGreen=Native | Orange=Autumn Nocturnal | Yellow=Autumn Diurnal | Purple=Spring', \n",
    "                 fontweight='bold', fontsize=20, pad=20)\n",
    "    \n",
    "    # Enhanced grid\n",
    "    ax.grid(True, alpha=0.4, linestyle='-', linewidth=0.5, color='gray')\n",
    "    \n",
    "    # Statistics box with migration info\n",
    "    total_obs = len(df_europe)\n",
    "    total_countries = df_europe['countryCode'].nunique()\n",
    "    total_species = df_europe['speciesCode'].nunique()\n",
    "    total_locations = df_europe['locId'].nunique()\n",
    "    \n",
    "    # Migration group breakdown\n",
    "    migration_breakdown = df_europe['migration_category'].value_counts()\n",
    "    migration_text = \"\\n\".join([f\"  {cat}: {count:,} ({count/total_obs*100:.1f}%)\" \n",
    "                                 for cat, count in migration_breakdown.items()])\n",
    "    \n",
    "    stats_text = (f\"DATASET OVERVIEW\\n\"\n",
    "                 f\"{'─' * 32}\\n\"\n",
    "                 f\"Total Observations: {total_obs:,}\\n\"\n",
    "                 f\"Countries: {total_countries}\\n\"\n",
    "                 f\"Species: {total_species}\\n\"\n",
    "                 f\"Locations: {total_locations:,}\\n\\n\"\n",
    "                 f\"MIGRATION GROUPS\\n\"\n",
    "                 f\"{'─' * 32}\\n\"\n",
    "                 f\"{migration_text}\")\n",
    "    \n",
    "    ax.text(0.015, 0.985, stats_text, \n",
    "           transform=ax.transAxes, \n",
    "           fontsize=9,\n",
    "           verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', \n",
    "                    facecolor='wheat', \n",
    "                    alpha=0.95,\n",
    "                    edgecolor='black',\n",
    "                    linewidth=2),\n",
    "           zorder=4,\n",
    "           family='monospace')\n",
    "    \n",
    "    # Legend for migration categories\n",
    "    legend = ax.legend(loc='lower right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=10,\n",
    "                      title='Migration Category (observations)',\n",
    "                      title_fontsize=11,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=1.0,\n",
    "                      edgecolor='black',\n",
    "                      facecolor='white',\n",
    "                      markerscale=2)\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "    \n",
    "    # Add compass rose\n",
    "    compass_x, compass_y = 0.96, 0.05\n",
    "    ax.annotate('', xy=(compass_x, compass_y + 0.03), \n",
    "               xytext=(compass_x, compass_y),\n",
    "               transform=ax.transAxes,\n",
    "               ha='center',\n",
    "               arrowprops=dict(arrowstyle='->', lw=2.5, color='black'))\n",
    "    ax.text(compass_x, compass_y + 0.035, 'N', \n",
    "           transform=ax.transAxes,\n",
    "           ha='center', va='bottom',\n",
    "           fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add scale bar\n",
    "    scale_lon = lon_min + 5\n",
    "    scale_lat = lat_min + 2\n",
    "    scale_length = 5  # degrees longitude\n",
    "    ax.plot([scale_lon, scale_lon + scale_length], \n",
    "           [scale_lat, scale_lat], \n",
    "           'k-', linewidth=4, zorder=4, solid_capstyle='butt')\n",
    "    ax.plot([scale_lon, scale_lon], \n",
    "           [scale_lat - 0.4, scale_lat + 0.4], \n",
    "           'k-', linewidth=3, zorder=4)\n",
    "    ax.plot([scale_lon + scale_length, scale_lon + scale_length], \n",
    "           [scale_lat - 0.4, scale_lat + 0.4], \n",
    "           'k-', linewidth=3, zorder=4)\n",
    "    ax.text(scale_lon + scale_length/2, scale_lat - 1.2, \n",
    "           '~400 km', ha='center', fontsize=11, fontweight='bold',\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, \n",
    "                    edgecolor='black', linewidth=1))\n",
    "    \n",
    "    # Add color key explanation box\n",
    "    color_key = (\n",
    "        \"COLOR KEY:\\n\"\n",
    "        \"━━━━━━━━━━━━━━━━━━\\n\"\n",
    "        \"🟢 Native (Resident)\\n\"\n",
    "        \"   Year-round residents\\n\\n\"\n",
    "        \"🟠 Autumn Nocturnal\\n\"\n",
    "        \"   Migrate at night in autumn\\n\\n\"\n",
    "        \"🟡 Autumn Diurnal\\n\"\n",
    "        \"   Migrate by day in autumn\\n\\n\"\n",
    "        \"🟣 Spring Migrant\\n\"\n",
    "        \"   Migrate in spring\"\n",
    "    )\n",
    "    \n",
    "    ax.text(0.985, 0.52, color_key, \n",
    "           transform=ax.transAxes, \n",
    "           fontsize=9,\n",
    "           verticalalignment='top',\n",
    "           ha='right',\n",
    "           bbox=dict(boxstyle='round', \n",
    "                    facecolor='white', \n",
    "                    alpha=0.95,\n",
    "                    edgecolor='black',\n",
    "                    linewidth=2),\n",
    "           zorder=4,\n",
    "           family='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('geographic_distribution_map_by_migration.png', dpi=300, bbox_inches='tight', \n",
    "               facecolor='#f0f8ff')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Migration-colored geographic distribution map created!\")\n",
    "    print(f\"  • {n_migrations} migration groups shown in different colors\")\n",
    "    print(f\"  • Green = Native/Resident birds\")\n",
    "    print(f\"  • Orange = Autumn Migrant (Nocturnal)\")\n",
    "    print(f\"  • Yellow = Autumn Migrant (Diurnal)\")\n",
    "    print(f\"  • Purple = Spring Migrant\")\n",
    "    print(f\"  • Saved as: geographic_distribution_map_by_migration.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GEOGRAPHIC DISTRIBUTION MAP - COLORED BY SPECIES\n",
    "# Each species gets a unique color to show distribution patterns\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# European country information for labeling\n",
    "EUROPEAN_COUNTRIES = {\n",
    "    'GB': {'name': 'United Kingdom', 'lat': 54.0, 'lon': -2.0},\n",
    "    'IE': {'name': 'Ireland', 'lat': 53.0, 'lon': -8.0},\n",
    "    'FR': {'name': 'France', 'lat': 47.0, 'lon': 2.0},\n",
    "    'ES': {'name': 'Spain', 'lat': 40.0, 'lon': -4.0},\n",
    "    'PT': {'name': 'Portugal', 'lat': 39.5, 'lon': -8.0},\n",
    "    'IT': {'name': 'Italy', 'lat': 43.0, 'lon': 12.5},\n",
    "    'DE': {'name': 'Germany', 'lat': 51.0, 'lon': 10.0},\n",
    "    'PL': {'name': 'Poland', 'lat': 52.0, 'lon': 19.0},\n",
    "    'NL': {'name': 'Netherlands', 'lat': 52.5, 'lon': 5.5},\n",
    "    'BE': {'name': 'Belgium', 'lat': 50.5, 'lon': 4.5},\n",
    "    'CH': {'name': 'Switzerland', 'lat': 47.0, 'lon': 8.0},\n",
    "    'AT': {'name': 'Austria', 'lat': 47.5, 'lon': 14.0},\n",
    "    'CZ': {'name': 'Czechia', 'lat': 49.8, 'lon': 15.5},\n",
    "    'SK': {'name': 'Slovakia', 'lat': 48.7, 'lon': 19.5},\n",
    "    'HU': {'name': 'Hungary', 'lat': 47.0, 'lon': 19.5},\n",
    "    'RO': {'name': 'Romania', 'lat': 46.0, 'lon': 25.0},\n",
    "    'BG': {'name': 'Bulgaria', 'lat': 43.0, 'lon': 25.0},\n",
    "    'GR': {'name': 'Greece', 'lat': 39.0, 'lon': 22.0},\n",
    "    'SE': {'name': 'Sweden', 'lat': 62.0, 'lon': 15.0},\n",
    "    'NO': {'name': 'Norway', 'lat': 62.0, 'lon': 10.0},\n",
    "    'FI': {'name': 'Finland', 'lat': 64.0, 'lon': 26.0},\n",
    "    'DK': {'name': 'Denmark', 'lat': 56.0, 'lon': 10.0},\n",
    "    'EE': {'name': 'Estonia', 'lat': 59.0, 'lon': 26.0},\n",
    "    'LV': {'name': 'Latvia', 'lat': 57.0, 'lon': 25.0},\n",
    "    'LT': {'name': 'Lithuania', 'lat': 55.5, 'lon': 24.0},\n",
    "    'HR': {'name': 'Croatia', 'lat': 45.5, 'lon': 16.0},\n",
    "    'SI': {'name': 'Slovenia', 'lat': 46.0, 'lon': 15.0},\n",
    "    'BA': {'name': 'Bosnia', 'lat': 44.0, 'lon': 18.0},\n",
    "    'RS': {'name': 'Serbia', 'lat': 44.0, 'lon': 21.0},\n",
    "    'AL': {'name': 'Albania', 'lat': 41.0, 'lon': 20.0},\n",
    "    'MK': {'name': 'N. Macedonia', 'lat': 41.6, 'lon': 21.7},\n",
    "    'ME': {'name': 'Montenegro', 'lat': 42.7, 'lon': 19.3},\n",
    "    'XK': {'name': 'Kosovo', 'lat': 42.6, 'lon': 20.9},\n",
    "    'TR': {'name': 'Turkey', 'lat': 39.0, 'lon': 35.0},\n",
    "    'CY': {'name': 'Cyprus', 'lat': 35.0, 'lon': 33.0},\n",
    "    'IS': {'name': 'Iceland', 'lat': 65.0, 'lon': -18.0},\n",
    "    'UA': {'name': 'Ukraine', 'lat': 49.0, 'lon': 32.0},\n",
    "    'BY': {'name': 'Belarus', 'lat': 54.0, 'lon': 28.0},\n",
    "    'MD': {'name': 'Moldova', 'lat': 47.0, 'lon': 29.0},\n",
    "    'RU': {'name': 'Russia', 'lat': 60.0, 'lon': 40.0},\n",
    "    'LU': {'name': 'Luxembourg', 'lat': 49.8, 'lon': 6.1},\n",
    "    'MT': {'name': 'Malta', 'lat': 35.9, 'lon': 14.4},\n",
    "    'MC': {'name': 'Monaco', 'lat': 43.7, 'lon': 7.4},\n",
    "    'AD': {'name': 'Andorra', 'lat': 42.5, 'lon': 1.5},\n",
    "    'LI': {'name': 'Liechtenstein', 'lat': 47.1, 'lon': 9.5},\n",
    "    'SM': {'name': 'San Marino', 'lat': 43.9, 'lon': 12.5},\n",
    "    'VA': {'name': 'Vatican', 'lat': 41.9, 'lon': 12.5},\n",
    "}\n",
    "\n",
    "# Coastline approximations (simplified)\n",
    "COASTLINES = [\n",
    "    # Atlantic/North Sea coast\n",
    "    [(60, -5), (58, -3), (55, -4), (53, -6), (51, -5), (50, 1), (51, 4), (54, 5), \n",
    "     (57, 6), (59, 11), (63, 10), (65, 12), (68, 15), (70, 20), (70, 30)],\n",
    "    # Mediterranean coast  \n",
    "    [(36, -6), (37, -3), (38, 0), (41, 3), (43, 7), (43, 12), (40, 15), (38, 18), \n",
    "     (36, 23), (36, 28), (38, 32), (41, 28), (43, 19), (45, 14)],\n",
    "    # Black Sea\n",
    "    [(41, 28), (42, 29), (44, 30), (45, 31), (46, 32), (46, 38), (45, 40), \n",
    "     (43, 41), (42, 39), (41, 35), (41, 28)],\n",
    "]\n",
    "\n",
    "# Europe bounding box\n",
    "lon_min, lon_max = -25, 50\n",
    "lat_min, lat_max = 35, 72\n",
    "\n",
    "# Filter data to Europe region\n",
    "df_europe = combined_df[(combined_df['lng'] >= lon_min) & (combined_df['lng'] <= lon_max) & \n",
    "                        (combined_df['lat'] >= lat_min) & (combined_df['lat'] <= lat_max)]\n",
    "\n",
    "print(f\"Creating map colored by SPECIES with {len(df_europe):,} observations...\")\n",
    "\n",
    "# Get unique species and create color map\n",
    "unique_species = sorted(df_europe['speciesCode'].unique())\n",
    "n_species = len(unique_species)\n",
    "print(f\"Found {n_species} unique species\")\n",
    "\n",
    "# Create distinct colors for each species using a good colormap\n",
    "# Use tab20 for up to 20 species, otherwise use hsv\n",
    "if n_species <= 20:\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, n_species))\n",
    "else:\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, n_species))\n",
    "    \n",
    "species_color_map = dict(zip(unique_species, colors))\n",
    "\n",
    "# Also get common names for legend\n",
    "if 'comName' in df_europe.columns:\n",
    "    species_names = df_europe.groupby('speciesCode')['comName'].first().to_dict()\n",
    "else:\n",
    "    species_names = {code: code for code in unique_species}\n",
    "\n",
    "# Create figure with larger size\n",
    "fig, ax = plt.subplots(figsize=(26, 16), facecolor='#f0f8ff')\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "\n",
    "# Draw simplified border grid\n",
    "for lon in range(-25, 50, 5):\n",
    "    ax.axvline(x=lon, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "for lat in range(35, 75, 5):\n",
    "    ax.axhline(y=lat, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "\n",
    "# Draw coastlines\n",
    "for coastline in COASTLINES:\n",
    "    lats, lons = zip(*[(lat, lon) for lat, lon in coastline])\n",
    "    ax.plot(lons, lats, color='steelblue', linewidth=2.5, alpha=0.7, zorder=1)\n",
    "\n",
    "# Plot observations by species with distinct colors\n",
    "print(\"Plotting observations by species...\")\n",
    "for i, species in enumerate(unique_species):\n",
    "    species_data = df_europe[df_europe['speciesCode'] == species]\n",
    "    if len(species_data) > 0:\n",
    "        ax.scatter(species_data['lng'], species_data['lat'], \n",
    "                  c=[species_color_map[species]], \n",
    "                  alpha=0.5, s=4, \n",
    "                  edgecolors='none',\n",
    "                  zorder=2,\n",
    "                  label=f\"{species_names[species]} ({len(species_data):,})\")\n",
    "\n",
    "# Add country code labels\n",
    "countries_in_data = df_europe['countryCode'].unique()\n",
    "for code, info in EUROPEAN_COUNTRIES.items():\n",
    "    if code in countries_in_data:\n",
    "        country_obs = df_europe[df_europe['countryCode'] == code]\n",
    "        if len(country_obs) > 100:\n",
    "            label_lon = country_obs['lng'].median()\n",
    "            label_lat = country_obs['lat'].median()\n",
    "            \n",
    "            if lon_min <= label_lon <= lon_max and lat_min <= label_lat <= lat_max:\n",
    "                ax.text(label_lon, label_lat, code, \n",
    "                       fontsize=8, fontweight='bold', \n",
    "                       ha='center', va='center',\n",
    "                       color='black',\n",
    "                       bbox=dict(boxstyle='round,pad=0.4', \n",
    "                               facecolor='white', \n",
    "                               edgecolor='darkgray',\n",
    "                               alpha=0.75,\n",
    "                               linewidth=1.5),\n",
    "                       zorder=3)\n",
    "\n",
    "# Set map extent to Europe\n",
    "ax.set_xlim(lon_min, lon_max)\n",
    "ax.set_ylim(lat_min, lat_max)\n",
    "\n",
    "# Styling\n",
    "ax.set_xlabel('Longitude', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Latitude', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Geographic Distribution of Bird Observations - Colored by Species\\nEach color represents a different bird species', \n",
    "             fontweight='bold', fontsize=20, pad=20)\n",
    "\n",
    "# Enhanced grid\n",
    "ax.grid(True, alpha=0.4, linestyle='-', linewidth=0.5, color='gray')\n",
    "\n",
    "# Statistics box with species info\n",
    "total_obs = len(df_europe)\n",
    "total_countries = df_europe['countryCode'].nunique()\n",
    "total_species = df_europe['speciesCode'].nunique()\n",
    "total_locations = df_europe['locId'].nunique()\n",
    "\n",
    "# Top 5 species by observation count\n",
    "top_species = df_europe['speciesCode'].value_counts().head(5)\n",
    "top_species_text = \"\\n\".join([f\"  {species_names.get(code, code)[:20]}: {count:,}\" \n",
    "                               for code, count in top_species.items()])\n",
    "\n",
    "stats_text = (f\"DATASET OVERVIEW\\n\"\n",
    "             f\"{'─' * 30}\\n\"\n",
    "             f\"Total Observations: {total_obs:,}\\n\"\n",
    "             f\"Countries: {total_countries}\\n\"\n",
    "             f\"Species: {total_species}\\n\"\n",
    "             f\"Locations: {total_locations:,}\\n\\n\"\n",
    "             f\"TOP 5 SPECIES\\n\"\n",
    "             f\"{'─' * 30}\\n\"\n",
    "             f\"{top_species_text}\")\n",
    "\n",
    "ax.text(0.015, 0.985, stats_text, \n",
    "       transform=ax.transAxes, \n",
    "       fontsize=10,\n",
    "       verticalalignment='top',\n",
    "       bbox=dict(boxstyle='round', \n",
    "                facecolor='wheat', \n",
    "                alpha=0.95,\n",
    "                edgecolor='black',\n",
    "                linewidth=2),\n",
    "       zorder=4,\n",
    "       family='monospace')\n",
    "\n",
    "# Legend for species (show all if <= 20, otherwise show top 10)\n",
    "if n_species <= 20:\n",
    "    legend = ax.legend(loc='lower right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=8,\n",
    "                      title='Species (observations)',\n",
    "                      title_fontsize=9,\n",
    "                      ncol=2,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=0.6,\n",
    "                      columnspacing=1.5,\n",
    "                      edgecolor='black',\n",
    "                      facecolor='white')\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "else:\n",
    "    # Show top 10 species in legend\n",
    "    print(f\"Too many species ({n_species}) for full legend - showing top 10\")\n",
    "    # Clear previous legend items and add top 10\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Sort by observation count (already in order from plotting)\n",
    "    top_10_indices = [i for i in range(min(10, len(handles)))]\n",
    "    legend = ax.legend([handles[i] for i in top_10_indices],\n",
    "                      [labels[i] for i in top_10_indices],\n",
    "                      loc='lower right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=8,\n",
    "                      title=f'Top 10 Species (of {n_species})',\n",
    "                      title_fontsize=9,\n",
    "                      ncol=2,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=0.6,\n",
    "                      columnspacing=1.5,\n",
    "                      edgecolor='black',\n",
    "                      facecolor='white')\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "\n",
    "# Add compass rose\n",
    "compass_x, compass_y = 0.96, 0.05\n",
    "ax.annotate('', xy=(compass_x, compass_y + 0.03), \n",
    "           xytext=(compass_x, compass_y),\n",
    "           transform=ax.transAxes,\n",
    "           ha='center',\n",
    "           arrowprops=dict(arrowstyle='->', lw=2.5, color='black'))\n",
    "ax.text(compass_x, compass_y + 0.035, 'N', \n",
    "       transform=ax.transAxes,\n",
    "       ha='center', va='bottom',\n",
    "       fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add scale bar\n",
    "scale_lon = lon_min + 5\n",
    "scale_lat = lat_min + 2\n",
    "scale_length = 5  # degrees longitude\n",
    "ax.plot([scale_lon, scale_lon + scale_length], \n",
    "       [scale_lat, scale_lat], \n",
    "       'k-', linewidth=4, zorder=4, solid_capstyle='butt')\n",
    "ax.plot([scale_lon, scale_lon], \n",
    "       [scale_lat - 0.4, scale_lat + 0.4], \n",
    "       'k-', linewidth=3, zorder=4)\n",
    "ax.plot([scale_lon + scale_length, scale_lon + scale_length], \n",
    "       [scale_lat - 0.4, scale_lat + 0.4], \n",
    "       'k-', linewidth=3, zorder=4)\n",
    "ax.text(scale_lon + scale_length/2, scale_lat - 1.2, \n",
    "       '~400 km', ha='center', fontsize=11, fontweight='bold',\n",
    "       bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, \n",
    "                edgecolor='black', linewidth=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('geographic_distribution_map_by_species.png', dpi=300, bbox_inches='tight', \n",
    "           facecolor='#f0f8ff')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Species-colored geographic distribution map created!\")\n",
    "print(f\"  • {n_species} species shown in different colors\")\n",
    "print(f\"  • Each dot color represents a different bird species\")\n",
    "print(f\"  • Saved as: geographic_distribution_map_by_species.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ULTRA-DETAILED GEOGRAPHIC DISTRIBUTION MAP\n",
    "# Advanced version with precise country boundaries and enhanced visualization\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "# Simplified country boundary polygons (key European countries)\n",
    "# Format: country_code: [(lon, lat), ...]\n",
    "COUNTRY_BOUNDARIES = {\n",
    "    'GB': [(-6, 58), (-3, 59), (0, 58), (2, 52), (1, 50), (-2, 50), (-5, 52), (-6, 55), (-6, 58)],\n",
    "    'FR': [(-5, 48), (-2, 51), (3, 51), (8, 49), (8, 47), (7, 44), (4, 43), (2, 42), (-2, 43), (-2, 48), (-5, 48)],\n",
    "    'ES': [(-9, 43), (-7, 42), (-2, 43), (2, 42), (3, 40), (0, 38), (-2, 37), (-7, 37), (-9, 40), (-9, 43)],\n",
    "    'IT': [(8, 47), (13, 47), (16, 41), (18, 40), (16, 38), (15, 37), (12, 37), (10, 43), (8, 44), (8, 47)],\n",
    "    'DE': [(6, 54), (10, 55), (14, 53), (15, 51), (13, 48), (10, 47), (7, 48), (6, 50), (6, 54)],\n",
    "    'PL': [(14, 54), (17, 55), (23, 54), (24, 50), (23, 49), (18, 49), (15, 50), (14, 54)],\n",
    "    'SE': [(11, 56), (13, 58), (18, 59), (22, 66), (24, 68), (20, 69), (16, 68), (12, 63), (11, 56)],\n",
    "    'NO': [(5, 59), (8, 61), (12, 63), (16, 68), (24, 70), (28, 71), (25, 69), (20, 69), (11, 61), (5, 59)],\n",
    "}\n",
    "\n",
    "# Major city locations for reference\n",
    "MAJOR_CITIES = {\n",
    "    'London': (51.5, -0.1),\n",
    "    'Paris': (48.9, 2.4),\n",
    "    'Berlin': (52.5, 13.4),\n",
    "    'Madrid': (40.4, -3.7),\n",
    "    'Rome': (41.9, 12.5),\n",
    "    'Warsaw': (52.2, 21.0),\n",
    "    'Stockholm': (59.3, 18.1),\n",
    "    'Oslo': (59.9, 10.8),\n",
    "    'Helsinki': (60.2, 25.0),\n",
    "    'Vienna': (48.2, 16.4),\n",
    "    'Prague': (50.1, 14.4),\n",
    "    'Budapest': (47.5, 19.1),\n",
    "    'Athens': (38.0, 23.7),\n",
    "    'Bucharest': (44.4, 26.1),\n",
    "    'Kiev': (50.5, 30.5),\n",
    "    'Lisbon': (38.7, -9.1),\n",
    "    'Dublin': (53.3, -6.3),\n",
    "    'Copenhagen': (55.7, 12.6),\n",
    "    'Amsterdam': (52.4, 4.9),\n",
    "    'Brussels': (50.8, 4.4),\n",
    "}\n",
    "\n",
    "# Regional seas\n",
    "SEAS = {\n",
    "    'North Sea': (55, 4),\n",
    "    'Baltic Sea': (58, 20),\n",
    "    'Mediterranean': (38, 18),\n",
    "    'Black Sea': (44, 35),\n",
    "    'Atlantic Ocean': (45, -15),\n",
    "}\n",
    "\n",
    "# Europe bounding box (fills screen)\n",
    "lon_min, lon_max = -25, 50\n",
    "lat_min, lat_max = 35, 72\n",
    "\n",
    "# Filter data to Europe\n",
    "df_europe = combined_df[(combined_df['lng'] >= lon_min) & (combined_df['lng'] <= lon_max) & \n",
    "                        (combined_df['lat'] >= lat_min) & (combined_df['lat'] <= lat_max)]\n",
    "\n",
    "print(f\"Creating ultra-detailed map with {len(df_europe):,} observations...\")\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(28, 18), facecolor='#e8f4f8')\n",
    "ax = fig.add_subplot(111, facecolor='#d6ecf5')\n",
    "\n",
    "# Draw refined grid (latitude/longitude lines)\n",
    "for lon in np.arange(-20, 50, 5):\n",
    "    ax.axvline(x=lon, color='lightgray', alpha=0.4, linewidth=0.7, linestyle=':')\n",
    "    if lon % 10 == 0:\n",
    "        ax.axvline(x=lon, color='gray', alpha=0.5, linewidth=1.0, linestyle='--')\n",
    "        \n",
    "for lat in np.arange(35, 75, 5):\n",
    "    ax.axhline(y=lat, color='lightgray', alpha=0.4, linewidth=0.7, linestyle=':')\n",
    "    if lat % 10 == 0:\n",
    "        ax.axhline(y=lat, color='gray', alpha=0.5, linewidth=1.0, linestyle='--')\n",
    "\n",
    "# Draw country boundaries\n",
    "print(\"Drawing country boundaries...\")\n",
    "for country_code, boundary in COUNTRY_BOUNDARIES.items():\n",
    "    lons, lats = zip(*[(lon, lat) for lat, lon in boundary])\n",
    "    ax.plot(lons, lats, color='#2c3e50', linewidth=2.5, alpha=0.8, zorder=2)\n",
    "    ax.fill(lons, lats, color='white', alpha=0.15, zorder=1)\n",
    "\n",
    "# Color mapping for countries\n",
    "countries_in_data = sorted(df_europe['countryCode'].unique())\n",
    "n_countries = len(countries_in_data)\n",
    "\n",
    "# Use multiple colormaps for variety\n",
    "colors = []\n",
    "for i, country in enumerate(countries_in_data):\n",
    "    hue = i / n_countries\n",
    "    colors.append(plt.cm.hsv(hue))\n",
    "color_map = dict(zip(countries_in_data, colors))\n",
    "\n",
    "# Plot observations with distinct colors per country\n",
    "print(\"Plotting observations...\")\n",
    "for i, country in enumerate(countries_in_data):\n",
    "    country_data = df_europe[df_europe['countryCode'] == country]\n",
    "    if len(country_data) > 0:\n",
    "        ax.scatter(country_data['lng'], country_data['lat'], \n",
    "                  c=[color_map[country]], \n",
    "                  alpha=0.35, s=2.5, \n",
    "                  edgecolors='none',\n",
    "                  zorder=3,\n",
    "                  label=country if i < 25 else None)\n",
    "\n",
    "# Add country labels at observation centers\n",
    "print(\"Adding country labels...\")\n",
    "for code in countries_in_data:\n",
    "    country_obs = df_europe[df_europe['countryCode'] == code]\n",
    "    if len(country_obs) > 50:  # Only label countries with sufficient data\n",
    "        label_lon = country_obs['lng'].median()\n",
    "        label_lat = country_obs['lat'].median()\n",
    "        \n",
    "        if lon_min <= label_lon <= lon_max and lat_min <= label_lat <= lat_max:\n",
    "            # Calculate observation density for this country\n",
    "            obs_count = len(country_obs)\n",
    "            \n",
    "            # Adjust label styling based on observation count\n",
    "            fontsize = min(12, max(7, 7 + np.log10(obs_count)))\n",
    "            \n",
    "            ax.text(label_lon, label_lat, code, \n",
    "                   fontsize=fontsize, fontweight='bold', \n",
    "                   ha='center', va='center',\n",
    "                   color='#2c3e50',\n",
    "                   bbox=dict(boxstyle='round,pad=0.5', \n",
    "                           facecolor='white', \n",
    "                           edgecolor='#34495e',\n",
    "                           alpha=0.9,\n",
    "                           linewidth=2),\n",
    "                   zorder=5)\n",
    "\n",
    "# Add major city markers\n",
    "print(\"Adding major cities...\")\n",
    "for city, (lat, lon) in MAJOR_CITIES.items():\n",
    "    if lon_min <= lon <= lon_max and lat_min <= lat <= lat_max:\n",
    "        ax.plot(lon, lat, 'k*', markersize=8, zorder=4, \n",
    "               markeredgecolor='white', markeredgewidth=1)\n",
    "        ax.text(lon + 0.8, lat + 0.5, city, fontsize=7, \n",
    "               style='italic', alpha=0.7, zorder=4)\n",
    "\n",
    "# Add sea labels\n",
    "for sea, (lat, lon) in SEAS.items():\n",
    "    if lon_min <= lon <= lon_max and lat_min <= lat <= lat_max:\n",
    "        ax.text(lon, lat, sea, fontsize=10, \n",
    "               ha='center', va='center',\n",
    "               color='#2980b9', alpha=0.6,\n",
    "               style='italic', fontweight='bold')\n",
    "\n",
    "# Set extent\n",
    "ax.set_xlim(lon_min, lon_max)\n",
    "ax.set_ylim(lat_min, lat_max)\n",
    "\n",
    "# Enhanced styling\n",
    "ax.set_xlabel('Longitude (°E)', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Latitude (°N)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('Geographic Distribution of Bird Observations Across Europe\\nDetailed Country Boundaries and Observation Density', \n",
    "             fontweight='bold', fontsize=22, pad=25)\n",
    "\n",
    "# Major grid with labels\n",
    "ax.grid(True, which='major', alpha=0.5, linestyle='-', linewidth=0.8, color='gray')\n",
    "\n",
    "# Detailed statistics panel\n",
    "total_obs = len(df_europe)\n",
    "total_countries = df_europe['countryCode'].nunique()\n",
    "total_species = df_europe['speciesCode'].nunique()\n",
    "total_locations = df_europe['locId'].nunique()\n",
    "\n",
    "# Top 5 countries\n",
    "top_countries = df_europe['countryCode'].value_counts().head(5)\n",
    "top_countries_text = \"\\n\".join([f\"  {code}: {count:,}\" for code, count in top_countries.items()])\n",
    "\n",
    "stats_text = (\n",
    "    f\"DATASET OVERVIEW\\n\"\n",
    "    f\"{'─' * 30}\\n\"\n",
    "    f\"Total Observations: {total_obs:,}\\n\"\n",
    "    f\"Countries: {total_countries}\\n\"\n",
    "    f\"Species: {total_species:,}\\n\"\n",
    "    f\"Locations: {total_locations:,}\\n\\n\"\n",
    "    f\"COVERAGE\\n\"\n",
    "    f\"{'─' * 30}\\n\"\n",
    "    f\"Latitude: {lat_min}° to {lat_max}°\\n\"\n",
    "    f\"Longitude: {lon_min}° to {lon_max}°\\n\\n\"\n",
    "    f\"TOP 5 COUNTRIES\\n\"\n",
    "    f\"{'─' * 30}\\n\"\n",
    "    f\"{top_countries_text}\"\n",
    ")\n",
    "\n",
    "ax.text(0.015, 0.985, stats_text, \n",
    "       transform=ax.transAxes, \n",
    "       fontsize=10,\n",
    "       verticalalignment='top',\n",
    "       bbox=dict(boxstyle='round,pad=1', \n",
    "                facecolor='#ecf0f1', \n",
    "                alpha=0.95,\n",
    "                edgecolor='#2c3e50',\n",
    "                linewidth=3),\n",
    "       zorder=6,\n",
    "       family='monospace',\n",
    "       linespacing=1.5)\n",
    "\n",
    "# Legend for top countries (if not too many)\n",
    "if len(countries_in_data) <= 25:\n",
    "    legend = ax.legend(loc='upper right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=8,\n",
    "                      title='Country Codes',\n",
    "                      title_fontsize=10,\n",
    "                      ncol=3,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=0.8,\n",
    "                      columnspacing=1.5,\n",
    "                      edgecolor='#2c3e50',\n",
    "                      facecolor='#ecf0f1')\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "\n",
    "# Enhanced compass rose\n",
    "compass_x, compass_y = 0.97, 0.04\n",
    "# North arrow\n",
    "ax.annotate('', xy=(compass_x, compass_y + 0.035), \n",
    "           xytext=(compass_x, compass_y),\n",
    "           transform=ax.transAxes,\n",
    "           arrowprops=dict(arrowstyle='->', lw=3, color='#2c3e50'))\n",
    "ax.text(compass_x, compass_y + 0.04, 'N', \n",
    "       transform=ax.transAxes,\n",
    "       ha='center', va='bottom',\n",
    "       fontsize=16, fontweight='bold', color='#2c3e50')\n",
    "\n",
    "# Cardinal directions\n",
    "cardinal_size = 0.015\n",
    "for direction, (dx, dy) in [('E', (cardinal_size, 0)), ('W', (-cardinal_size, 0)), ('S', (0, -cardinal_size))]:\n",
    "    ax.text(compass_x + dx, compass_y + dy, direction,\n",
    "           transform=ax.transAxes,\n",
    "           ha='center', va='center',\n",
    "           fontsize=11, color='#2c3e50', alpha=0.7)\n",
    "\n",
    "# Enhanced scale bar with multiple distances\n",
    "scale_lon = lon_min + 4\n",
    "scale_lat = lat_min + 1.5\n",
    "scale_lengths = [5, 10]  # Multiple scale bars\n",
    "scale_colors = ['black', 'darkgray']\n",
    "\n",
    "for i, (length, color) in enumerate(zip(scale_lengths, scale_colors)):\n",
    "    y_offset = i * 0.8\n",
    "    ax.plot([scale_lon, scale_lon + length], \n",
    "           [scale_lat - y_offset, scale_lat - y_offset], \n",
    "           color=color, linewidth=5, zorder=4, solid_capstyle='butt')\n",
    "    ax.plot([scale_lon, scale_lon], \n",
    "           [scale_lat - 0.5 - y_offset, scale_lat + 0.5 - y_offset], \n",
    "           color=color, linewidth=3, zorder=4)\n",
    "    ax.plot([scale_lon + length, scale_lon + length], \n",
    "           [scale_lat - 0.5 - y_offset, scale_lat + 0.5 - y_offset], \n",
    "           color=color, linewidth=3, zorder=4)\n",
    "    \n",
    "    # Distance label (approximate)\n",
    "    km_approx = int(length * 80)  # ~80km per degree at European latitudes\n",
    "    ax.text(scale_lon + length/2, scale_lat - 1.5 - y_offset, \n",
    "           f'~{km_approx} km', \n",
    "           ha='center', fontsize=9, fontweight='bold',\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.95, \n",
    "                    edgecolor=color, linewidth=1.5))\n",
    "\n",
    "# Add data attribution\n",
    "ax.text(0.5, 0.005, \n",
    "       'Data Source: eBird | 47 European Countries | 2022', \n",
    "       transform=ax.transAxes,\n",
    "       ha='center', va='bottom',\n",
    "       fontsize=9, style='italic', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('geographic_distribution_map_ultra_detailed.png', \n",
    "           dpi=350, bbox_inches='tight', facecolor='#e8f4f8')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Ultra-detailed geographic distribution map created!\")\n",
    "print(\"\\nFeatures:\")\n",
    "print(\"  ✓ Europe fills entire screen (35°N - 72°N, 25°W - 50°E)\")\n",
    "print(\"  ✓ Country boundaries with shading\")\n",
    "print(\"  ✓ Country code labels at observation centers\")\n",
    "print(\"  ✓ Major cities marked with stars\")\n",
    "print(\"  ✓ Sea and ocean labels\")\n",
    "print(\"  ✓ Enhanced grid with major/minor lines\")\n",
    "print(\"  ✓ Compass rose with cardinal directions\")\n",
    "print(\"  ✓ Multiple distance scale bars\")\n",
    "print(\"  ✓ Comprehensive statistics panel\")\n",
    "print(\"  ✓ Top 5 countries by observations\")\n",
    "print(\"  ✓ Color-coded observations by country\")\n",
    "print(f\"  ✓ High resolution (350 DPI) output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Statistical Tests and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis between country metrics\n",
    "print(\"\\nCOUNTRY METRICS CORRELATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correlation_data = country_stats[['Total Observations', 'Species Count', \n",
    "                                   'Unique Locations']].corr()\n",
    "\n",
    "print(correlation_data)\n",
    "\n",
    "# Visualize correlation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_data, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix: Country Metrics', fontweight='bold', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Correlation analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Distribution of observations per country\n",
    "axes[0].hist(country_stats['Total Observations'], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Observations per Country')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Observations per Country', fontweight='bold')\n",
    "axes[0].axvline(country_stats['Total Observations'].median(), color='red', \n",
    "                   linestyle='--', label=f'Median: {country_stats[\"Total Observations\"].median():.0f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Distribution of species per country\n",
    "axes[1].hist(country_stats['Species Count'], bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Species Count per Country')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Species Diversity per Country', fontweight='bold')\n",
    "axes[1].axvline(country_stats['Species Count'].median(), color='red', \n",
    "                   linestyle='--', label=f'Median: {country_stats[\"Species Count\"].median():.0f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Distribution of observations per species\n",
    "axes[2].hist(species_stats['Total Observations'], bins=50, color='forestgreen', alpha=0.7, edgecolor='black')\n",
    "axes[2].set_xlabel('Observations per Species')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Distribution of Observations per Species', fontweight='bold')\n",
    "axes[2].set_xlim(0, species_stats['Total Observations'].quantile(0.95))\n",
    "axes[2].axvline(species_stats['Total Observations'].median(), color='red', \n",
    "                   linestyle='--', label=f'Median: {species_stats[\"Total Observations\"].median():.0f}')\n",
    "axes[2].legend()\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Distribution analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined dataset\n",
    "output_file = 'combined_european_birds_full.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Combined dataset saved: {output_file}\")\n",
    "print(f\"  Size: {Path(output_file).stat().st_size / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save statistical summaries\n",
    "country_stats.to_csv('country_statistics_detailed.csv', index=False)\n",
    "print(\"✓ Country statistics saved: country_statistics_detailed.csv\")\n",
    "\n",
    "species_stats.to_csv('species_statistics_detailed.csv', index=False)\n",
    "print(\"✓ Species statistics saved: species_statistics_detailed.csv\")\n",
    "\n",
    "# Save migration analysis results\n",
    "if len(unspotted_species) > 0:\n",
    "    unspotted_species.to_csv('unspotted_species.csv', index=False)\n",
    "    print(\"✓ Unspotted species saved: unspotted_species.csv\")\n",
    "\n",
    "spotted_species.to_csv('spotted_reference_species.csv', index=False)\n",
    "print(\"✓ Spotted reference species saved: spotted_reference_species.csv\")\n",
    "\n",
    "# Save habitat type analysis (Forest, Countryside, City Centre)\n",
    "habitat_summary = combined_df.groupby(['habitat_type', 'comName']).size().reset_index(name='Observations')\n",
    "habitat_summary = habitat_summary.sort_values(['habitat_type', 'Observations'], ascending=[True, False])\n",
    "habitat_summary.to_csv('habitat_type_species.csv', index=False)\n",
    "print(\"✓ Habitat type analysis saved: habitat_type_species.csv\")\n",
    "\n",
    "# Save migration season analysis\n",
    "migration_season_summary = reference_obs.groupby(['migration_category', 'season', 'comName']).size().reset_index(name='Observations')\n",
    "migration_season_summary = migration_season_summary.sort_values(['migration_category', 'season', 'Observations'], ascending=[True, True, False])\n",
    "migration_season_summary.to_csv('migration_season_analysis.csv', index=False)\n",
    "print(\"✓ Migration season analysis saved: migration_season_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary report\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "EUROPEAN BIRD SIGHTINGS - COMPREHENSIVE STATISTICAL ANALYSIS REPORT\n",
    "{'='*80}\n",
    "\n",
    "Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "DATASET OVERVIEW\n",
    "{'-'*80}\n",
    "Total Observations: {len(combined_df):,}\n",
    "Countries Covered: {combined_df['countryCode'].nunique()}\n",
    "Unique Species Observed: {combined_df['speciesCode'].nunique()}\n",
    "Unique Locations: {combined_df['locId'].nunique()}\n",
    "Total Checklists: {combined_df['subId'].nunique()}\n",
    "Date Range: {combined_df['obsDt'].min()} to {combined_df['obsDt'].max()}\n",
    "\n",
    "GEOGRAPHIC COVERAGE\n",
    "{'-'*80}\n",
    "Latitude Range: {combined_df['lat'].min():.4f}° to {combined_df['lat'].max():.4f}°\n",
    "Longitude Range: {combined_df['lng'].min():.4f}° to {combined_df['lng'].max():.4f}°\n",
    "\n",
    "REFERENCE SPECIES ANALYSIS\n",
    "{'-'*80}\n",
    "Total Reference Species: {len(bird_reference_clean)}\n",
    "Species Spotted: {len(spotted_species)} ({len(spotted_species)/len(bird_reference_clean)*100:.1f}%)\n",
    "Species Not Spotted: {len(unspotted_species)} ({len(unspotted_species)/len(bird_reference_clean)*100:.1f}%)\n",
    "\n",
    "HABITAT TYPE ANALYSIS (Coordinate-Based)\n",
    "{'-'*80}\n",
    "City Centre Observations: {len(combined_df[combined_df['habitat_type'] == 'City Centre']):,}\n",
    "Countryside Observations: {len(combined_df[combined_df['habitat_type'] == 'Countryside']):,}\n",
    "Forest Observations: {len(combined_df[combined_df['habitat_type'] == 'Forest']):,}\n",
    "Unknown Habitat: {len(combined_df[combined_df['habitat_type'] == 'Unknown']):,}\n",
    "\n",
    "MIGRATION PATTERN ANALYSIS\n",
    "{'-'*80}\n",
    "Native (Resident) Birds: {len(reference_obs[reference_obs['migration_category'] == 'Native (Resident)']):,} observations\n",
    "Autumn Migrants (Nocturnal): {len(reference_obs[reference_obs['migration_category'] == 'Autumn Migrant (Nocturnal)']):,} observations\n",
    "Autumn Migrants (Diurnal): {len(reference_obs[reference_obs['migration_category'] == 'Autumn Migrant (Diurnal)']):,} observations\n",
    "Spring Migrants: {len(reference_obs[reference_obs['migration_category'] == 'Spring Migrant']):,} observations\n",
    "\n",
    "TOP 10 COUNTRIES BY OBSERVATIONS\n",
    "{'-'*80}\n",
    "{country_stats[['Country Name', 'Total Observations', 'Species Count']].head(10).to_string(index=False)}\n",
    "\n",
    "TOP 10 MOST OBSERVED SPECIES\n",
    "{'-'*80}\n",
    "{species_stats[['Common Name', 'Scientific Name', 'Total Observations', 'Countries Found']].head(10).to_string(index=False)}\n",
    "\n",
    "TEMPORAL DISTRIBUTION\n",
    "{'-'*80}\n",
    "Peak Observation Month: {month_names[int(monthly_obs.idxmax())] if pd.notna(monthly_obs.idxmax()) else 'N/A'}\n",
    "Average Observations per Month: {combined_df.groupby('month').size().mean():.0f}\n",
    "\n",
    "FILES GENERATED\n",
    "{'-'*80}\n",
    "1. combined_european_birds_full.csv - Complete combined dataset\n",
    "2. country_statistics_detailed.csv - Country-level statistics\n",
    "3. species_statistics_detailed.csv - Species-level statistics\n",
    "4. unspotted_species.csv - Species from reference list not observed\n",
    "5. spotted_reference_species.csv - Reference species that were observed\n",
    "6. habitat_type_species.csv - Species by habitat type (City/Countryside/Forest)\n",
    "7. migration_season_analysis.csv - Migration patterns by season\n",
    "8. european_bird_analysis_overview.png - Overview visualizations\n",
    "9. geographic_distribution_map.png - Geographic map\n",
    "10. correlation_matrix.png - Correlation analysis\n",
    "11. distribution_analysis.png - Distribution plots\n",
    "12. migration_habitat_analysis.png - Migration and habitat charts\n",
    "13. migration_season_heatmap.png - Seasonal migration heatmap\n",
    "\n",
    "{'='*80}\n",
    "END OF REPORT\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "with open('analysis_report_full.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✓ Comprehensive report saved: analysis_report_full.txt\")\n",
    "print(\"\\n\" + report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This analysis has successfully:\n",
    "- Combined all 47 European country CSV files into one dataset\n",
    "- Performed comprehensive statistical analysis on countries, species, and temporal patterns\n",
    "- Analyzed bird species from the reference list (spotted vs unspotted)\n",
    "- Classified observations by **habitat type using location features**: City Centre, Countryside, and Forest (works for ALL European countries)\n",
    "- Analyzed migration patterns with **split autumn migrants**: Nocturnal and Diurnal\n",
    "- Examined seasonal patterns across different migration groups\n",
    "- Generated visualizations showing patterns and distributions\n",
    "- Exported detailed statistics and reports\n",
    "\n",
    "All output files have been saved to the current directory.\n",
    "\n",
    "---\n",
    "\n",
    "**Output Files:**\n",
    "\n",
    "*CSV Data Files:*\n",
    "- `combined_european_birds_full.csv` - Complete combined dataset with all new fields\n",
    "- `country_statistics_detailed.csv` - Country-level statistics\n",
    "- `species_statistics_detailed.csv` - Species-level statistics\n",
    "- `unspotted_species.csv` - Species from reference list not observed\n",
    "- `spotted_reference_species.csv` - Reference species that were observed\n",
    "- `habitat_type_species.csv` - Species observations by habitat (City/Countryside/Forest)\n",
    "- `migration_season_analysis.csv` - Detailed migration patterns by season (with split autumn migrants)\n",
    "\n",
    "*Visualization Files:*\n",
    "- `european_bird_analysis_overview.png` - 6 overview charts (countries, species, temporal)\n",
    "- `geographic_distribution_map.png` - Geographic scatter plot of all observations\n",
    "- `correlation_matrix.png` - Country metrics correlation heatmap\n",
    "- `distribution_analysis.png` - 3 distribution histograms\n",
    "- `migration_habitat_analysis.png` - 6 charts for migration and habitat patterns\n",
    "- `migration_season_heatmap.png` - Heatmap showing migration patterns across seasons\n",
    "\n",
    "*Report:*\n",
    "- `analysis_report_full.txt` - Comprehensive text summary report\n",
    "\n",
    "**Key Improvements:**\n",
    "1. **Intelligent Habitat Classification**: Uses multilingual keywords (English, French, German, Italian, Spanish, Albanian) and location features to classify habitats across ALL European countries\n",
    "2. **Split Autumn Migrants**: Separates nocturnal and diurnal autumn migrants for more detailed migration analysis\n",
    "3. **Three Habitat Types**: City Centre, Countryside, and Forest classifications\n",
    "4. **Four Migration Categories**: Native (Resident), Autumn Migrant (Nocturnal), Autumn Migrant (Diurnal), and Spring Migrant\n",
    "\n",
    "**Classification Method:**\n",
    "- **Forest**: Identifies protected areas, national parks, mountains, and natural reserves using multilingual keywords\n",
    "- **City Centre**: Detects urban areas using city/town names and infrastructure keywords\n",
    "- **Countryside**: Agricultural and rural areas (default classification)\n",
    "- Works across all 47 European countries without country-specific hardcoding\n",
    "\n",
    "**Key Findings:**\n",
    "1. **Reference Species Coverage**: See what percentage of expected species were observed\n",
    "2. **Habitat Preferences**: Compare bird diversity and abundance across City/Countryside/Forest\n",
    "3. **Migration Patterns**: Understand when different migration groups (including split autumn migrants) are most active\n",
    "4. **Seasonal Trends**: Identify peak observation periods for each detailed migration category\n",
    "\n",
    "**Next Steps:**\n",
    "- Examine the CSV files for detailed breakdowns\n",
    "- Review visualizations for insights into patterns\n",
    "- Read the comprehensive report for a full summary\n",
    "- Use this notebook to further explore specific aspects of the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (da)",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
