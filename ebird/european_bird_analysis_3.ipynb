{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European Bird Sightings Analysis\n",
    "## Combining and Analyzing eBird Data from 47 European Countries\n",
    "\n",
    "This notebook will:\n",
    "1. Combine all your CSV files into one dataset\n",
    "2. Perform comprehensive statistical analysis\n",
    "3. Create visualizations\n",
    "4. Export results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Combine All CSV Files\n",
    "\n",
    "**Instructions:** \n",
    "- Update the `data_directory` path below to point to where your CSV files are stored\n",
    "- The script will automatically find all files matching the pattern `checkpoint_ebird_*.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 CSV files\n",
      "\n",
      "Files found:\n",
      "  1. checkpoint_ebird_IT_35378_obs.csv\n",
      "  2. checkpoint_ebird_UA_9461_obs.csv\n",
      "  3. checkpoint_ebird_LI_37185_obs.csv\n",
      "  4. checkpoint_ebird_MD_40387_obs.csv\n",
      "  5. checkpoint_ebird_EE_16886_obs.csv\n",
      "  6. checkpoint_ebird_RO_53262_obs.csv\n",
      "  7. checkpoint_ebird_BY_3405_obs.csv\n",
      "  8. checkpoint_ebird_GR_28235_obs.csv\n",
      "  9. checkpoint_ebird_SI_60424_obs.csv\n",
      "  10. checkpoint_ebird_VA_13010_obs.csv\n",
      "  11. checkpoint_ebird_SK_58864_obs.csv\n",
      "  12. checkpoint_ebird_TR_7826_obs.csv\n",
      "  13. checkpoint_ebird_RU_55325_obs.csv\n",
      "  14. checkpoint_ebird_CH_5357_obs.csv\n",
      "  15. checkpoint_ebird_PL_48925_obs.csv\n",
      "  16. checkpoint_ebird_NL_43115_obs.csv\n",
      "  17. checkpoint_ebird_DK_15823_obs.csv\n",
      "  18. checkpoint_ebird_PT_52100_obs.csv\n",
      "  19. checkpoint_ebird_SM_55354_obs.csv\n",
      "  20. checkpoint_ebird_SE_2926_obs.csv\n",
      "  21. checkpoint_ebird_BA_5784_obs.csv\n",
      "  22. checkpoint_ebird_XK_35604_obs.csv\n",
      "  23. checkpoint_ebird_IS_30734_obs.csv\n",
      "  24. checkpoint_ebird_LV_37106_obs.csv\n",
      "  25. checkpoint_ebird_IE_33051_obs.csv\n",
      "  26. checkpoint_ebird_FI_19526_obs.csv\n",
      "  27. checkpoint_ebird_AT_2000_obs.csv\n",
      "  28. checkpoint_ebird_BE_5471_obs.csv\n",
      "  29. checkpoint_ebird_LT_39023_obs.csv\n",
      "  30. checkpoint_ebird_AL_391_obs.csv\n",
      "  31. checkpoint_ebird_FR_22785_obs.csv\n",
      "  32. checkpoint_ebird_HU_30151_obs.csv\n",
      "  33. checkpoint_ebird_MC_40430_obs.csv\n",
      "  34. checkpoint_ebird_HR_9501_obs.csv\n",
      "  35. checkpoint_ebird_GB_12995_obs.csv\n",
      "  36. checkpoint_ebird_ES_64313_obs.csv\n",
      "  37. checkpoint_ebird_ME_40826_obs.csv\n",
      "  38. checkpoint_ebird_RS_56964_obs.csv\n",
      "  39. checkpoint_ebird_MK_43399_obs.csv\n",
      "  40. checkpoint_ebird_BG_7794_obs.csv\n",
      "  41. checkpoint_ebird_LU_39530_obs.csv\n",
      "  42. checkpoint_ebird_DE_26085_obs.csv\n",
      "  43. checkpoint_ebird_NO_46009_obs.csv\n",
      "  44. checkpoint_ebird_CY_10513_obs.csv\n",
      "  45. checkpoint_ebird_CZ_13476_obs.csv\n",
      "  46. checkpoint_ebird_AD_638_obs.csv\n",
      "  47. checkpoint_ebird_MT_39812_obs.csv\n"
     ]
    }
   ],
   "source": [
    "# UPDATE THIS PATH to where your CSV files are located\n",
    "data_directory = Path('/Users/dazedinthecity/Documents/GitHub/ceu-ds-project-groupB-2026/ebird/20spe_2022')  # Current directory - change as needed\n",
    "\n",
    "# Find all eBird CSV files\n",
    "csv_files = list(data_directory.glob('checkpoint_ebird_*.csv'))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "print(\"\\nFiles found:\")\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    print(f\"  {i}. {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n",
      "\n",
      "✓ Loaded checkpoint_ebird_IT_35378_obs.csv: 35,378 observations\n",
      "✓ Loaded checkpoint_ebird_UA_9461_obs.csv: 9,461 observations\n",
      "✓ Loaded checkpoint_ebird_LI_37185_obs.csv: 37,185 observations\n",
      "✓ Loaded checkpoint_ebird_MD_40387_obs.csv: 40,387 observations\n",
      "✓ Loaded checkpoint_ebird_EE_16886_obs.csv: 16,886 observations\n",
      "✓ Loaded checkpoint_ebird_RO_53262_obs.csv: 53,262 observations\n",
      "✓ Loaded checkpoint_ebird_BY_3405_obs.csv: 3,405 observations\n",
      "✓ Loaded checkpoint_ebird_GR_28235_obs.csv: 28,235 observations\n",
      "✓ Loaded checkpoint_ebird_SI_60424_obs.csv: 60,424 observations\n",
      "✓ Loaded checkpoint_ebird_VA_13010_obs.csv: 13,010 observations\n",
      "✓ Loaded checkpoint_ebird_SK_58864_obs.csv: 58,864 observations\n",
      "✓ Loaded checkpoint_ebird_TR_7826_obs.csv: 7,826 observations\n",
      "✓ Loaded checkpoint_ebird_RU_55325_obs.csv: 55,325 observations\n",
      "✓ Loaded checkpoint_ebird_CH_5357_obs.csv: 5,357 observations\n",
      "✓ Loaded checkpoint_ebird_PL_48925_obs.csv: 48,925 observations\n",
      "✓ Loaded checkpoint_ebird_NL_43115_obs.csv: 43,115 observations\n",
      "✓ Loaded checkpoint_ebird_DK_15823_obs.csv: 15,823 observations\n",
      "✓ Loaded checkpoint_ebird_PT_52100_obs.csv: 52,100 observations\n",
      "✓ Loaded checkpoint_ebird_SM_55354_obs.csv: 55,354 observations\n",
      "✓ Loaded checkpoint_ebird_SE_2926_obs.csv: 2,926 observations\n",
      "✓ Loaded checkpoint_ebird_BA_5784_obs.csv: 5,784 observations\n",
      "✓ Loaded checkpoint_ebird_XK_35604_obs.csv: 35,604 observations\n",
      "✓ Loaded checkpoint_ebird_IS_30734_obs.csv: 30,734 observations\n",
      "✓ Loaded checkpoint_ebird_LV_37106_obs.csv: 37,106 observations\n",
      "✓ Loaded checkpoint_ebird_IE_33051_obs.csv: 33,051 observations\n",
      "✓ Loaded checkpoint_ebird_FI_19526_obs.csv: 19,526 observations\n",
      "✓ Loaded checkpoint_ebird_AT_2000_obs.csv: 2,000 observations\n",
      "✓ Loaded checkpoint_ebird_BE_5471_obs.csv: 5,471 observations\n",
      "✓ Loaded checkpoint_ebird_LT_39023_obs.csv: 39,023 observations\n",
      "✓ Loaded checkpoint_ebird_AL_391_obs.csv: 391 observations\n",
      "✓ Loaded checkpoint_ebird_FR_22785_obs.csv: 22,785 observations\n",
      "✓ Loaded checkpoint_ebird_HU_30151_obs.csv: 30,151 observations\n",
      "✓ Loaded checkpoint_ebird_MC_40430_obs.csv: 40,430 observations\n",
      "✓ Loaded checkpoint_ebird_HR_9501_obs.csv: 9,501 observations\n",
      "✓ Loaded checkpoint_ebird_GB_12995_obs.csv: 12,995 observations\n",
      "✓ Loaded checkpoint_ebird_ES_64313_obs.csv: 64,313 observations\n",
      "✓ Loaded checkpoint_ebird_ME_40826_obs.csv: 40,826 observations\n",
      "✓ Loaded checkpoint_ebird_RS_56964_obs.csv: 56,964 observations\n",
      "✓ Loaded checkpoint_ebird_MK_43399_obs.csv: 43,399 observations\n",
      "✓ Loaded checkpoint_ebird_BG_7794_obs.csv: 7,794 observations\n",
      "✓ Loaded checkpoint_ebird_LU_39530_obs.csv: 39,530 observations\n",
      "✓ Loaded checkpoint_ebird_DE_26085_obs.csv: 26,085 observations\n",
      "✓ Loaded checkpoint_ebird_NO_46009_obs.csv: 46,009 observations\n",
      "✓ Loaded checkpoint_ebird_CY_10513_obs.csv: 10,513 observations\n",
      "✓ Loaded checkpoint_ebird_CZ_13476_obs.csv: 13,476 observations\n",
      "✓ Loaded checkpoint_ebird_AD_638_obs.csv: 638 observations\n",
      "✓ Loaded checkpoint_ebird_MT_39812_obs.csv: 39,812 observations\n",
      "\n",
      "============================================================\n",
      "Successfully loaded 47 files\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load and combine all CSV files\n",
    "print(\"Loading CSV files...\\n\")\n",
    "\n",
    "dfs = []\n",
    "file_info = []\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "        \n",
    "        # Extract country code from filename (e.g., AD from checkpoint_ebird_AD_638_obs.csv)\n",
    "        country_code = file.stem.split('_')[2]\n",
    "        \n",
    "        file_info.append({\n",
    "            'File': file.name,\n",
    "            'Country Code': country_code,\n",
    "            'Observations': len(df)\n",
    "        })\n",
    "        \n",
    "        print(f\"✓ Loaded {file.name}: {len(df):,} observations\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {file.name}: {e}\")\n",
    "\n",
    "# Create summary dataframe\n",
    "files_df = pd.DataFrame(file_info).sort_values('Observations', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Successfully loaded {len(dfs)} files\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File Loading Summary:\n",
      "                             File Country Code  Observations\n",
      "checkpoint_ebird_ES_64313_obs.csv           ES         64313\n",
      "checkpoint_ebird_SI_60424_obs.csv           SI         60424\n",
      "checkpoint_ebird_SK_58864_obs.csv           SK         58864\n",
      "checkpoint_ebird_RS_56964_obs.csv           RS         56964\n",
      "checkpoint_ebird_SM_55354_obs.csv           SM         55354\n",
      "checkpoint_ebird_RU_55325_obs.csv           RU         55325\n",
      "checkpoint_ebird_RO_53262_obs.csv           RO         53262\n",
      "checkpoint_ebird_PT_52100_obs.csv           PT         52100\n",
      "checkpoint_ebird_PL_48925_obs.csv           PL         48925\n",
      "checkpoint_ebird_NO_46009_obs.csv           NO         46009\n",
      "checkpoint_ebird_MK_43399_obs.csv           MK         43399\n",
      "checkpoint_ebird_NL_43115_obs.csv           NL         43115\n",
      "checkpoint_ebird_ME_40826_obs.csv           ME         40826\n",
      "checkpoint_ebird_MC_40430_obs.csv           MC         40430\n",
      "checkpoint_ebird_MD_40387_obs.csv           MD         40387\n",
      "checkpoint_ebird_MT_39812_obs.csv           MT         39812\n",
      "checkpoint_ebird_LU_39530_obs.csv           LU         39530\n",
      "checkpoint_ebird_LT_39023_obs.csv           LT         39023\n",
      "checkpoint_ebird_LI_37185_obs.csv           LI         37185\n",
      "checkpoint_ebird_LV_37106_obs.csv           LV         37106\n",
      "checkpoint_ebird_XK_35604_obs.csv           XK         35604\n",
      "checkpoint_ebird_IT_35378_obs.csv           IT         35378\n",
      "checkpoint_ebird_IE_33051_obs.csv           IE         33051\n",
      "checkpoint_ebird_IS_30734_obs.csv           IS         30734\n",
      "checkpoint_ebird_HU_30151_obs.csv           HU         30151\n",
      "checkpoint_ebird_GR_28235_obs.csv           GR         28235\n",
      "checkpoint_ebird_DE_26085_obs.csv           DE         26085\n",
      "checkpoint_ebird_FR_22785_obs.csv           FR         22785\n",
      "checkpoint_ebird_FI_19526_obs.csv           FI         19526\n",
      "checkpoint_ebird_EE_16886_obs.csv           EE         16886\n",
      "checkpoint_ebird_DK_15823_obs.csv           DK         15823\n",
      "checkpoint_ebird_CZ_13476_obs.csv           CZ         13476\n",
      "checkpoint_ebird_VA_13010_obs.csv           VA         13010\n",
      "checkpoint_ebird_GB_12995_obs.csv           GB         12995\n",
      "checkpoint_ebird_CY_10513_obs.csv           CY         10513\n",
      " checkpoint_ebird_HR_9501_obs.csv           HR          9501\n",
      " checkpoint_ebird_UA_9461_obs.csv           UA          9461\n",
      " checkpoint_ebird_TR_7826_obs.csv           TR          7826\n",
      " checkpoint_ebird_BG_7794_obs.csv           BG          7794\n",
      " checkpoint_ebird_BA_5784_obs.csv           BA          5784\n",
      " checkpoint_ebird_BE_5471_obs.csv           BE          5471\n",
      " checkpoint_ebird_CH_5357_obs.csv           CH          5357\n",
      " checkpoint_ebird_BY_3405_obs.csv           BY          3405\n",
      " checkpoint_ebird_SE_2926_obs.csv           SE          2926\n",
      " checkpoint_ebird_AT_2000_obs.csv           AT          2000\n",
      "  checkpoint_ebird_AD_638_obs.csv           AD           638\n",
      "  checkpoint_ebird_AL_391_obs.csv           AL           391\n",
      "\n",
      "Total observations to combine: 1,357,159\n"
     ]
    }
   ],
   "source": [
    "# Display file loading summary\n",
    "print(\"\\nFile Loading Summary:\")\n",
    "print(files_df.to_string(index=False))\n",
    "print(f\"\\nTotal observations to combine: {files_df['Observations'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes\n",
    "print(\"Combining all dataframes...\")\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Combined dataset created!\")\n",
    "print(f\"  Total observations: {len(combined_df):,}\")\n",
    "print(f\"  Total columns: {len(combined_df.columns)}\")\n",
    "print(f\"  Memory usage: {combined_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of combined dataset:\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data structure\n",
    "print(\"\\nDataset Information:\")\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime\n",
    "combined_df['obsDt'] = pd.to_datetime(combined_df['obsDt'], errors='coerce')\n",
    "\n",
    "# Extract temporal features\n",
    "combined_df['year'] = combined_df['obsDt'].dt.year\n",
    "combined_df['month'] = combined_df['obsDt'].dt.month\n",
    "combined_df['day_of_week'] = combined_df['obsDt'].dt.dayofweek\n",
    "combined_df['day_of_year'] = combined_df['obsDt'].dt.dayofyear\n",
    "\n",
    "# Convert count to numeric\n",
    "combined_df['howMany'] = pd.to_numeric(combined_df['howMany'], errors='coerce')\n",
    "\n",
    "print(\"✓ Data preprocessing complete!\")\n",
    "print(f\"\\nDate range: {combined_df['obsDt'].min()} to {combined_df['obsDt'].max()}\")\n",
    "print(f\"Years covered: {sorted(combined_df['year'].dropna().unique().astype(int).tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "print(\"=\"*80)\n",
    "print(\"OVERALL DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal observations: {len(combined_df):,}\")\n",
    "print(f\"Number of countries: {combined_df['countryCode'].nunique()}\")\n",
    "print(f\"Number of unique species: {combined_df['speciesCode'].nunique()}\")\n",
    "print(f\"Number of unique locations: {combined_df['locId'].nunique()}\")\n",
    "print(f\"Number of observers: {combined_df['userDisplayName'].nunique()}\")\n",
    "print(f\"Number of checklists: {combined_df['subId'].nunique()}\")\n",
    "print(f\"Number of subnational regions: {combined_df['subnational1Code'].nunique()}\")\n",
    "\n",
    "# Count data statistics\n",
    "count_data = combined_df[combined_df['howMany'].notna()]\n",
    "print(f\"\\nObservations with count data: {len(count_data):,} ({len(count_data)/len(combined_df)*100:.1f}%)\")\n",
    "if len(count_data) > 0:\n",
    "    print(f\"Total birds counted: {count_data['howMany'].sum():,.0f}\")\n",
    "    print(f\"Average count per observation: {count_data['howMany'].mean():.2f}\")\n",
    "    print(f\"Median count: {count_data['howMany'].median():.0f}\")\n",
    "    print(f\"Maximum count in single observation: {count_data['howMany'].max():,.0f}\")\n",
    "    print(f\"Minimum count: {count_data['howMany'].min():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-level statistics\n",
    "country_stats = combined_df.groupby(['countryCode', 'countryName']).agg({\n",
    "    'obsId': 'count',\n",
    "    'speciesCode': 'nunique',\n",
    "    'locId': 'nunique',\n",
    "    'userDisplayName': 'nunique',\n",
    "    'subId': 'nunique',\n",
    "    'howMany': lambda x: x.sum() if x.notna().any() else 0\n",
    "}).reset_index()\n",
    "\n",
    "country_stats.columns = ['Country Code', 'Country Name', 'Total Observations', \n",
    "                         'Species Count', 'Unique Locations', 'Number of Observers',\n",
    "                         'Checklists', 'Total Birds Counted']\n",
    "\n",
    "country_stats = country_stats.sort_values('Total Observations', ascending=False)\n",
    "\n",
    "print(\"\\nSTATISTICS BY COUNTRY\")\n",
    "print(\"=\"*120)\n",
    "print(country_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country summary statistics\n",
    "print(\"\\nCOUNTRY SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average observations per country: {country_stats['Total Observations'].mean():,.0f}\")\n",
    "print(f\"Median observations per country: {country_stats['Total Observations'].median():,.0f}\")\n",
    "print(f\"Country with most observations: {country_stats.iloc[0]['Country Name']} ({country_stats.iloc[0]['Total Observations']:,})\")\n",
    "print(f\"Country with most species: {country_stats.sort_values('Species Count', ascending=False).iloc[0]['Country Name']} ({country_stats.sort_values('Species Count', ascending=False).iloc[0]['Species Count']})\")\n",
    "print(f\"Country with most observers: {country_stats.sort_values('Number of Observers', ascending=False).iloc[0]['Country Name']} ({country_stats.sort_values('Number of Observers', ascending=False).iloc[0]['Number of Observers']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Species Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species statistics\n",
    "species_stats = combined_df.groupby(['speciesCode', 'comName', 'sciName']).agg({\n",
    "    'obsId': 'count',\n",
    "    'countryCode': 'nunique',\n",
    "    'locId': 'nunique',\n",
    "    'howMany': lambda x: x.sum() if x.notna().any() else 0\n",
    "}).reset_index()\n",
    "\n",
    "species_stats.columns = ['Species Code', 'Common Name', 'Scientific Name', \n",
    "                        'Total Observations', 'Countries Found', 'Locations', 'Total Count']\n",
    "\n",
    "species_stats = species_stats.sort_values('Total Observations', ascending=False)\n",
    "\n",
    "print(\"\\nTOP 30 MOST OBSERVED SPECIES\")\n",
    "print(\"=\"*120)\n",
    "print(species_stats.head(30).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species diversity analysis\n",
    "print(\"\\nSPECIES DIVERSITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total unique species: {len(species_stats)}\")\n",
    "print(f\"\\nSpecies distribution:\")\n",
    "print(f\"  Species found in 1 country only: {(species_stats['Countries Found'] == 1).sum()}\")\n",
    "print(f\"  Species found in 2-5 countries: {((species_stats['Countries Found'] >= 2) & (species_stats['Countries Found'] <= 5)).sum()}\")\n",
    "print(f\"  Species found in 6-10 countries: {((species_stats['Countries Found'] >= 6) & (species_stats['Countries Found'] <= 10)).sum()}\")\n",
    "print(f\"  Species found in 11+ countries: {(species_stats['Countries Found'] >= 11).sum()}\")\n",
    "print(f\"\\nMost widespread species: {species_stats.sort_values('Countries Found', ascending=False).iloc[0]['Common Name']} (found in {species_stats.sort_values('Countries Found', ascending=False).iloc[0]['Countries Found']} countries)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal distribution\n",
    "print(\"\\nTEMPORAL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# By year\n",
    "yearly_obs = combined_df.groupby('year').size().sort_index()\n",
    "print(\"\\nObservations by Year:\")\n",
    "for year, count in yearly_obs.items():\n",
    "    if pd.notna(year):\n",
    "        print(f\"  {int(year)}: {count:,}\")\n",
    "\n",
    "# By month\n",
    "monthly_obs = combined_df.groupby('month').size().sort_index()\n",
    "month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',\n",
    "               7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "print(\"\\nObservations by Month:\")\n",
    "for month, count in monthly_obs.items():\n",
    "    if pd.notna(month):\n",
    "        print(f\"  {month_names[int(month)]}: {count:,}\")\n",
    "\n",
    "# Peak observation period\n",
    "peak_month = monthly_obs.idxmax()\n",
    "if pd.notna(peak_month):\n",
    "    print(f\"\\nPeak observation month: {month_names[int(peak_month)]} ({monthly_obs.max():,} observations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic distribution\n",
    "print(\"\\nGEOGRAPHIC DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Latitude range: {combined_df['lat'].min():.4f}° to {combined_df['lat'].max():.4f}°\")\n",
    "print(f\"Longitude range: {combined_df['lng'].min():.4f}° to {combined_df['lng'].max():.4f}°\")\n",
    "print(f\"\\nLatitude statistics:\")\n",
    "print(f\"  Mean: {combined_df['lat'].mean():.4f}°\")\n",
    "print(f\"  Median: {combined_df['lat'].median():.4f}°\")\n",
    "print(f\"\\nLongitude statistics:\")\n",
    "print(f\"  Mean: {combined_df['lng'].mean():.4f}°\")\n",
    "print(f\"  Median: {combined_df['lng'].median():.4f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bird Species Reference Analysis\n",
    "\n",
    "This section connects the observation data with a reference list of bird species to identify:\n",
    "1. Which species from the reference list were not spotted\n",
    "2. Urban vs countryside sighting patterns\n",
    "3. Migration patterns by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bird species reference file\n",
    "# UPDATE THIS PATH if your Excel file is in a different location\n",
    "reference_file = '/Users/dazedinthecity/Documents/GitHub/ceu-ds-project-groupB-2026/datasets/bird_species_new_add.xlsx'  # Change as needed\n",
    "\n",
    "try:\n",
    "    bird_reference = pd.read_excel(reference_file)\n",
    "    print(\"✓ Bird species reference file loaded successfully!\")\n",
    "    print(f\"\\nReference file contains {len(bird_reference)} rows\")\n",
    "    print(f\"\\nColumns: {bird_reference.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find '{reference_file}'\")\n",
    "    print(\"Please update the reference_file path in the cell above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and prepare the reference data\n",
    "# Remove group header rows (those without eBird codes)\n",
    "bird_reference_clean = bird_reference[bird_reference['eBird Code'].notna()].copy()\n",
    "\n",
    "# Standardize column names\n",
    "bird_reference_clean.columns = ['Bird Species', 'eBird Code','Migration Period','Migration Group', 'Status', 'Trend Summary']\n",
    "\n",
    "print(f\"Total species in reference list: {len(bird_reference_clean)}\")\n",
    "print(f\"\\nMigration groups:\")\n",
    "print(bird_reference_clean['Migration Group'].value_counts())\n",
    "print(f\"\\nFirst few entries:\")\n",
    "print(bird_reference_clean[['Bird Species', 'eBird Code', 'Migration Group']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Unspotted Species Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which species from the reference list were NOT spotted\n",
    "reference_species_codes = set(bird_reference_clean['eBird Code'].str.lower())\n",
    "observed_species_codes = set(combined_df['speciesCode'].str.lower())\n",
    "\n",
    "unspotted_codes = reference_species_codes - observed_species_codes\n",
    "spotted_codes = reference_species_codes & observed_species_codes\n",
    "\n",
    "# Get details of unspotted species\n",
    "unspotted_species = bird_reference_clean[\n",
    "    bird_reference_clean['eBird Code'].str.lower().isin(unspotted_codes)\n",
    "].copy()\n",
    "\n",
    "spotted_species = bird_reference_clean[\n",
    "    bird_reference_clean['eBird Code'].str.lower().isin(spotted_codes)\n",
    "].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UNSPOTTED SPECIES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal species in reference list: {len(bird_reference_clean)}\")\n",
    "print(f\"Species spotted: {len(spotted_species)} ({len(spotted_species)/len(bird_reference_clean)*100:.1f}%)\")\n",
    "print(f\"Species NOT spotted: {len(unspotted_species)} ({len(unspotted_species)/len(bird_reference_clean)*100:.1f}%)\")\n",
    "\n",
    "if len(unspotted_species) > 0:\n",
    "    print(f\"\\nUNSPOTTED SPECIES:\")\n",
    "    print(\"-\"*80)\n",
    "    print(unspotted_species[['Bird Species', 'eBird Code', 'Migration Group', 'Status']].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nUnspotted species by migration group:\")\n",
    "    print(unspotted_species['Migration Group'].value_counts())\n",
    "else:\n",
    "    print(\"\\n✓ All reference species were spotted!\")\n",
    "\n",
    "print(f\"\\n\\nSPOTTED SPECIES:\")\n",
    "print(\"-\"*80)\n",
    "print(spotted_species[['Bird Species', 'eBird Code', 'Migration Group', 'Status']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Location Type Analysis: Forest, Countryside, and City Centre\n",
    "\n",
    "This analysis uses geographic coordinates to categorize observations into three habitat types:\n",
    "- **City Centre**: Urban areas including capitals, major cities, towns, and villages\n",
    "- **Countryside**: Agricultural lands, rural areas, and open habitats\n",
    "- **Forest**: Woodlands, forested areas, mountain regions, and protected natural areas\n",
    "\n",
    "**Note**: This analysis uses a combination of:\n",
    "1. Location name keywords for protected areas and natural landmarks\n",
    "2. Population density heuristics based on proximity to populated places\n",
    "3. Elevation and geographic features to identify forested/mountainous areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank subnations by species sightings for each country\n",
    "# Group by country, species, and subnation to count observations\n",
    "species_subnation_rankings = combined_df.groupby(\n",
    "    ['countryCode', 'speciesCode', 'subnation1Code', 'subnationName']\n",
    ").size().reset_index(name='sightings')\n",
    "\n",
    "# Rank subnations within each country-species combination\n",
    "species_subnation_rankings['rank'] = species_subnation_rankings.groupby(\n",
    "    ['countryCode', 'speciesCode']\n",
    ")['sightings'].rank(method='dense', ascending=False).astype(int)\n",
    "\n",
    "# Sort for better readability\n",
    "species_subnation_rankings = species_subnation_rankings.sort_values(\n",
    "    ['countryCode', 'speciesCode', 'rank']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Display sample results\n",
    "print(\"Sample Rankings (showing top-ranked subnations for each country-species pair):\")\n",
    "print(\"\\nFirst 20 rows:\")\n",
    "print(species_subnation_rankings.head(20))\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total country-species-subnation combinations: {len(species_subnation_rankings):,}\")\n",
    "print(f\"Countries analyzed: {species_subnation_rankings['countryCode'].nunique()}\")\n",
    "print(f\"Species analyzed: {species_subnation_rankings['speciesCode'].nunique()}\")\n",
    "print(f\"Subnations analyzed: {species_subnation_rankings['subnation1Code'].nunique()}\")\n",
    "\n",
    "# Example: Show top 3 subnations for a specific country and species\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Example - Top 3 subnations in Italy (IT) for a specific species:\")\n",
    "sample_species = species_subnation_rankings[species_subnation_rankings['countryCode'] == 'IT']['speciesCode'].iloc[0]\n",
    "italy_example = species_subnation_rankings[\n",
    "    (species_subnation_rankings['countryCode'] == 'IT') & \n",
    "    (species_subnation_rankings['speciesCode'] == sample_species) &\n",
    "    (species_subnation_rankings['rank'] <= 3)\n",
    "]\n",
    "print(f\"\\nSpecies: {sample_species}\")\n",
    "print(italy_example[['rank', 'subnation1Code', 'subnationName', 'sightings']])\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'species_subnation_rankings_by_country.csv'\n",
    "species_subnation_rankings.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"\\n✓ Rankings saved to: {output_file}\")\n",
    "print(f\"  Columns: countryCode, speciesCode, subnation1Code, subnationName, sightings, rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Migration Pattern Analysis by Season\n",
    "\n",
    "Analyzing bird sightings based on migration groups across different seasonal periods:\n",
    "- **Spring Migration Period**: Mid-March to Mid-June\n",
    "- **Summer Period**: July to Early August\n",
    "- **Autumn Migration Period**: Late August to Early December  \n",
    "- **Winter Period**: Late December to Early March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, map migration groups to our observation data\n",
    "# Create a mapping dictionary from the reference file\n",
    "migration_map = dict(zip(\n",
    "    bird_reference_clean['eBird Code'].str.lower(),\n",
    "    bird_reference_clean['Migration Period']\n",
    "))\n",
    "\n",
    "# Map migration groups to observations\n",
    "combined_df['migration_group'] = combined_df['speciesCode'].str.lower().map(migration_map)\n",
    "\n",
    "# Classify migration groups into detailed categories\n",
    "# Split Autumn Migrants into Nocturnal and Diurnal\n",
    "def classify_migration(migration_group):\n",
    "    if pd.isna(migration_group):\n",
    "        return 'Not in Reference'\n",
    "    elif migration_group == 'Resident':\n",
    "        return 'Native (Resident)'\n",
    "    elif migration_group == 'Nocturnal':\n",
    "        return 'Autumn Migrant (Nocturnal)'\n",
    "    elif migration_group == 'Diurnal':\n",
    "        return 'Autumn Migrant (Diurnal)'\n",
    "    elif migration_group == 'Spring Arrival':\n",
    "        return 'Spring Migrant'\n",
    "    else:\n",
    "        return migration_group\n",
    "\n",
    "combined_df['migration_category'] = combined_df['migration_group'].apply(classify_migration)\n",
    "\n",
    "print(\"Migration group distribution in observations:\")\n",
    "print(combined_df['migration_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seasonal periods\n",
    "def get_season(date):\n",
    "    \"\"\"\n",
    "    Classify observation date into seasonal periods.\n",
    "    \"\"\"\n",
    "    if pd.isna(date):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    \n",
    "    # Spring Migration: Mid-March (Mar 15) to Mid-June (Jun 15)\n",
    "    if (month == 3 and day >= 15) or (month in [4, 5]) or (month == 6 and day <= 15):\n",
    "        return 'Spring Migration (Mid-Mar to Mid-Jun)'\n",
    "    \n",
    "    # Summer: July and Early August (to Aug 20)\n",
    "    elif month == 7 or (month == 8 and day <= 20):\n",
    "        return 'Summer (Jul to Early Aug)'\n",
    "    \n",
    "    # Autumn Migration: Late August (Aug 21) to Early December (Dec 10)\n",
    "    elif (month == 8 and day > 20) or (month in [9, 10, 11]) or (month == 12 and day <= 10):\n",
    "        return 'Autumn Migration (Late Aug to Early Dec)'\n",
    "    \n",
    "    # Winter: Late December (Dec 11+) to Early March (Mar 14)\n",
    "    else:  # (month == 12 and day > 10) or (month in [1, 2]) or (month == 3 and day < 15)\n",
    "        return 'Winter (Late Dec to Early Mar)'\n",
    "\n",
    "# Apply seasonal classification\n",
    "combined_df['season'] = combined_df['obsDt'].apply(get_season)\n",
    "\n",
    "print(\"Observations by season:\")\n",
    "season_counts = combined_df['season'].value_counts()\n",
    "for season, count in season_counts.items():\n",
    "    print(f\"  {season}: {count:,} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-tabulation of migration groups vs seasons\n",
    "print(\"=\"*100)\n",
    "print(\"MIGRATION PATTERN ANALYSIS BY SEASON\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Filter to only include birds in the reference list\n",
    "reference_obs = combined_df[combined_df['migration_category'] != 'Not in Reference'].copy()\n",
    "\n",
    "migration_season_crosstab = pd.crosstab(\n",
    "    reference_obs['migration_category'],\n",
    "    reference_obs['season'],\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(\"\\nObservations by Migration Group and Season:\")\n",
    "print(\"-\"*100)\n",
    "print(migration_season_crosstab)\n",
    "\n",
    "# Calculate percentages\n",
    "print(\"\\n\\nPercentage distribution within each migration group:\")\n",
    "print(\"-\"*100)\n",
    "migration_season_pct = pd.crosstab(\n",
    "    reference_obs['migration_category'],\n",
    "    reference_obs['season'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "print(migration_season_pct.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis for each migration category\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"DETAILED SEASONAL ANALYSIS BY MIGRATION GROUP\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for migration_cat in ['Native (Resident)', 'Autumn Migrant (Nocturnal)', 'Autumn Migrant (Diurnal)', 'Spring Migrant']:\n",
    "    print(f\"\\n{migration_cat.upper()}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    category_data = reference_obs[reference_obs['migration_category'] == migration_cat]\n",
    "    \n",
    "    if len(category_data) > 0:\n",
    "        print(f\"Total observations: {len(category_data):,}\")\n",
    "        print(f\"Number of species: {category_data['speciesCode'].nunique()}\")\n",
    "        \n",
    "        # Seasonal breakdown\n",
    "        seasonal_breakdown = category_data.groupby('season').agg({\n",
    "            'obsId': 'count',\n",
    "            'speciesCode': 'nunique'\n",
    "        }).reset_index()\n",
    "        seasonal_breakdown.columns = ['Season', 'Observations', 'Species Count']\n",
    "        seasonal_breakdown['Percentage'] = (seasonal_breakdown['Observations'] / len(category_data) * 100).round(1)\n",
    "        \n",
    "        print(\"\\nSeasonal distribution:\")\n",
    "        print(seasonal_breakdown.to_string(index=False))\n",
    "        \n",
    "        # Top species in this category\n",
    "        top_species = category_data.groupby(['comName']).size().reset_index(name='Observations')\n",
    "        top_species = top_species.sort_values('Observations', ascending=False).head(5)\n",
    "        print(f\"\\nTop 5 species in this group:\")\n",
    "        print(top_species.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"No observations found for {migration_cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Migration Pattern Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for migration patterns\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Habitat type distribution\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "habitat_data = combined_df[combined_df['habitat_type'] != 'Unknown']['habitat_type'].value_counts()\n",
    "colors_habitat = ['#3498db', '#2ecc71', '#8B4513']\n",
    "ax1.pie(habitat_data.values, labels=habitat_data.index, autopct='%1.1f%%',\n",
    "        colors=colors_habitat, startangle=90)\n",
    "ax1.set_title('Habitat Type Distribution', fontweight='bold', fontsize=12)\n",
    "\n",
    "# 2. Species spotted vs unspotted\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "spotted_data = pd.Series({\n",
    "    'Spotted': len(spotted_species),\n",
    "    'Not Spotted': len(unspotted_species)\n",
    "})\n",
    "colors_spot = ['#2ecc71', '#e74c3c']\n",
    "ax2.pie(spotted_data.values, labels=spotted_data.index, autopct='%1.1f%%',\n",
    "        colors=colors_spot, startangle=90)\n",
    "ax2.set_title('Reference Species: Spotted vs Unspotted', fontweight='bold', fontsize=12)\n",
    "\n",
    "# 3. Migration groups distribution\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "migration_dist = reference_obs['migration_category'].value_counts()\n",
    "colors_mig = ['#3498db', '#e67e22', '#f39c12', '#9b59b6']\n",
    "ax3.bar(range(len(migration_dist)), migration_dist.values, color=colors_mig[:len(migration_dist)], alpha=0.7)\n",
    "ax3.set_xticks(range(len(migration_dist)))\n",
    "ax3.set_xticklabels([label.replace('Autumn Migrant ', 'Autumn\\n').replace(' (', '\\n(') \n",
    "                      for label in migration_dist.index], rotation=0, ha='center', fontsize=9)\n",
    "ax3.set_ylabel('Number of Observations')\n",
    "ax3.set_title('Observations by Migration Category', fontweight='bold', fontsize=12)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Seasonal observations by migration group (stacked bar)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "season_order = ['Spring Migration (Mid-Mar to Mid-Jun)', 'Summer (Jul to Early Aug)',\n",
    "                'Autumn Migration (Late Aug to Early Dec)', 'Winter (Late Dec to Early Mar)']\n",
    "migration_categories = ['Native (Resident)', 'Autumn Migrant (Nocturnal)', \n",
    "                       'Autumn Migrant (Diurnal)', 'Spring Migrant']\n",
    "\n",
    "# Prepare data for stacked bar chart\n",
    "season_data_dict = {cat: [] for cat in migration_categories}\n",
    "for season in season_order:\n",
    "    if season in reference_obs['season'].values:\n",
    "        for cat in migration_categories:\n",
    "            count = len(reference_obs[(reference_obs['season'] == season) & \n",
    "                                     (reference_obs['migration_category'] == cat)])\n",
    "            season_data_dict[cat].append(count)\n",
    "    else:\n",
    "        for cat in migration_categories:\n",
    "            season_data_dict[cat].append(0)\n",
    "\n",
    "x = range(len(season_order))\n",
    "width = 0.6\n",
    "bottom = [0] * len(season_order)\n",
    "colors_migration = ['#3498db', '#e67e22', '#f39c12', '#9b59b6']\n",
    "\n",
    "for i, cat in enumerate(migration_categories):\n",
    "    if any(season_data_dict[cat]):  # Only plot if there's data\n",
    "        label = cat.replace('Autumn Migrant ', 'Autumn ').replace(' (', ' (')\n",
    "        ax4.bar(x, season_data_dict[cat], width, label=label, bottom=bottom, \n",
    "                color=colors_migration[i], alpha=0.8)\n",
    "        bottom = [b + v for b, v in zip(bottom, season_data_dict[cat])]\n",
    "\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(['Spring\\nMigration', 'Summer', 'Autumn\\nMigration', 'Winter'], fontsize=9)\n",
    "ax4.set_ylabel('Number of Observations')\n",
    "ax4.set_title('Seasonal Observations by Migration Group', fontweight='bold', fontsize=12)\n",
    "ax4.legend(fontsize=8, loc='upper left')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Top species in city centres\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "if 'City Centre' in combined_df['habitat_type'].values:\n",
    "    city_top = combined_df[combined_df['habitat_type'] == 'City Centre'].groupby('comName').size().sort_values(ascending=False).head(10)\n",
    "    ax5.barh(range(len(city_top)), city_top.values, color='steelblue', alpha=0.7)\n",
    "    ax5.set_yticks(range(len(city_top)))\n",
    "    labels = [name[:20] + '...' if len(name) > 20 else name for name in city_top.index]\n",
    "    ax5.set_yticklabels(labels, fontsize=9)\n",
    "    ax5.set_xlabel('Number of Observations')\n",
    "    ax5.set_title('Top 10 Species in City Centres', fontweight='bold', fontsize=12)\n",
    "    ax5.invert_yaxis()\n",
    "\n",
    "# 6. Top species in forests\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "if 'Forest' in combined_df['habitat_type'].values:\n",
    "    forest_top = combined_df[combined_df['habitat_type'] == 'Forest'].groupby('comName').size().sort_values(ascending=False).head(10)\n",
    "    ax6.barh(range(len(forest_top)), forest_top.values, color='forestgreen', alpha=0.7)\n",
    "    ax6.set_yticks(range(len(forest_top)))\n",
    "    labels = [name[:20] + '...' if len(name) > 20 else name for name in forest_top.index]\n",
    "    ax6.set_yticklabels(labels, fontsize=9)\n",
    "    ax6.set_xlabel('Number of Observations')\n",
    "    ax6.set_title('Top 10 Species in Forests', fontweight='bold', fontsize=12)\n",
    "    ax6.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('migration_habitat_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Migration and habitat analysis charts created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of migration patterns across seasons\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "heatmap_data = reference_obs.groupby(['migration_category', 'season']).size().unstack(fill_value=0)\n",
    "\n",
    "# Reorder columns to match season order\n",
    "column_order = [col for col in season_order if col in heatmap_data.columns]\n",
    "heatmap_data = heatmap_data[column_order]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Number of Observations'},\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "\n",
    "plt.title('Migration Pattern Heatmap: Observations by Season', fontweight='bold', fontsize=14, pad=20)\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Migration Category', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('migration_season_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Migration season heatmap created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Top countries by observations\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "top_countries = country_stats.head(20)\n",
    "ax1.barh(range(len(top_countries)), top_countries['Total Observations'], color='steelblue')\n",
    "ax1.set_yticks(range(len(top_countries)))\n",
    "ax1.set_yticklabels(top_countries['Country Name'], fontsize=9)\n",
    "ax1.set_xlabel('Number of Observations')\n",
    "ax1.set_title('Top 20 Countries by Observations', fontweight='bold', fontsize=12)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# 2. Top countries by species diversity\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "top_diversity = country_stats.sort_values('Species Count', ascending=False).head(20)\n",
    "ax2.barh(range(len(top_diversity)), top_diversity['Species Count'], color='coral')\n",
    "ax2.set_yticks(range(len(top_diversity)))\n",
    "ax2.set_yticklabels(top_diversity['Country Name'], fontsize=9)\n",
    "ax2.set_xlabel('Number of Species')\n",
    "ax2.set_title('Top 20 Countries by Species Diversity', fontweight='bold', fontsize=12)\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# 3. Top species\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "top_species = species_stats.head(20)\n",
    "ax3.barh(range(len(top_species)), top_species['Total Observations'], color='forestgreen', alpha=0.7)\n",
    "ax3.set_yticks(range(len(top_species)))\n",
    "labels = [name[:25] + '...' if len(name) > 25 else name for name in top_species['Common Name']]\n",
    "ax3.set_yticklabels(labels, fontsize=9)\n",
    "ax3.set_xlabel('Number of Observations')\n",
    "ax3.set_title('Top 20 Most Observed Species', fontweight='bold', fontsize=12)\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# 4. Observations by month\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "monthly_data = combined_df[combined_df['month'].notna()].groupby('month').size()\n",
    "months = list(range(1, 13))\n",
    "counts = [monthly_data.get(m, 0) for m in months]\n",
    "month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "ax4.bar(months, counts, color='skyblue', alpha=0.8)\n",
    "ax4.set_xticks(months)\n",
    "ax4.set_xticklabels(month_labels, rotation=45)\n",
    "ax4.set_xlabel('Month')\n",
    "ax4.set_ylabel('Number of Observations')\n",
    "ax4.set_title('Seasonal Distribution of Observations', fontweight='bold', fontsize=12)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Observations by year\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "yearly_data = combined_df[combined_df['year'].notna()].groupby('year').size().sort_index()\n",
    "ax5.plot(yearly_data.index, yearly_data.values, marker='o', linewidth=2, markersize=8, color='darkblue')\n",
    "ax5.set_xlabel('Year')\n",
    "ax5.set_ylabel('Number of Observations')\n",
    "ax5.set_title('Observations Over Time', fontweight='bold', fontsize=12)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Species geographic distribution\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "species_distribution = species_stats['Countries Found'].value_counts().sort_index()\n",
    "ax6.bar(species_distribution.index, species_distribution.values, color='teal', alpha=0.7)\n",
    "ax6.set_xlabel('Number of Countries')\n",
    "ax6.set_ylabel('Number of Species')\n",
    "ax6.set_title('Species Geographic Range Distribution', fontweight='bold', fontsize=12)\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('european_bird_analysis_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Overview charts created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic distribution map\n",
    "fig, ax = plt.subplots(figsize=(18, 12))\n",
    "\n",
    "# Create scatter plot with country colors\n",
    "scatter = ax.scatter(combined_df['lng'], combined_df['lat'], \n",
    "                    c=combined_df['countryCode'].astype('category').cat.codes,\n",
    "                    alpha=0.3, s=2, cmap='tab20c')\n",
    "\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('Geographic Distribution of Bird Observations Across Europe', \n",
    "             fontweight='bold', fontsize=16, pad=20)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics box\n",
    "stats_text = f\"Total: {len(combined_df):,} observations\\n\" \\\n",
    "             f\"Countries: {combined_df['countryCode'].nunique()}\\n\" \\\n",
    "             f\"Species: {combined_df['speciesCode'].nunique()}\"\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('geographic_distribution_map.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Geographic distribution map created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GEOGRAPHIC DISTRIBUTION MAP - COLORED BY MIGRATION GROUP\n",
    "# Different colors for Native, Autumn Migrant (Nocturnal), Autumn Migrant (Diurnal), Spring Migrant\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# European country information for labeling\n",
    "EUROPEAN_COUNTRIES = {\n",
    "    'GB': {'name': 'United Kingdom', 'lat': 54.0, 'lon': -2.0},\n",
    "    'IE': {'name': 'Ireland', 'lat': 53.0, 'lon': -8.0},\n",
    "    'FR': {'name': 'France', 'lat': 47.0, 'lon': 2.0},\n",
    "    'ES': {'name': 'Spain', 'lat': 40.0, 'lon': -4.0},\n",
    "    'PT': {'name': 'Portugal', 'lat': 39.5, 'lon': -8.0},\n",
    "    'IT': {'name': 'Italy', 'lat': 43.0, 'lon': 12.5},\n",
    "    'DE': {'name': 'Germany', 'lat': 51.0, 'lon': 10.0},\n",
    "    'PL': {'name': 'Poland', 'lat': 52.0, 'lon': 19.0},\n",
    "    'NL': {'name': 'Netherlands', 'lat': 52.5, 'lon': 5.5},\n",
    "    'BE': {'name': 'Belgium', 'lat': 50.5, 'lon': 4.5},\n",
    "    'CH': {'name': 'Switzerland', 'lat': 47.0, 'lon': 8.0},\n",
    "    'AT': {'name': 'Austria', 'lat': 47.5, 'lon': 14.0},\n",
    "    'CZ': {'name': 'Czechia', 'lat': 49.8, 'lon': 15.5},\n",
    "    'SK': {'name': 'Slovakia', 'lat': 48.7, 'lon': 19.5},\n",
    "    'HU': {'name': 'Hungary', 'lat': 47.0, 'lon': 19.5},\n",
    "    'RO': {'name': 'Romania', 'lat': 46.0, 'lon': 25.0},\n",
    "    'BG': {'name': 'Bulgaria', 'lat': 43.0, 'lon': 25.0},\n",
    "    'GR': {'name': 'Greece', 'lat': 39.0, 'lon': 22.0},\n",
    "    'SE': {'name': 'Sweden', 'lat': 62.0, 'lon': 15.0},\n",
    "    'NO': {'name': 'Norway', 'lat': 62.0, 'lon': 10.0},\n",
    "    'FI': {'name': 'Finland', 'lat': 64.0, 'lon': 26.0},\n",
    "    'DK': {'name': 'Denmark', 'lat': 56.0, 'lon': 10.0},\n",
    "    'EE': {'name': 'Estonia', 'lat': 59.0, 'lon': 26.0},\n",
    "    'LV': {'name': 'Latvia', 'lat': 57.0, 'lon': 25.0},\n",
    "    'LT': {'name': 'Lithuania', 'lat': 55.5, 'lon': 24.0},\n",
    "    'HR': {'name': 'Croatia', 'lat': 45.5, 'lon': 16.0},\n",
    "    'SI': {'name': 'Slovenia', 'lat': 46.0, 'lon': 15.0},\n",
    "    'BA': {'name': 'Bosnia', 'lat': 44.0, 'lon': 18.0},\n",
    "    'RS': {'name': 'Serbia', 'lat': 44.0, 'lon': 21.0},\n",
    "    'AL': {'name': 'Albania', 'lat': 41.0, 'lon': 20.0},\n",
    "    'MK': {'name': 'N. Macedonia', 'lat': 41.6, 'lon': 21.7},\n",
    "    'ME': {'name': 'Montenegro', 'lat': 42.7, 'lon': 19.3},\n",
    "    'XK': {'name': 'Kosovo', 'lat': 42.6, 'lon': 20.9},\n",
    "    'TR': {'name': 'Turkey', 'lat': 39.0, 'lon': 35.0},\n",
    "    'CY': {'name': 'Cyprus', 'lat': 35.0, 'lon': 33.0},\n",
    "    'IS': {'name': 'Iceland', 'lat': 65.0, 'lon': -18.0},\n",
    "    'UA': {'name': 'Ukraine', 'lat': 49.0, 'lon': 32.0},\n",
    "    'BY': {'name': 'Belarus', 'lat': 54.0, 'lon': 28.0},\n",
    "    'MD': {'name': 'Moldova', 'lat': 47.0, 'lon': 29.0},\n",
    "    'RU': {'name': 'Russia', 'lat': 60.0, 'lon': 40.0},\n",
    "    'LU': {'name': 'Luxembourg', 'lat': 49.8, 'lon': 6.1},\n",
    "    'MT': {'name': 'Malta', 'lat': 35.9, 'lon': 14.4},\n",
    "    'MC': {'name': 'Monaco', 'lat': 43.7, 'lon': 7.4},\n",
    "    'AD': {'name': 'Andorra', 'lat': 42.5, 'lon': 1.5},\n",
    "    'LI': {'name': 'Liechtenstein', 'lat': 47.1, 'lon': 9.5},\n",
    "    'SM': {'name': 'San Marino', 'lat': 43.9, 'lon': 12.5},\n",
    "    'VA': {'name': 'Vatican', 'lat': 41.9, 'lon': 12.5},\n",
    "}\n",
    "\n",
    "# Coastline approximations (simplified)\n",
    "COASTLINES = [\n",
    "    # Atlantic/North Sea coast\n",
    "    [(60, -5), (58, -3), (55, -4), (53, -6), (51, -5), (50, 1), (51, 4), (54, 5), \n",
    "     (57, 6), (59, 11), (63, 10), (65, 12), (68, 15), (70, 20), (70, 30)],\n",
    "    # Mediterranean coast  \n",
    "    [(36, -6), (37, -3), (38, 0), (41, 3), (43, 7), (43, 12), (40, 15), (38, 18), \n",
    "     (36, 23), (36, 28), (38, 32), (41, 28), (43, 19), (45, 14)],\n",
    "    # Black Sea\n",
    "    [(41, 28), (42, 29), (44, 30), (45, 31), (46, 32), (46, 38), (45, 40), \n",
    "     (43, 41), (42, 39), (41, 35), (41, 28)],\n",
    "]\n",
    "\n",
    "# Europe bounding box\n",
    "lon_min, lon_max = -25, 50\n",
    "lat_min, lat_max = 35, 72\n",
    "\n",
    "# Filter data to Europe region\n",
    "df_europe = combined_df[(combined_df['lng'] >= lon_min) & (combined_df['lng'] <= lon_max) & \n",
    "                        (combined_df['lat'] >= lat_min) & (combined_df['lat'] <= lat_max)]\n",
    "\n",
    "print(f\"Creating map colored by MIGRATION GROUP with {len(df_europe):,} observations...\")\n",
    "\n",
    "# Check if migration_category column exists\n",
    "if 'migration_category' not in df_europe.columns:\n",
    "    print(\"ERROR: 'migration_category' column not found in data!\")\n",
    "    print(\"Available columns:\", df_europe.columns.tolist())\n",
    "    print(\"\\nThis map requires the migration_category column from your analysis.\")\n",
    "    print(\"Make sure you've run the migration analysis section first.\")\n",
    "else:\n",
    "    # Get unique migration categories\n",
    "    unique_migrations = sorted(df_europe['migration_category'].dropna().unique())\n",
    "    n_migrations = len(unique_migrations)\n",
    "    print(f\"Found {n_migrations} migration groups: {unique_migrations}\")\n",
    "    \n",
    "    # Define distinct colors for each migration category\n",
    "    # Using meaningful colors that represent the migration behavior\n",
    "    migration_colors = {\n",
    "        'Native (Resident)': '#2ecc71',  # Green - stays year-round\n",
    "        'Autumn Migrant (Nocturnal)': '#e67e22',  # Orange - autumn nocturnal\n",
    "        'Autumn Migrant (Diurnal)': '#f39c12',  # Yellow-orange - autumn diurnal\n",
    "        'Spring Migrant': '#9b59b6',  # Purple - spring migrant\n",
    "    }\n",
    "    \n",
    "    # Use default colors for any unexpected categories\n",
    "    default_color = '#95a5a6'  # Gray\n",
    "    \n",
    "    # Create figure with larger size\n",
    "    fig, ax = plt.subplots(figsize=(26, 16), facecolor='#f0f8ff')\n",
    "    ax.set_facecolor('#e6f2ff')\n",
    "    \n",
    "    # Draw simplified border grid\n",
    "    for lon in range(-25, 50, 5):\n",
    "        ax.axvline(x=lon, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "    for lat in range(35, 75, 5):\n",
    "        ax.axhline(y=lat, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "    \n",
    "    # Draw coastlines\n",
    "    for coastline in COASTLINES:\n",
    "        lats, lons = zip(*[(lat, lon) for lat, lon in coastline])\n",
    "        ax.plot(lons, lats, color='steelblue', linewidth=2.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # Plot observations by migration category with distinct colors\n",
    "    print(\"Plotting observations by migration group...\")\n",
    "    for migration_cat in unique_migrations:\n",
    "        migration_data = df_europe[df_europe['migration_category'] == migration_cat]\n",
    "        if len(migration_data) > 0:\n",
    "            color = migration_colors.get(migration_cat, default_color)\n",
    "            ax.scatter(migration_data['lng'], migration_data['lat'], \n",
    "                      c=color, \n",
    "                      alpha=0.5, s=4, \n",
    "                      edgecolors='none',\n",
    "                      zorder=2,\n",
    "                      label=f\"{migration_cat} ({len(migration_data):,})\")\n",
    "    \n",
    "    # Add country code labels\n",
    "    countries_in_data = df_europe['countryCode'].unique()\n",
    "    for code, info in EUROPEAN_COUNTRIES.items():\n",
    "        if code in countries_in_data:\n",
    "            country_obs = df_europe[df_europe['countryCode'] == code]\n",
    "            if len(country_obs) > 100:\n",
    "                label_lon = country_obs['lng'].median()\n",
    "                label_lat = country_obs['lat'].median()\n",
    "                \n",
    "                if lon_min <= label_lon <= lon_max and lat_min <= label_lat <= lat_max:\n",
    "                    ax.text(label_lon, label_lat, code, \n",
    "                           fontsize=8, fontweight='bold', \n",
    "                           ha='center', va='center',\n",
    "                           color='black',\n",
    "                           bbox=dict(boxstyle='round,pad=0.4', \n",
    "                                   facecolor='white', \n",
    "                                   edgecolor='darkgray',\n",
    "                                   alpha=0.75,\n",
    "                                   linewidth=1.5),\n",
    "                           zorder=3)\n",
    "    \n",
    "    # Set map extent to Europe\n",
    "    ax.set_xlim(lon_min, lon_max)\n",
    "    ax.set_ylim(lat_min, lat_max)\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_xlabel('Longitude', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Latitude', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('Geographic Distribution of Bird Observations - Colored by Migration Group\\nGreen=Native | Orange=Autumn Nocturnal | Yellow=Autumn Diurnal | Purple=Spring', \n",
    "                 fontweight='bold', fontsize=20, pad=20)\n",
    "    \n",
    "    # Enhanced grid\n",
    "    ax.grid(True, alpha=0.4, linestyle='-', linewidth=0.5, color='gray')\n",
    "    \n",
    "    # Statistics box with migration info\n",
    "    total_obs = len(df_europe)\n",
    "    total_countries = df_europe['countryCode'].nunique()\n",
    "    total_species = df_europe['speciesCode'].nunique()\n",
    "    total_locations = df_europe['locId'].nunique()\n",
    "    \n",
    "    # Migration group breakdown\n",
    "    migration_breakdown = df_europe['migration_category'].value_counts()\n",
    "    migration_text = \"\\n\".join([f\"  {cat}: {count:,} ({count/total_obs*100:.1f}%)\" \n",
    "                                 for cat, count in migration_breakdown.items()])\n",
    "    \n",
    "    stats_text = (f\"DATASET OVERVIEW\\n\"\n",
    "                 f\"{'─' * 32}\\n\"\n",
    "                 f\"Total Observations: {total_obs:,}\\n\"\n",
    "                 f\"Countries: {total_countries}\\n\"\n",
    "                 f\"Species: {total_species}\\n\"\n",
    "                 f\"Locations: {total_locations:,}\\n\\n\"\n",
    "                 f\"MIGRATION GROUPS\\n\"\n",
    "                 f\"{'─' * 32}\\n\"\n",
    "                 f\"{migration_text}\")\n",
    "    \n",
    "    ax.text(0.015, 0.985, stats_text, \n",
    "           transform=ax.transAxes, \n",
    "           fontsize=9,\n",
    "           verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', \n",
    "                    facecolor='wheat', \n",
    "                    alpha=0.95,\n",
    "                    edgecolor='black',\n",
    "                    linewidth=2),\n",
    "           zorder=4,\n",
    "           family='monospace')\n",
    "    \n",
    "    # Legend for migration categories\n",
    "    legend = ax.legend(loc='lower right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=10,\n",
    "                      title='Migration Category (observations)',\n",
    "                      title_fontsize=11,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=1.0,\n",
    "                      edgecolor='black',\n",
    "                      facecolor='white',\n",
    "                      markerscale=2)\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "    \n",
    "    # Add compass rose\n",
    "    compass_x, compass_y = 0.96, 0.05\n",
    "    ax.annotate('', xy=(compass_x, compass_y + 0.03), \n",
    "               xytext=(compass_x, compass_y),\n",
    "               transform=ax.transAxes,\n",
    "               ha='center',\n",
    "               arrowprops=dict(arrowstyle='->', lw=2.5, color='black'))\n",
    "    ax.text(compass_x, compass_y + 0.035, 'N', \n",
    "           transform=ax.transAxes,\n",
    "           ha='center', va='bottom',\n",
    "           fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add scale bar\n",
    "    scale_lon = lon_min + 5\n",
    "    scale_lat = lat_min + 2\n",
    "    scale_length = 5  # degrees longitude\n",
    "    ax.plot([scale_lon, scale_lon + scale_length], \n",
    "           [scale_lat, scale_lat], \n",
    "           'k-', linewidth=4, zorder=4, solid_capstyle='butt')\n",
    "    ax.plot([scale_lon, scale_lon], \n",
    "           [scale_lat - 0.4, scale_lat + 0.4], \n",
    "           'k-', linewidth=3, zorder=4)\n",
    "    ax.plot([scale_lon + scale_length, scale_lon + scale_length], \n",
    "           [scale_lat - 0.4, scale_lat + 0.4], \n",
    "           'k-', linewidth=3, zorder=4)\n",
    "    ax.text(scale_lon + scale_length/2, scale_lat - 1.2, \n",
    "           '~400 km', ha='center', fontsize=11, fontweight='bold',\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, \n",
    "                    edgecolor='black', linewidth=1))\n",
    "    \n",
    "    # Add color key explanation box\n",
    "    color_key = (\n",
    "        \"COLOR KEY:\\n\"\n",
    "        \"━━━━━━━━━━━━━━━━━━\\n\"\n",
    "        \"🟢 Native (Resident)\\n\"\n",
    "        \"   Year-round residents\\n\\n\"\n",
    "        \"🟠 Autumn Nocturnal\\n\"\n",
    "        \"   Migrate at night in autumn\\n\\n\"\n",
    "        \"🟡 Autumn Diurnal\\n\"\n",
    "        \"   Migrate by day in autumn\\n\\n\"\n",
    "        \"🟣 Spring Migrant\\n\"\n",
    "        \"   Migrate in spring\"\n",
    "    )\n",
    "    \n",
    "    ax.text(0.985, 0.52, color_key, \n",
    "           transform=ax.transAxes, \n",
    "           fontsize=9,\n",
    "           verticalalignment='top',\n",
    "           ha='right',\n",
    "           bbox=dict(boxstyle='round', \n",
    "                    facecolor='white', \n",
    "                    alpha=0.95,\n",
    "                    edgecolor='black',\n",
    "                    linewidth=2),\n",
    "           zorder=4,\n",
    "           family='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('geographic_distribution_map_by_migration.png', dpi=300, bbox_inches='tight', \n",
    "               facecolor='#f0f8ff')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Migration-colored geographic distribution map created!\")\n",
    "    print(f\"  • {n_migrations} migration groups shown in different colors\")\n",
    "    print(f\"  • Green = Native/Resident birds\")\n",
    "    print(f\"  • Orange = Autumn Migrant (Nocturnal)\")\n",
    "    print(f\"  • Yellow = Autumn Migrant (Diurnal)\")\n",
    "    print(f\"  • Purple = Spring Migrant\")\n",
    "    print(f\"  • Saved as: geographic_distribution_map_by_migration.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GEOGRAPHIC DISTRIBUTION MAP - COLORED BY SPECIES\n",
    "# Each species gets a unique color to show distribution patterns\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# European country information for labeling\n",
    "EUROPEAN_COUNTRIES = {\n",
    "    'GB': {'name': 'United Kingdom', 'lat': 54.0, 'lon': -2.0},\n",
    "    'IE': {'name': 'Ireland', 'lat': 53.0, 'lon': -8.0},\n",
    "    'FR': {'name': 'France', 'lat': 47.0, 'lon': 2.0},\n",
    "    'ES': {'name': 'Spain', 'lat': 40.0, 'lon': -4.0},\n",
    "    'PT': {'name': 'Portugal', 'lat': 39.5, 'lon': -8.0},\n",
    "    'IT': {'name': 'Italy', 'lat': 43.0, 'lon': 12.5},\n",
    "    'DE': {'name': 'Germany', 'lat': 51.0, 'lon': 10.0},\n",
    "    'PL': {'name': 'Poland', 'lat': 52.0, 'lon': 19.0},\n",
    "    'NL': {'name': 'Netherlands', 'lat': 52.5, 'lon': 5.5},\n",
    "    'BE': {'name': 'Belgium', 'lat': 50.5, 'lon': 4.5},\n",
    "    'CH': {'name': 'Switzerland', 'lat': 47.0, 'lon': 8.0},\n",
    "    'AT': {'name': 'Austria', 'lat': 47.5, 'lon': 14.0},\n",
    "    'CZ': {'name': 'Czechia', 'lat': 49.8, 'lon': 15.5},\n",
    "    'SK': {'name': 'Slovakia', 'lat': 48.7, 'lon': 19.5},\n",
    "    'HU': {'name': 'Hungary', 'lat': 47.0, 'lon': 19.5},\n",
    "    'RO': {'name': 'Romania', 'lat': 46.0, 'lon': 25.0},\n",
    "    'BG': {'name': 'Bulgaria', 'lat': 43.0, 'lon': 25.0},\n",
    "    'GR': {'name': 'Greece', 'lat': 39.0, 'lon': 22.0},\n",
    "    'SE': {'name': 'Sweden', 'lat': 62.0, 'lon': 15.0},\n",
    "    'NO': {'name': 'Norway', 'lat': 62.0, 'lon': 10.0},\n",
    "    'FI': {'name': 'Finland', 'lat': 64.0, 'lon': 26.0},\n",
    "    'DK': {'name': 'Denmark', 'lat': 56.0, 'lon': 10.0},\n",
    "    'EE': {'name': 'Estonia', 'lat': 59.0, 'lon': 26.0},\n",
    "    'LV': {'name': 'Latvia', 'lat': 57.0, 'lon': 25.0},\n",
    "    'LT': {'name': 'Lithuania', 'lat': 55.5, 'lon': 24.0},\n",
    "    'HR': {'name': 'Croatia', 'lat': 45.5, 'lon': 16.0},\n",
    "    'SI': {'name': 'Slovenia', 'lat': 46.0, 'lon': 15.0},\n",
    "    'BA': {'name': 'Bosnia', 'lat': 44.0, 'lon': 18.0},\n",
    "    'RS': {'name': 'Serbia', 'lat': 44.0, 'lon': 21.0},\n",
    "    'AL': {'name': 'Albania', 'lat': 41.0, 'lon': 20.0},\n",
    "    'MK': {'name': 'N. Macedonia', 'lat': 41.6, 'lon': 21.7},\n",
    "    'ME': {'name': 'Montenegro', 'lat': 42.7, 'lon': 19.3},\n",
    "    'XK': {'name': 'Kosovo', 'lat': 42.6, 'lon': 20.9},\n",
    "    'TR': {'name': 'Turkey', 'lat': 39.0, 'lon': 35.0},\n",
    "    'CY': {'name': 'Cyprus', 'lat': 35.0, 'lon': 33.0},\n",
    "    'IS': {'name': 'Iceland', 'lat': 65.0, 'lon': -18.0},\n",
    "    'UA': {'name': 'Ukraine', 'lat': 49.0, 'lon': 32.0},\n",
    "    'BY': {'name': 'Belarus', 'lat': 54.0, 'lon': 28.0},\n",
    "    'MD': {'name': 'Moldova', 'lat': 47.0, 'lon': 29.0},\n",
    "    'RU': {'name': 'Russia', 'lat': 60.0, 'lon': 40.0},\n",
    "    'LU': {'name': 'Luxembourg', 'lat': 49.8, 'lon': 6.1},\n",
    "    'MT': {'name': 'Malta', 'lat': 35.9, 'lon': 14.4},\n",
    "    'MC': {'name': 'Monaco', 'lat': 43.7, 'lon': 7.4},\n",
    "    'AD': {'name': 'Andorra', 'lat': 42.5, 'lon': 1.5},\n",
    "    'LI': {'name': 'Liechtenstein', 'lat': 47.1, 'lon': 9.5},\n",
    "    'SM': {'name': 'San Marino', 'lat': 43.9, 'lon': 12.5},\n",
    "    'VA': {'name': 'Vatican', 'lat': 41.9, 'lon': 12.5},\n",
    "}\n",
    "\n",
    "# Coastline approximations (simplified)\n",
    "COASTLINES = [\n",
    "    # Atlantic/North Sea coast\n",
    "    [(60, -5), (58, -3), (55, -4), (53, -6), (51, -5), (50, 1), (51, 4), (54, 5), \n",
    "     (57, 6), (59, 11), (63, 10), (65, 12), (68, 15), (70, 20), (70, 30)],\n",
    "    # Mediterranean coast  \n",
    "    [(36, -6), (37, -3), (38, 0), (41, 3), (43, 7), (43, 12), (40, 15), (38, 18), \n",
    "     (36, 23), (36, 28), (38, 32), (41, 28), (43, 19), (45, 14)],\n",
    "    # Black Sea\n",
    "    [(41, 28), (42, 29), (44, 30), (45, 31), (46, 32), (46, 38), (45, 40), \n",
    "     (43, 41), (42, 39), (41, 35), (41, 28)],\n",
    "]\n",
    "\n",
    "# Europe bounding box\n",
    "lon_min, lon_max = -25, 50\n",
    "lat_min, lat_max = 35, 72\n",
    "\n",
    "# Filter data to Europe region\n",
    "df_europe = combined_df[(combined_df['lng'] >= lon_min) & (combined_df['lng'] <= lon_max) & \n",
    "                        (combined_df['lat'] >= lat_min) & (combined_df['lat'] <= lat_max)]\n",
    "\n",
    "print(f\"Creating map colored by SPECIES with {len(df_europe):,} observations...\")\n",
    "\n",
    "# Get unique species and create color map\n",
    "unique_species = sorted(df_europe['speciesCode'].unique())\n",
    "n_species = len(unique_species)\n",
    "print(f\"Found {n_species} unique species\")\n",
    "\n",
    "# Create distinct colors for each species using a good colormap\n",
    "# Use tab20 for up to 20 species, otherwise use hsv\n",
    "if n_species <= 20:\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, n_species))\n",
    "else:\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, n_species))\n",
    "    \n",
    "species_color_map = dict(zip(unique_species, colors))\n",
    "\n",
    "# Also get common names for legend\n",
    "if 'comName' in df_europe.columns:\n",
    "    species_names = df_europe.groupby('speciesCode')['comName'].first().to_dict()\n",
    "else:\n",
    "    species_names = {code: code for code in unique_species}\n",
    "\n",
    "# Create figure with larger size\n",
    "fig, ax = plt.subplots(figsize=(26, 16), facecolor='#f0f8ff')\n",
    "ax.set_facecolor('#e6f2ff')\n",
    "\n",
    "# Draw simplified border grid\n",
    "for lon in range(-25, 50, 5):\n",
    "    ax.axvline(x=lon, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "for lat in range(35, 75, 5):\n",
    "    ax.axhline(y=lat, color='gray', alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "\n",
    "# Draw coastlines\n",
    "for coastline in COASTLINES:\n",
    "    lats, lons = zip(*[(lat, lon) for lat, lon in coastline])\n",
    "    ax.plot(lons, lats, color='steelblue', linewidth=2.5, alpha=0.7, zorder=1)\n",
    "\n",
    "# Plot observations by species with distinct colors\n",
    "print(\"Plotting observations by species...\")\n",
    "for i, species in enumerate(unique_species):\n",
    "    species_data = df_europe[df_europe['speciesCode'] == species]\n",
    "    if len(species_data) > 0:\n",
    "        ax.scatter(species_data['lng'], species_data['lat'], \n",
    "                  c=[species_color_map[species]], \n",
    "                  alpha=0.5, s=4, \n",
    "                  edgecolors='none',\n",
    "                  zorder=2,\n",
    "                  label=f\"{species_names[species]} ({len(species_data):,})\")\n",
    "\n",
    "# Add country code labels\n",
    "countries_in_data = df_europe['countryCode'].unique()\n",
    "for code, info in EUROPEAN_COUNTRIES.items():\n",
    "    if code in countries_in_data:\n",
    "        country_obs = df_europe[df_europe['countryCode'] == code]\n",
    "        if len(country_obs) > 100:\n",
    "            label_lon = country_obs['lng'].median()\n",
    "            label_lat = country_obs['lat'].median()\n",
    "            \n",
    "            if lon_min <= label_lon <= lon_max and lat_min <= label_lat <= lat_max:\n",
    "                ax.text(label_lon, label_lat, code, \n",
    "                       fontsize=8, fontweight='bold', \n",
    "                       ha='center', va='center',\n",
    "                       color='black',\n",
    "                       bbox=dict(boxstyle='round,pad=0.4', \n",
    "                               facecolor='white', \n",
    "                               edgecolor='darkgray',\n",
    "                               alpha=0.75,\n",
    "                               linewidth=1.5),\n",
    "                       zorder=3)\n",
    "\n",
    "# Set map extent to Europe\n",
    "ax.set_xlim(lon_min, lon_max)\n",
    "ax.set_ylim(lat_min, lat_max)\n",
    "\n",
    "# Styling\n",
    "ax.set_xlabel('Longitude', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Latitude', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Geographic Distribution of Bird Observations - Colored by Species\\nEach color represents a different bird species', \n",
    "             fontweight='bold', fontsize=20, pad=20)\n",
    "\n",
    "# Enhanced grid\n",
    "ax.grid(True, alpha=0.4, linestyle='-', linewidth=0.5, color='gray')\n",
    "\n",
    "# Statistics box with species info\n",
    "total_obs = len(df_europe)\n",
    "total_countries = df_europe['countryCode'].nunique()\n",
    "total_species = df_europe['speciesCode'].nunique()\n",
    "total_locations = df_europe['locId'].nunique()\n",
    "\n",
    "# Top 5 species by observation count\n",
    "top_species = df_europe['speciesCode'].value_counts().head(5)\n",
    "top_species_text = \"\\n\".join([f\"  {species_names.get(code, code)[:20]}: {count:,}\" \n",
    "                               for code, count in top_species.items()])\n",
    "\n",
    "stats_text = (f\"DATASET OVERVIEW\\n\"\n",
    "             f\"{'─' * 30}\\n\"\n",
    "             f\"Total Observations: {total_obs:,}\\n\"\n",
    "             f\"Countries: {total_countries}\\n\"\n",
    "             f\"Species: {total_species}\\n\"\n",
    "             f\"Locations: {total_locations:,}\\n\\n\"\n",
    "             f\"TOP 5 SPECIES\\n\"\n",
    "             f\"{'─' * 30}\\n\"\n",
    "             f\"{top_species_text}\")\n",
    "\n",
    "ax.text(0.015, 0.985, stats_text, \n",
    "       transform=ax.transAxes, \n",
    "       fontsize=10,\n",
    "       verticalalignment='top',\n",
    "       bbox=dict(boxstyle='round', \n",
    "                facecolor='wheat', \n",
    "                alpha=0.95,\n",
    "                edgecolor='black',\n",
    "                linewidth=2),\n",
    "       zorder=4,\n",
    "       family='monospace')\n",
    "\n",
    "# Legend for species (show all if <= 20, otherwise show top 10)\n",
    "if n_species <= 20:\n",
    "    legend = ax.legend(loc='lower right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=8,\n",
    "                      title='Species (observations)',\n",
    "                      title_fontsize=9,\n",
    "                      ncol=2,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=0.6,\n",
    "                      columnspacing=1.5,\n",
    "                      edgecolor='black',\n",
    "                      facecolor='white')\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "else:\n",
    "    # Show top 10 species in legend\n",
    "    print(f\"Too many species ({n_species}) for full legend - showing top 10\")\n",
    "    # Clear previous legend items and add top 10\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Sort by observation count (already in order from plotting)\n",
    "    top_10_indices = [i for i in range(min(10, len(handles)))]\n",
    "    legend = ax.legend([handles[i] for i in top_10_indices],\n",
    "                      [labels[i] for i in top_10_indices],\n",
    "                      loc='lower right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=8,\n",
    "                      title=f'Top 10 Species (of {n_species})',\n",
    "                      title_fontsize=9,\n",
    "                      ncol=2,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=0.6,\n",
    "                      columnspacing=1.5,\n",
    "                      edgecolor='black',\n",
    "                      facecolor='white')\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "\n",
    "# Add compass rose\n",
    "compass_x, compass_y = 0.96, 0.05\n",
    "ax.annotate('', xy=(compass_x, compass_y + 0.03), \n",
    "           xytext=(compass_x, compass_y),\n",
    "           transform=ax.transAxes,\n",
    "           ha='center',\n",
    "           arrowprops=dict(arrowstyle='->', lw=2.5, color='black'))\n",
    "ax.text(compass_x, compass_y + 0.035, 'N', \n",
    "       transform=ax.transAxes,\n",
    "       ha='center', va='bottom',\n",
    "       fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add scale bar\n",
    "scale_lon = lon_min + 5\n",
    "scale_lat = lat_min + 2\n",
    "scale_length = 5  # degrees longitude\n",
    "ax.plot([scale_lon, scale_lon + scale_length], \n",
    "       [scale_lat, scale_lat], \n",
    "       'k-', linewidth=4, zorder=4, solid_capstyle='butt')\n",
    "ax.plot([scale_lon, scale_lon], \n",
    "       [scale_lat - 0.4, scale_lat + 0.4], \n",
    "       'k-', linewidth=3, zorder=4)\n",
    "ax.plot([scale_lon + scale_length, scale_lon + scale_length], \n",
    "       [scale_lat - 0.4, scale_lat + 0.4], \n",
    "       'k-', linewidth=3, zorder=4)\n",
    "ax.text(scale_lon + scale_length/2, scale_lat - 1.2, \n",
    "       '~400 km', ha='center', fontsize=11, fontweight='bold',\n",
    "       bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, \n",
    "                edgecolor='black', linewidth=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('geographic_distribution_map_by_species.png', dpi=300, bbox_inches='tight', \n",
    "           facecolor='#f0f8ff')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Species-colored geographic distribution map created!\")\n",
    "print(f\"  • {n_species} species shown in different colors\")\n",
    "print(f\"  • Each dot color represents a different bird species\")\n",
    "print(f\"  • Saved as: geographic_distribution_map_by_species.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ULTRA-DETAILED GEOGRAPHIC DISTRIBUTION MAP\n",
    "# Advanced version with precise country boundaries and enhanced visualization\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "# Simplified country boundary polygons (key European countries)\n",
    "# Format: country_code: [(lon, lat), ...]\n",
    "COUNTRY_BOUNDARIES = {\n",
    "    'GB': [(-6, 58), (-3, 59), (0, 58), (2, 52), (1, 50), (-2, 50), (-5, 52), (-6, 55), (-6, 58)],\n",
    "    'FR': [(-5, 48), (-2, 51), (3, 51), (8, 49), (8, 47), (7, 44), (4, 43), (2, 42), (-2, 43), (-2, 48), (-5, 48)],\n",
    "    'ES': [(-9, 43), (-7, 42), (-2, 43), (2, 42), (3, 40), (0, 38), (-2, 37), (-7, 37), (-9, 40), (-9, 43)],\n",
    "    'IT': [(8, 47), (13, 47), (16, 41), (18, 40), (16, 38), (15, 37), (12, 37), (10, 43), (8, 44), (8, 47)],\n",
    "    'DE': [(6, 54), (10, 55), (14, 53), (15, 51), (13, 48), (10, 47), (7, 48), (6, 50), (6, 54)],\n",
    "    'PL': [(14, 54), (17, 55), (23, 54), (24, 50), (23, 49), (18, 49), (15, 50), (14, 54)],\n",
    "    'SE': [(11, 56), (13, 58), (18, 59), (22, 66), (24, 68), (20, 69), (16, 68), (12, 63), (11, 56)],\n",
    "    'NO': [(5, 59), (8, 61), (12, 63), (16, 68), (24, 70), (28, 71), (25, 69), (20, 69), (11, 61), (5, 59)],\n",
    "}\n",
    "\n",
    "# Major city locations for reference\n",
    "MAJOR_CITIES = {\n",
    "    'London': (51.5, -0.1),\n",
    "    'Paris': (48.9, 2.4),\n",
    "    'Berlin': (52.5, 13.4),\n",
    "    'Madrid': (40.4, -3.7),\n",
    "    'Rome': (41.9, 12.5),\n",
    "    'Warsaw': (52.2, 21.0),\n",
    "    'Stockholm': (59.3, 18.1),\n",
    "    'Oslo': (59.9, 10.8),\n",
    "    'Helsinki': (60.2, 25.0),\n",
    "    'Vienna': (48.2, 16.4),\n",
    "    'Prague': (50.1, 14.4),\n",
    "    'Budapest': (47.5, 19.1),\n",
    "    'Athens': (38.0, 23.7),\n",
    "    'Bucharest': (44.4, 26.1),\n",
    "    'Kiev': (50.5, 30.5),\n",
    "    'Lisbon': (38.7, -9.1),\n",
    "    'Dublin': (53.3, -6.3),\n",
    "    'Copenhagen': (55.7, 12.6),\n",
    "    'Amsterdam': (52.4, 4.9),\n",
    "    'Brussels': (50.8, 4.4),\n",
    "}\n",
    "\n",
    "# Regional seas\n",
    "SEAS = {\n",
    "    'North Sea': (55, 4),\n",
    "    'Baltic Sea': (58, 20),\n",
    "    'Mediterranean': (38, 18),\n",
    "    'Black Sea': (44, 35),\n",
    "    'Atlantic Ocean': (45, -15),\n",
    "}\n",
    "\n",
    "# Europe bounding box (fills screen)\n",
    "lon_min, lon_max = -25, 50\n",
    "lat_min, lat_max = 35, 72\n",
    "\n",
    "# Filter data to Europe\n",
    "df_europe = combined_df[(combined_df['lng'] >= lon_min) & (combined_df['lng'] <= lon_max) & \n",
    "                        (combined_df['lat'] >= lat_min) & (combined_df['lat'] <= lat_max)]\n",
    "\n",
    "print(f\"Creating ultra-detailed map with {len(df_europe):,} observations...\")\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(28, 18), facecolor='#e8f4f8')\n",
    "ax = fig.add_subplot(111, facecolor='#d6ecf5')\n",
    "\n",
    "# Draw refined grid (latitude/longitude lines)\n",
    "for lon in np.arange(-20, 50, 5):\n",
    "    ax.axvline(x=lon, color='lightgray', alpha=0.4, linewidth=0.7, linestyle=':')\n",
    "    if lon % 10 == 0:\n",
    "        ax.axvline(x=lon, color='gray', alpha=0.5, linewidth=1.0, linestyle='--')\n",
    "        \n",
    "for lat in np.arange(35, 75, 5):\n",
    "    ax.axhline(y=lat, color='lightgray', alpha=0.4, linewidth=0.7, linestyle=':')\n",
    "    if lat % 10 == 0:\n",
    "        ax.axhline(y=lat, color='gray', alpha=0.5, linewidth=1.0, linestyle='--')\n",
    "\n",
    "# Draw country boundaries\n",
    "print(\"Drawing country boundaries...\")\n",
    "for country_code, boundary in COUNTRY_BOUNDARIES.items():\n",
    "    lons, lats = zip(*[(lon, lat) for lat, lon in boundary])\n",
    "    ax.plot(lons, lats, color='#2c3e50', linewidth=2.5, alpha=0.8, zorder=2)\n",
    "    ax.fill(lons, lats, color='white', alpha=0.15, zorder=1)\n",
    "\n",
    "# Color mapping for countries\n",
    "countries_in_data = sorted(df_europe['countryCode'].unique())\n",
    "n_countries = len(countries_in_data)\n",
    "\n",
    "# Use multiple colormaps for variety\n",
    "colors = []\n",
    "for i, country in enumerate(countries_in_data):\n",
    "    hue = i / n_countries\n",
    "    colors.append(plt.cm.hsv(hue))\n",
    "color_map = dict(zip(countries_in_data, colors))\n",
    "\n",
    "# Plot observations with distinct colors per country\n",
    "print(\"Plotting observations...\")\n",
    "for i, country in enumerate(countries_in_data):\n",
    "    country_data = df_europe[df_europe['countryCode'] == country]\n",
    "    if len(country_data) > 0:\n",
    "        ax.scatter(country_data['lng'], country_data['lat'], \n",
    "                  c=[color_map[country]], \n",
    "                  alpha=0.35, s=2.5, \n",
    "                  edgecolors='none',\n",
    "                  zorder=3,\n",
    "                  label=country if i < 25 else None)\n",
    "\n",
    "# Add country labels at observation centers\n",
    "print(\"Adding country labels...\")\n",
    "for code in countries_in_data:\n",
    "    country_obs = df_europe[df_europe['countryCode'] == code]\n",
    "    if len(country_obs) > 50:  # Only label countries with sufficient data\n",
    "        label_lon = country_obs['lng'].median()\n",
    "        label_lat = country_obs['lat'].median()\n",
    "        \n",
    "        if lon_min <= label_lon <= lon_max and lat_min <= label_lat <= lat_max:\n",
    "            # Calculate observation density for this country\n",
    "            obs_count = len(country_obs)\n",
    "            \n",
    "            # Adjust label styling based on observation count\n",
    "            fontsize = min(12, max(7, 7 + np.log10(obs_count)))\n",
    "            \n",
    "            ax.text(label_lon, label_lat, code, \n",
    "                   fontsize=fontsize, fontweight='bold', \n",
    "                   ha='center', va='center',\n",
    "                   color='#2c3e50',\n",
    "                   bbox=dict(boxstyle='round,pad=0.5', \n",
    "                           facecolor='white', \n",
    "                           edgecolor='#34495e',\n",
    "                           alpha=0.9,\n",
    "                           linewidth=2),\n",
    "                   zorder=5)\n",
    "\n",
    "# Add major city markers\n",
    "print(\"Adding major cities...\")\n",
    "for city, (lat, lon) in MAJOR_CITIES.items():\n",
    "    if lon_min <= lon <= lon_max and lat_min <= lat <= lat_max:\n",
    "        ax.plot(lon, lat, 'k*', markersize=8, zorder=4, \n",
    "               markeredgecolor='white', markeredgewidth=1)\n",
    "        ax.text(lon + 0.8, lat + 0.5, city, fontsize=7, \n",
    "               style='italic', alpha=0.7, zorder=4)\n",
    "\n",
    "# Add sea labels\n",
    "for sea, (lat, lon) in SEAS.items():\n",
    "    if lon_min <= lon <= lon_max and lat_min <= lat <= lat_max:\n",
    "        ax.text(lon, lat, sea, fontsize=10, \n",
    "               ha='center', va='center',\n",
    "               color='#2980b9', alpha=0.6,\n",
    "               style='italic', fontweight='bold')\n",
    "\n",
    "# Set extent\n",
    "ax.set_xlim(lon_min, lon_max)\n",
    "ax.set_ylim(lat_min, lat_max)\n",
    "\n",
    "# Enhanced styling\n",
    "ax.set_xlabel('Longitude (°E)', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Latitude (°N)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('Geographic Distribution of Bird Observations Across Europe\\nDetailed Country Boundaries and Observation Density', \n",
    "             fontweight='bold', fontsize=22, pad=25)\n",
    "\n",
    "# Major grid with labels\n",
    "ax.grid(True, which='major', alpha=0.5, linestyle='-', linewidth=0.8, color='gray')\n",
    "\n",
    "# Detailed statistics panel\n",
    "total_obs = len(df_europe)\n",
    "total_countries = df_europe['countryCode'].nunique()\n",
    "total_species = df_europe['speciesCode'].nunique()\n",
    "total_locations = df_europe['locId'].nunique()\n",
    "\n",
    "# Top 5 countries\n",
    "top_countries = df_europe['countryCode'].value_counts().head(5)\n",
    "top_countries_text = \"\\n\".join([f\"  {code}: {count:,}\" for code, count in top_countries.items()])\n",
    "\n",
    "stats_text = (\n",
    "    f\"DATASET OVERVIEW\\n\"\n",
    "    f\"{'─' * 30}\\n\"\n",
    "    f\"Total Observations: {total_obs:,}\\n\"\n",
    "    f\"Countries: {total_countries}\\n\"\n",
    "    f\"Species: {total_species:,}\\n\"\n",
    "    f\"Locations: {total_locations:,}\\n\\n\"\n",
    "    f\"COVERAGE\\n\"\n",
    "    f\"{'─' * 30}\\n\"\n",
    "    f\"Latitude: {lat_min}° to {lat_max}°\\n\"\n",
    "    f\"Longitude: {lon_min}° to {lon_max}°\\n\\n\"\n",
    "    f\"TOP 5 COUNTRIES\\n\"\n",
    "    f\"{'─' * 30}\\n\"\n",
    "    f\"{top_countries_text}\"\n",
    ")\n",
    "\n",
    "ax.text(0.015, 0.985, stats_text, \n",
    "       transform=ax.transAxes, \n",
    "       fontsize=10,\n",
    "       verticalalignment='top',\n",
    "       bbox=dict(boxstyle='round,pad=1', \n",
    "                facecolor='#ecf0f1', \n",
    "                alpha=0.95,\n",
    "                edgecolor='#2c3e50',\n",
    "                linewidth=3),\n",
    "       zorder=6,\n",
    "       family='monospace',\n",
    "       linespacing=1.5)\n",
    "\n",
    "# Legend for top countries (if not too many)\n",
    "if len(countries_in_data) <= 25:\n",
    "    legend = ax.legend(loc='upper right', \n",
    "                      framealpha=0.95, \n",
    "                      fontsize=8,\n",
    "                      title='Country Codes',\n",
    "                      title_fontsize=10,\n",
    "                      ncol=3,\n",
    "                      borderpad=1,\n",
    "                      labelspacing=0.8,\n",
    "                      columnspacing=1.5,\n",
    "                      edgecolor='#2c3e50',\n",
    "                      facecolor='#ecf0f1')\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "\n",
    "# Enhanced compass rose\n",
    "compass_x, compass_y = 0.97, 0.04\n",
    "# North arrow\n",
    "ax.annotate('', xy=(compass_x, compass_y + 0.035), \n",
    "           xytext=(compass_x, compass_y),\n",
    "           transform=ax.transAxes,\n",
    "           arrowprops=dict(arrowstyle='->', lw=3, color='#2c3e50'))\n",
    "ax.text(compass_x, compass_y + 0.04, 'N', \n",
    "       transform=ax.transAxes,\n",
    "       ha='center', va='bottom',\n",
    "       fontsize=16, fontweight='bold', color='#2c3e50')\n",
    "\n",
    "# Cardinal directions\n",
    "cardinal_size = 0.015\n",
    "for direction, (dx, dy) in [('E', (cardinal_size, 0)), ('W', (-cardinal_size, 0)), ('S', (0, -cardinal_size))]:\n",
    "    ax.text(compass_x + dx, compass_y + dy, direction,\n",
    "           transform=ax.transAxes,\n",
    "           ha='center', va='center',\n",
    "           fontsize=11, color='#2c3e50', alpha=0.7)\n",
    "\n",
    "# Enhanced scale bar with multiple distances\n",
    "scale_lon = lon_min + 4\n",
    "scale_lat = lat_min + 1.5\n",
    "scale_lengths = [5, 10]  # Multiple scale bars\n",
    "scale_colors = ['black', 'darkgray']\n",
    "\n",
    "for i, (length, color) in enumerate(zip(scale_lengths, scale_colors)):\n",
    "    y_offset = i * 0.8\n",
    "    ax.plot([scale_lon, scale_lon + length], \n",
    "           [scale_lat - y_offset, scale_lat - y_offset], \n",
    "           color=color, linewidth=5, zorder=4, solid_capstyle='butt')\n",
    "    ax.plot([scale_lon, scale_lon], \n",
    "           [scale_lat - 0.5 - y_offset, scale_lat + 0.5 - y_offset], \n",
    "           color=color, linewidth=3, zorder=4)\n",
    "    ax.plot([scale_lon + length, scale_lon + length], \n",
    "           [scale_lat - 0.5 - y_offset, scale_lat + 0.5 - y_offset], \n",
    "           color=color, linewidth=3, zorder=4)\n",
    "    \n",
    "    # Distance label (approximate)\n",
    "    km_approx = int(length * 80)  # ~80km per degree at European latitudes\n",
    "    ax.text(scale_lon + length/2, scale_lat - 1.5 - y_offset, \n",
    "           f'~{km_approx} km', \n",
    "           ha='center', fontsize=9, fontweight='bold',\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.95, \n",
    "                    edgecolor=color, linewidth=1.5))\n",
    "\n",
    "# Add data attribution\n",
    "ax.text(0.5, 0.005, \n",
    "       'Data Source: eBird | 47 European Countries | 2022', \n",
    "       transform=ax.transAxes,\n",
    "       ha='center', va='bottom',\n",
    "       fontsize=9, style='italic', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('geographic_distribution_map_ultra_detailed.png', \n",
    "           dpi=350, bbox_inches='tight', facecolor='#e8f4f8')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Ultra-detailed geographic distribution map created!\")\n",
    "print(\"\\nFeatures:\")\n",
    "print(\"  ✓ Europe fills entire screen (35°N - 72°N, 25°W - 50°E)\")\n",
    "print(\"  ✓ Country boundaries with shading\")\n",
    "print(\"  ✓ Country code labels at observation centers\")\n",
    "print(\"  ✓ Major cities marked with stars\")\n",
    "print(\"  ✓ Sea and ocean labels\")\n",
    "print(\"  ✓ Enhanced grid with major/minor lines\")\n",
    "print(\"  ✓ Compass rose with cardinal directions\")\n",
    "print(\"  ✓ Multiple distance scale bars\")\n",
    "print(\"  ✓ Comprehensive statistics panel\")\n",
    "print(\"  ✓ Top 5 countries by observations\")\n",
    "print(\"  ✓ Color-coded observations by country\")\n",
    "print(f\"  ✓ High resolution (350 DPI) output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Statistical Tests and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis between country metrics\n",
    "print(\"\\nCOUNTRY METRICS CORRELATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correlation_data = country_stats[['Total Observations', 'Species Count', \n",
    "                                   'Unique Locations']].corr()\n",
    "\n",
    "print(correlation_data)\n",
    "\n",
    "# Visualize correlation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_data, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix: Country Metrics', fontweight='bold', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Correlation analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Distribution of observations per country\n",
    "axes[0].hist(country_stats['Total Observations'], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Observations per Country')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Observations per Country', fontweight='bold')\n",
    "axes[0].axvline(country_stats['Total Observations'].median(), color='red', \n",
    "                   linestyle='--', label=f'Median: {country_stats[\"Total Observations\"].median():.0f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Distribution of species per country\n",
    "axes[1].hist(country_stats['Species Count'], bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Species Count per Country')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Species Diversity per Country', fontweight='bold')\n",
    "axes[1].axvline(country_stats['Species Count'].median(), color='red', \n",
    "                   linestyle='--', label=f'Median: {country_stats[\"Species Count\"].median():.0f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Distribution of observations per species\n",
    "axes[2].hist(species_stats['Total Observations'], bins=50, color='forestgreen', alpha=0.7, edgecolor='black')\n",
    "axes[2].set_xlabel('Observations per Species')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Distribution of Observations per Species', fontweight='bold')\n",
    "axes[2].set_xlim(0, species_stats['Total Observations'].quantile(0.95))\n",
    "axes[2].axvline(species_stats['Total Observations'].median(), color='red', \n",
    "                   linestyle='--', label=f'Median: {species_stats[\"Total Observations\"].median():.0f}')\n",
    "axes[2].legend()\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Distribution analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined dataset\n",
    "output_file = 'combined_european_birds_full.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Combined dataset saved: {output_file}\")\n",
    "print(f\"  Size: {Path(output_file).stat().st_size / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save statistical summaries\n",
    "country_stats.to_csv('country_statistics_detailed.csv', index=False)\n",
    "print(\"✓ Country statistics saved: country_statistics_detailed.csv\")\n",
    "\n",
    "species_stats.to_csv('species_statistics_detailed.csv', index=False)\n",
    "print(\"✓ Species statistics saved: species_statistics_detailed.csv\")\n",
    "\n",
    "# Save migration analysis results\n",
    "if len(unspotted_species) > 0:\n",
    "    unspotted_species.to_csv('unspotted_species.csv', index=False)\n",
    "    print(\"✓ Unspotted species saved: unspotted_species.csv\")\n",
    "\n",
    "spotted_species.to_csv('spotted_reference_species.csv', index=False)\n",
    "print(\"✓ Spotted reference species saved: spotted_reference_species.csv\")\n",
    "\n",
    "# Save habitat type analysis (Forest, Countryside, City Centre)\n",
    "habitat_summary = combined_df.groupby(['habitat_type', 'comName']).size().reset_index(name='Observations')\n",
    "habitat_summary = habitat_summary.sort_values(['habitat_type', 'Observations'], ascending=[True, False])\n",
    "habitat_summary.to_csv('habitat_type_species.csv', index=False)\n",
    "print(\"✓ Habitat type analysis saved: habitat_type_species.csv\")\n",
    "\n",
    "# Save migration season analysis\n",
    "migration_season_summary = reference_obs.groupby(['migration_category', 'season', 'comName']).size().reset_index(name='Observations')\n",
    "migration_season_summary = migration_season_summary.sort_values(['migration_category', 'season', 'Observations'], ascending=[True, True, False])\n",
    "migration_season_summary.to_csv('migration_season_analysis.csv', index=False)\n",
    "print(\"✓ Migration season analysis saved: migration_season_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary report\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "EUROPEAN BIRD SIGHTINGS - COMPREHENSIVE STATISTICAL ANALYSIS REPORT\n",
    "{'='*80}\n",
    "\n",
    "Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "DATASET OVERVIEW\n",
    "{'-'*80}\n",
    "Total Observations: {len(combined_df):,}\n",
    "Countries Covered: {combined_df['countryCode'].nunique()}\n",
    "Unique Species Observed: {combined_df['speciesCode'].nunique()}\n",
    "Unique Locations: {combined_df['locId'].nunique()}\n",
    "Total Checklists: {combined_df['subId'].nunique()}\n",
    "Date Range: {combined_df['obsDt'].min()} to {combined_df['obsDt'].max()}\n",
    "\n",
    "GEOGRAPHIC COVERAGE\n",
    "{'-'*80}\n",
    "Latitude Range: {combined_df['lat'].min():.4f}° to {combined_df['lat'].max():.4f}°\n",
    "Longitude Range: {combined_df['lng'].min():.4f}° to {combined_df['lng'].max():.4f}°\n",
    "\n",
    "REFERENCE SPECIES ANALYSIS\n",
    "{'-'*80}\n",
    "Total Reference Species: {len(bird_reference_clean)}\n",
    "Species Spotted: {len(spotted_species)} ({len(spotted_species)/len(bird_reference_clean)*100:.1f}%)\n",
    "Species Not Spotted: {len(unspotted_species)} ({len(unspotted_species)/len(bird_reference_clean)*100:.1f}%)\n",
    "\n",
    "HABITAT TYPE ANALYSIS (Coordinate-Based)\n",
    "{'-'*80}\n",
    "City Centre Observations: {len(combined_df[combined_df['habitat_type'] == 'City Centre']):,}\n",
    "Countryside Observations: {len(combined_df[combined_df['habitat_type'] == 'Countryside']):,}\n",
    "Forest Observations: {len(combined_df[combined_df['habitat_type'] == 'Forest']):,}\n",
    "Unknown Habitat: {len(combined_df[combined_df['habitat_type'] == 'Unknown']):,}\n",
    "\n",
    "MIGRATION PATTERN ANALYSIS\n",
    "{'-'*80}\n",
    "Native (Resident) Birds: {len(reference_obs[reference_obs['migration_category'] == 'Native (Resident)']):,} observations\n",
    "Autumn Migrants (Nocturnal): {len(reference_obs[reference_obs['migration_category'] == 'Autumn Migrant (Nocturnal)']):,} observations\n",
    "Autumn Migrants (Diurnal): {len(reference_obs[reference_obs['migration_category'] == 'Autumn Migrant (Diurnal)']):,} observations\n",
    "Spring Migrants: {len(reference_obs[reference_obs['migration_category'] == 'Spring Migrant']):,} observations\n",
    "\n",
    "TOP 10 COUNTRIES BY OBSERVATIONS\n",
    "{'-'*80}\n",
    "{country_stats[['Country Name', 'Total Observations', 'Species Count']].head(10).to_string(index=False)}\n",
    "\n",
    "TOP 10 MOST OBSERVED SPECIES\n",
    "{'-'*80}\n",
    "{species_stats[['Common Name', 'Scientific Name', 'Total Observations', 'Countries Found']].head(10).to_string(index=False)}\n",
    "\n",
    "TEMPORAL DISTRIBUTION\n",
    "{'-'*80}\n",
    "Peak Observation Month: {month_names[int(monthly_obs.idxmax())] if pd.notna(monthly_obs.idxmax()) else 'N/A'}\n",
    "Average Observations per Month: {combined_df.groupby('month').size().mean():.0f}\n",
    "\n",
    "FILES GENERATED\n",
    "{'-'*80}\n",
    "1. combined_european_birds_full.csv - Complete combined dataset\n",
    "2. country_statistics_detailed.csv - Country-level statistics\n",
    "3. species_statistics_detailed.csv - Species-level statistics\n",
    "4. unspotted_species.csv - Species from reference list not observed\n",
    "5. spotted_reference_species.csv - Reference species that were observed\n",
    "6. habitat_type_species.csv - Species by habitat type (City/Countryside/Forest)\n",
    "7. migration_season_analysis.csv - Migration patterns by season\n",
    "8. european_bird_analysis_overview.png - Overview visualizations\n",
    "9. geographic_distribution_map.png - Geographic map\n",
    "10. correlation_matrix.png - Correlation analysis\n",
    "11. distribution_analysis.png - Distribution plots\n",
    "12. migration_habitat_analysis.png - Migration and habitat charts\n",
    "13. migration_season_heatmap.png - Seasonal migration heatmap\n",
    "\n",
    "{'='*80}\n",
    "END OF REPORT\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "with open('analysis_report_full.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✓ Comprehensive report saved: analysis_report_full.txt\")\n",
    "print(\"\\n\" + report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This analysis has successfully:\n",
    "- Combined all 47 European country CSV files into one dataset\n",
    "- Performed comprehensive statistical analysis on countries, species, and temporal patterns\n",
    "- Analyzed bird species from the reference list (spotted vs unspotted)\n",
    "- Classified observations by **habitat type using location features**: City Centre, Countryside, and Forest (works for ALL European countries)\n",
    "- Analyzed migration patterns with **split autumn migrants**: Nocturnal and Diurnal\n",
    "- Examined seasonal patterns across different migration groups\n",
    "- Generated visualizations showing patterns and distributions\n",
    "- Exported detailed statistics and reports\n",
    "\n",
    "All output files have been saved to the current directory.\n",
    "\n",
    "---\n",
    "\n",
    "**Output Files:**\n",
    "\n",
    "*CSV Data Files:*\n",
    "- `combined_european_birds_full.csv` - Complete combined dataset with all new fields\n",
    "- `country_statistics_detailed.csv` - Country-level statistics\n",
    "- `species_statistics_detailed.csv` - Species-level statistics\n",
    "- `unspotted_species.csv` - Species from reference list not observed\n",
    "- `spotted_reference_species.csv` - Reference species that were observed\n",
    "- `habitat_type_species.csv` - Species observations by habitat (City/Countryside/Forest)\n",
    "- `migration_season_analysis.csv` - Detailed migration patterns by season (with split autumn migrants)\n",
    "\n",
    "*Visualization Files:*\n",
    "- `european_bird_analysis_overview.png` - 6 overview charts (countries, species, temporal)\n",
    "- `geographic_distribution_map.png` - Geographic scatter plot of all observations\n",
    "- `correlation_matrix.png` - Country metrics correlation heatmap\n",
    "- `distribution_analysis.png` - 3 distribution histograms\n",
    "- `migration_habitat_analysis.png` - 6 charts for migration and habitat patterns\n",
    "- `migration_season_heatmap.png` - Heatmap showing migration patterns across seasons\n",
    "\n",
    "*Report:*\n",
    "- `analysis_report_full.txt` - Comprehensive text summary report\n",
    "\n",
    "**Key Improvements:**\n",
    "1. **Intelligent Habitat Classification**: Uses multilingual keywords (English, French, German, Italian, Spanish, Albanian) and location features to classify habitats across ALL European countries\n",
    "2. **Split Autumn Migrants**: Separates nocturnal and diurnal autumn migrants for more detailed migration analysis\n",
    "3. **Three Habitat Types**: City Centre, Countryside, and Forest classifications\n",
    "4. **Four Migration Categories**: Native (Resident), Autumn Migrant (Nocturnal), Autumn Migrant (Diurnal), and Spring Migrant\n",
    "\n",
    "**Classification Method:**\n",
    "- **Forest**: Identifies protected areas, national parks, mountains, and natural reserves using multilingual keywords\n",
    "- **City Centre**: Detects urban areas using city/town names and infrastructure keywords\n",
    "- **Countryside**: Agricultural and rural areas (default classification)\n",
    "- Works across all 47 European countries without country-specific hardcoding\n",
    "\n",
    "**Key Findings:**\n",
    "1. **Reference Species Coverage**: See what percentage of expected species were observed\n",
    "2. **Habitat Preferences**: Compare bird diversity and abundance across City/Countryside/Forest\n",
    "3. **Migration Patterns**: Understand when different migration groups (including split autumn migrants) are most active\n",
    "4. **Seasonal Trends**: Identify peak observation periods for each detailed migration category\n",
    "\n",
    "**Next Steps:**\n",
    "- Examine the CSV files for detailed breakdowns\n",
    "- Review visualizations for insights into patterns\n",
    "- Read the comprehensive report for a full summary\n",
    "- Use this notebook to further explore specific aspects of the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (da)",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
